 Network bank-app_default  Creating
 Network bank-app_default  Created
 Container kyc-service_postgres  Creating
 Container otel-collector  Creating
 Container kafka  Creating
 Container user-service-postgres  Creating
 Container minio  Creating
 Container bankapp-postgres  Creating
 Container kafka  Created
 Container otel-collector  Created
 Container security-service  Creating
 Container minio  Created
 Container bankapp-postgres  Created
 Container notification-service  Creating
 Container account-service  Creating
 Container settings-service  Creating
 Container bankapp  Creating
 Container fraud-detection  Creating
 Container user-service-postgres  Created
 Container auth-statistics-service  Creating
 Container kyc-service_postgres  Created
 Container kyc-service  Creating
 Container notification-service  Created
 Container security-service  Created
 Container account-service  Created
 Container fraud-detection  Created
 Container auth-statistics-service  Created
 Container bankapp  Created
 Container settings-service  Created
 Container bank-app-api-gateway-1  Creating
 Container kyc-service  Created
 Container bank-app-api-gateway-1  Created
Attaching to account-service, auth-statistics-service, api-gateway-1, bankapp, bankapp-postgres, fraud-detection, kafka, kyc-service, kyc-service_postgres, minio, notification-service, otel-collector, security-service, settings-service, user-service-postgres
kafka  | [38;5;6mkafka [38;5;5m16:11:14.23 [0m[38;5;2mINFO [0m ==> 
kafka  | [38;5;6mkafka [38;5;5m16:11:14.23 [0m[38;5;2mINFO [0m ==> [1mWelcome to the Bitnami kafka container[0m
kafka  | [38;5;6mkafka [38;5;5m16:11:14.24 [0m[38;5;2mINFO [0m ==> Subscribe to project updates by watching [1mhttps://github.com/bitnami/containers[0m
kafka  | [38;5;6mkafka [38;5;5m16:11:14.26 [0m[38;5;2mINFO [0m ==> Submit issues and feature requests at [1mhttps://github.com/bitnami/containers/issues[0m
kafka  | [38;5;6mkafka [38;5;5m16:11:14.27 [0m[38;5;2mINFO [0m ==> Upgrade to Tanzu Application Catalog for production environments to access custom-configured and pre-packaged software components. Gain enhanced features, including Software Bill of Materials (SBOM), CVE scan result reports, and VEX documents. To learn more, visit [1mhttps://bitnami.com/enterprise[0m
kafka  | [38;5;6mkafka [38;5;5m16:11:14.27 [0m[38;5;2mINFO [0m ==> 
kafka  | [38;5;6mkafka [38;5;5m16:11:14.28 [0m[38;5;2mINFO [0m ==> ** Starting Kafka setup **
bankapp-postgres  | 
bankapp-postgres  | PostgreSQL Database directory appears to contain a database; Skipping initialization
bankapp-postgres  | 
kyc-service_postgres  | ********************************************************************************
kyc-service_postgres  | WARNING: POSTGRES_HOST_AUTH_METHOD has been set to "trust". This will allow
kyc-service_postgres  |          anyone with access to the Postgres port to access your database without
kyc-service_postgres  |          a password, even if POSTGRES_PASSWORD is set. See PostgreSQL
kyc-service_postgres  |          documentation about "trust":
kyc-service_postgres  |          https://www.postgresql.org/docs/current/auth-trust.html
kyc-service_postgres  |          In Docker's default configuration, this is effectively any other
kyc-service_postgres  |          container on the same system.
kyc-service_postgres  | 
kyc-service_postgres  |          It is not recommended to use POSTGRES_HOST_AUTH_METHOD=trust. Replace
kyc-service_postgres  |          it with "-e POSTGRES_PASSWORD=password" instead to set a password in
kyc-service_postgres  |          "docker run".
kyc-service_postgres  | ********************************************************************************
user-service-postgres  | 
user-service-postgres  | PostgreSQL Database directory appears to contain a database; Skipping initialization
user-service-postgres  | 
kyc-service_postgres   | The files belonging to this database system will be owned by user "postgres".
kyc-service_postgres   | This user must also own the server process.
kyc-service_postgres   | 
kyc-service_postgres   | The database cluster will be initialized with locale "en_US.utf8".
kyc-service_postgres   | The default database encoding has accordingly been set to "UTF8".
kyc-service_postgres   | The default text search configuration will be set to "english".
kyc-service_postgres   | 
kyc-service_postgres   | Data page checksums are disabled.
kyc-service_postgres   | 
kyc-service_postgres   | fixing permissions on existing directory /var/lib/postgresql/data ... ok
kyc-service_postgres   | creating subdirectories ... ok
kyc-service_postgres   | selecting dynamic shared memory implementation ... posix
user-service-postgres  | 2025-10-03 16:11:14.924 UTC [1] LOG:  starting PostgreSQL 15.14 (Debian 15.14-1.pgdg13+1) on aarch64-unknown-linux-gnu, compiled by gcc (Debian 14.2.0-19) 14.2.0, 64-bit
kafka                  | [38;5;6mkafka [38;5;5m16:11:14.92 [0m[38;5;3mWARN [0m ==> Kafka has been configured with a PLAINTEXT listener, this setting is not recommended for production environments.
kyc-service_postgres   | selecting default max_connections ... 100
user-service-postgres  | 2025-10-03 16:11:14.931 UTC [1] LOG:  listening on IPv4 address "0.0.0.0", port 5432
user-service-postgres  | 2025-10-03 16:11:14.931 UTC [1] LOG:  listening on IPv6 address "::", port 5432
bankapp-postgres       | 2025-10-03 16:11:14.931 UTC [1] LOG:  starting PostgreSQL 15.14 (Debian 15.14-1.pgdg13+1) on aarch64-unknown-linux-gnu, compiled by gcc (Debian 14.2.0-19) 14.2.0, 64-bit
bankapp-postgres       | 2025-10-03 16:11:14.932 UTC [1] LOG:  listening on IPv4 address "0.0.0.0", port 5432
bankapp-postgres       | 2025-10-03 16:11:14.934 UTC [1] LOG:  listening on IPv6 address "::", port 5432
user-service-postgres  | 2025-10-03 16:11:14.947 UTC [1] LOG:  listening on Unix socket "/var/run/postgresql/.s.PGSQL.5432"
bankapp-postgres       | 2025-10-03 16:11:14.953 UTC [1] LOG:  listening on Unix socket "/var/run/postgresql/.s.PGSQL.5432"
kafka                  | [38;5;6mkafka [38;5;5m16:11:15.02 [0m[38;5;2mINFO [0m ==> Initializing Kafka...
bankapp-postgres       | 2025-10-03 16:11:15.027 UTC [27] LOG:  database system was shut down at 2025-10-03 15:55:52 UTC
user-service-postgres  | 2025-10-03 16:11:15.026 UTC [29] LOG:  database system was shut down at 2025-10-03 15:55:46 UTC
kafka                  | [38;5;6mkafka [38;5;5m16:11:15.04 [0m[38;5;2mINFO [0m ==> No injected configuration files found, creating default config files
bankapp-postgres       | 2025-10-03 16:11:15.063 UTC [1] LOG:  database system is ready to accept connections
user-service-postgres  | 2025-10-03 16:11:15.075 UTC [1] LOG:  database system is ready to accept connections
kyc-service_postgres   | selecting default shared_buffers ... 128MB
kyc-service_postgres   | selecting default time zone ... Etc/UTC
kyc-service_postgres   | creating configuration files ... ok
account-service        | OpenJDK 64-Bit Server VM warning: Sharing is only supported for boot loader classes because bootstrap classpath has been appended
kyc-service            | OpenJDK 64-Bit Server VM warning: Sharing is only supported for boot loader classes because bootstrap classpath has been appended
kyc-service_postgres   | running bootstrap script ... ok
otel-collector         | 2025-10-03T16:11:17.095Z	info	service@v0.132.0/service.go:187	Setting up own telemetry...	{"resource": {"service.instance.id": "4aa48a6d-7678-4f39-b57a-6fa72002086e", "service.name": "otelcol", "service.version": "0.132.0"}}
otel-collector         | 2025-10-03T16:11:17.251Z	info	service@v0.132.0/service.go:249	Starting otelcol...	{"resource": {"service.instance.id": "4aa48a6d-7678-4f39-b57a-6fa72002086e", "service.name": "otelcol", "service.version": "0.132.0"}, "Version": "0.132.0", "NumCPU": 5}
otel-collector         | 2025-10-03T16:11:17.264Z	info	extensions/extensions.go:41	Starting extensions...	{"resource": {"service.instance.id": "4aa48a6d-7678-4f39-b57a-6fa72002086e", "service.name": "otelcol", "service.version": "0.132.0"}}
otel-collector         | 2025-10-03T16:11:17.274Z	info	otlpreceiver@v0.132.0/otlp.go:117	Starting GRPC server	{"resource": {"service.instance.id": "4aa48a6d-7678-4f39-b57a-6fa72002086e", "service.name": "otelcol", "service.version": "0.132.0"}, "otelcol.component.id": "otlp", "otelcol.component.kind": "receiver", "endpoint": "0.0.0.0:4317"}
otel-collector         | 2025-10-03T16:11:17.290Z	info	otlpreceiver@v0.132.0/otlp.go:175	Starting HTTP server	{"resource": {"service.instance.id": "4aa48a6d-7678-4f39-b57a-6fa72002086e", "service.name": "otelcol", "service.version": "0.132.0"}, "otelcol.component.id": "otlp", "otelcol.component.kind": "receiver", "endpoint": "0.0.0.0:4318"}
otel-collector         | 2025-10-03T16:11:17.313Z	info	service@v0.132.0/service.go:272	Everything is ready. Begin running and processing data.	{"resource": {"service.instance.id": "4aa48a6d-7678-4f39-b57a-6fa72002086e", "service.name": "otelcol", "service.version": "0.132.0"}}
bankapp                | OpenJDK 64-Bit Server VM warning: Sharing is only supported for boot loader classes because bootstrap classpath has been appended
auth-statistics-service  | OpenJDK 64-Bit Server VM warning: Sharing is only supported for boot loader classes because bootstrap classpath has been appended
security-service         | OpenJDK 64-Bit Server VM warning: Sharing is only supported for boot loader classes because bootstrap classpath has been appended
kafka                    | [38;5;6mkafka [38;5;5m16:11:18.23 [0m[38;5;2mINFO [0m ==> Initializing KRaft storage metadata
kafka                    | [38;5;6mkafka [38;5;5m16:11:18.25 [0m[38;5;2mINFO [0m ==> Formatting storage directories to add metadata...
kyc-service              | [otel.javaagent 2025-10-03 16:11:18:558 +0000] [main] INFO io.opentelemetry.javaagent.tooling.VersionLogger - opentelemetry-javaagent - version: 2.15.0
account-service          | [otel.javaagent 2025-10-03 16:11:18:575 +0000] [main] INFO io.opentelemetry.javaagent.tooling.VersionLogger - opentelemetry-javaagent - version: 2.15.0
security-service         | [otel.javaagent 2025-10-03 16:11:19:165 +0000] [main] INFO io.opentelemetry.javaagent.tooling.VersionLogger - opentelemetry-javaagent - version: 2.15.0
bankapp                  | [otel.javaagent 2025-10-03 16:11:19:869 +0000] [main] INFO io.opentelemetry.javaagent.tooling.VersionLogger - opentelemetry-javaagent - version: 2.15.0
auth-statistics-service  | [otel.javaagent 2025-10-03 16:11:19:868 +0000] [main] INFO io.opentelemetry.javaagent.tooling.VersionLogger - opentelemetry-javaagent - version: 2.15.0
kyc-service_postgres     | performing post-bootstrap initialization ... ok
kafka                    | Picked up JAVA_TOOL_OPTIONS: 
kyc-service_postgres     | initdb: warning: enabling "trust" authentication for local connections
kyc-service_postgres     | initdb: hint: You can change this by editing pg_hba.conf or using the option -A, or --auth-local and --auth-host, the next time you run initdb.
kyc-service_postgres     | syncing data to disk ... ok
kyc-service_postgres     | 
kyc-service_postgres     | 
kyc-service_postgres     | Success. You can now start the database server using:
kyc-service_postgres     | 
kyc-service_postgres     |     pg_ctl -D /var/lib/postgresql/data -l logfile start
kyc-service_postgres     | 
kyc-service_postgres     | waiting for server to start....2025-10-03 16:11:21.603 UTC [50] LOG:  starting PostgreSQL 15.14 (Debian 15.14-1.pgdg13+1) on aarch64-unknown-linux-gnu, compiled by gcc (Debian 14.2.0-19) 14.2.0, 64-bit
kyc-service_postgres     | 2025-10-03 16:11:21.618 UTC [50] LOG:  listening on Unix socket "/var/run/postgresql/.s.PGSQL.5432"
kyc-service_postgres     | 2025-10-03 16:11:21.686 UTC [53] LOG:  database system was shut down at 2025-10-03 16:11:20 UTC
kyc-service_postgres     | 2025-10-03 16:11:21.804 UTC [50] LOG:  database system is ready to accept connections
kyc-service_postgres     |  done
kyc-service_postgres     | server started
minio                    | INFO: 
minio                    |  You are running an older version of MinIO released 1 month before the latest release 
minio                    |  Update: Run `mc admin update ALIAS` 
minio                    | 
minio                    | 
kyc-service_postgres     | CREATE DATABASE
kyc-service_postgres     | 
kyc-service_postgres     | 
kyc-service_postgres     | /usr/local/bin/docker-entrypoint.sh: ignoring /docker-entrypoint-initdb.d/*
kyc-service_postgres     | 
kyc-service_postgres     | waiting for server to shut down....2025-10-03 16:11:24.147 UTC [50] LOG:  received fast shutdown request
kyc-service_postgres     | 2025-10-03 16:11:24.155 UTC [50] LOG:  aborting any active transactions
minio                    | MinIO Object Storage Server
minio                    | Copyright: 2015-2025 MinIO, Inc.
minio                    | License: GNU AGPLv3 - https://www.gnu.org/licenses/agpl-3.0.html
minio                    | Version: RELEASE.2025-07-23T15-54-02Z (go1.24.5 linux/arm64)
minio                    | 
minio                    | API: http://172.18.0.2:9000  http://127.0.0.1:9000 
minio                    | WebUI: http://172.18.0.2:9001 http://127.0.0.1:9001  
minio                    | 
minio                    | Docs: https://docs.min.io
minio                    | WARN: Detected default credentials 'minioadmin:minioadmin', we recommend that you change these values with 'MINIO_ROOT_USER' and 'MINIO_ROOT_PASSWORD' environment variables
kyc-service_postgres     | 2025-10-03 16:11:24.190 UTC [50] LOG:  background worker "logical replication launcher" (PID 56) exited with exit code 1
kyc-service_postgres     | 2025-10-03 16:11:24.220 UTC [51] LOG:  shutting down
kyc-service_postgres     | 2025-10-03 16:11:24.230 UTC [51] LOG:  checkpoint starting: shutdown immediate
kyc-service_postgres     | 2025-10-03 16:11:24.619 UTC [51] LOG:  checkpoint complete: wrote 922 buffers (5.6%); 0 WAL file(s) added, 0 removed, 0 recycled; write=0.289 s, sync=0.084 s, total=0.398 s; sync files=301, longest=0.007 s, average=0.001 s; distance=4239 kB, estimate=4239 kB
kyc-service_postgres     | 2025-10-03 16:11:24.656 UTC [50] LOG:  database system is shut down
kyc-service_postgres     |  done
kyc-service_postgres     | server stopped
kyc-service_postgres     | 
kyc-service_postgres     | PostgreSQL init process complete; ready for start up.
kyc-service_postgres     | 
kyc-service_postgres     | 2025-10-03 16:11:25.161 UTC [1] LOG:  starting PostgreSQL 15.14 (Debian 15.14-1.pgdg13+1) on aarch64-unknown-linux-gnu, compiled by gcc (Debian 14.2.0-19) 14.2.0, 64-bit
kyc-service_postgres     | 2025-10-03 16:11:25.171 UTC [1] LOG:  listening on IPv4 address "0.0.0.0", port 5432
kyc-service_postgres     | 2025-10-03 16:11:25.179 UTC [1] LOG:  listening on IPv6 address "::", port 5432
kyc-service_postgres     | 2025-10-03 16:11:25.195 UTC [1] LOG:  listening on Unix socket "/var/run/postgresql/.s.PGSQL.5432"
kyc-service_postgres     | 2025-10-03 16:11:25.271 UTC [66] LOG:  database system was shut down at 2025-10-03 16:11:24 UTC
kyc-service_postgres     | 2025-10-03 16:11:25.344 UTC [1] LOG:  database system is ready to accept connections
settings-service         | 
settings-service         |   .   ____          _            __ _ _
settings-service         |  /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \
settings-service         | ( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \
settings-service         |  \\/  ___)| |_)| | | | | || (_| |  ) ) ) )
settings-service         |   '  |____| .__|_| |_|_| |_\__, | / / / /
settings-service         |  =========|_|==============|___/=/_/_/_/
settings-service         | 
settings-service         |  :: Spring Boot ::                (v3.5.0)
settings-service         | 
kafka                    | All of the log directories are already formatted.
fraud-detection          | 
fraud-detection          |   .   ____          _            __ _ _
fraud-detection          |  /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \
fraud-detection          | ( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \
fraud-detection          |  \\/  ___)| |_)| | | | | || (_| |  ) ) ) )
fraud-detection          |   '  |____| .__|_| |_|_| |_\__, | / / / /
fraud-detection          |  =========|_|==============|___/=/_/_/_/
fraud-detection          | 
fraud-detection          |  :: Spring Boot ::                (v3.5.0)
fraud-detection          | 
notification-service     | 
notification-service     |   .   ____          _            __ _ _
notification-service     |  /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \
notification-service     | ( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \
notification-service     |  \\/  ___)| |_)| | | | | || (_| |  ) ) ) )
notification-service     |   '  |____| .__|_| |_|_| |_\__, | / / / /
notification-service     |  =========|_|==============|___/=/_/_/_/
notification-service     | 
settings-service         | 2025-10-03T16:11:32.893Z  INFO 1 --- [bank-shared] [           main] r.k.b.s.SettingsServiceApplication       : Starting SettingsServiceApplication v0.0.1-SNAPSHOT using Java 21.0.8 with PID 1 (/app/app.jar started by root in /app)
notification-service     |  :: Spring Boot ::                (v3.5.0)
notification-service     | 
settings-service         | 2025-10-03T16:11:32.945Z  INFO 1 --- [bank-shared] [           main] r.k.b.s.SettingsServiceApplication       : The following 1 profile is active: "docker"
kafka                    | 
kafka                    | [38;5;6mkafka [38;5;5m16:11:33.07 [0m[38;5;2mINFO [0m ==> ** Kafka setup finished! **
kafka                    | [38;5;6mkafka [38;5;5m16:11:33.16 [0m[38;5;2mINFO [0m ==> ** Starting Kafka **
api-gateway-1            | 
api-gateway-1            |   .   ____          _            __ _ _
api-gateway-1            |  /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \
api-gateway-1            | ( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \
api-gateway-1            |  \\/  ___)| |_)| | | | | || (_| |  ) ) ) )
api-gateway-1            |   '  |____| .__|_| |_|_| |_\__, | / / / /
api-gateway-1            |  =========|_|==============|___/=/_/_/_/
api-gateway-1            | 
api-gateway-1            |  :: Spring Boot ::                (v3.5.0)
api-gateway-1            | 
notification-service     | 2025-10-03T16:11:33.968Z  INFO 1 --- [bank-shared] [           main] r.k.n.NotificationServiceApplication     : Starting NotificationServiceApplication v0.0.1-SNAPSHOT using Java 21.0.8 with PID 1 (/app/app.jar started by root in /app)
notification-service     | 2025-10-03T16:11:34.004Z  INFO 1 --- [bank-shared] [           main] r.k.n.NotificationServiceApplication     : The following 1 profile is active: "docker"
fraud-detection          | 2025-10-03T16:11:33.974Z  INFO 1 --- [fraud-detection] [           main] r.k.b.f.FraudDetectionApplication        : Starting FraudDetectionApplication v0.0.1-SNAPSHOT using Java 21.0.8 with PID 1 (/app/app.jar started by root in /app)
fraud-detection          | 2025-10-03T16:11:34.036Z  INFO 1 --- [fraud-detection] [           main] r.k.b.f.FraudDetectionApplication        : No active profile set, falling back to 1 default profile: "default"
kafka                    | Picked up JAVA_TOOL_OPTIONS: 
api-gateway-1            | 2025-10-03T16:11:36.112Z  INFO 1 --- [api-gateway] [           main] r.k.apigateway.ApiGatewayApplication     : Starting ApiGatewayApplication v0.0.1-SNAPSHOT using Java 21.0.8 with PID 1 (/app.jar started by root in /)
api-gateway-1            | 2025-10-03T16:11:36.331Z  INFO 1 --- [api-gateway] [           main] r.k.apigateway.ApiGatewayApplication     : No active profile set, falling back to 1 default profile: "default"
kafka                    | [2025-10-03 16:11:39,077] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
kafka                    | [2025-10-03 16:11:39,821] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
kafka                    | [2025-10-03 16:11:40,545] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
kafka                    | [2025-10-03 16:11:40,560] INFO [ControllerServer id=1] Starting controller (kafka.server.ControllerServer)
kafka                    | [2025-10-03 16:11:40,636] INFO authorizerStart completed for endpoint CONTROLLER. Endpoint is now READY. (org.apache.kafka.server.network.EndpointReadyFutures)
kafka                    | [2025-10-03 16:11:42,510] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
kafka                    | [2025-10-03 16:11:42,770] INFO [SocketServer listenerType=CONTROLLER, nodeId=1] Created data-plane acceptor and processors for endpoint : ListenerName(CONTROLLER) (kafka.network.SocketServer)
kafka                    | [2025-10-03 16:11:42,819] INFO [SharedServer id=1] Starting SharedServer (kafka.server.SharedServer)
kafka                    | [2025-10-03 16:11:43,506] INFO [LogLoader partition=__cluster_metadata-0, dir=/bitnami/kafka/data] Recovering unflushed segment 216868. 0/2 recovered for __cluster_metadata-0. (kafka.log.LogLoader)
kafka                    | [2025-10-03 16:11:43,542] INFO [LogLoader partition=__cluster_metadata-0, dir=/bitnami/kafka/data] Loading producer state till offset 216868 with message format version 2 (kafka.log.UnifiedLog$)
kafka                    | [2025-10-03 16:11:43,543] INFO [LogLoader partition=__cluster_metadata-0, dir=/bitnami/kafka/data] Reloading from producer snapshot and rebuilding producer state from offset 216868 (kafka.log.UnifiedLog$)
kafka                    | [2025-10-03 16:11:43,557] INFO Deleted producer state snapshot /bitnami/kafka/data/__cluster_metadata-0/00000000000000245566.snapshot (org.apache.kafka.storage.internals.log.SnapshotFile)
kafka                    | [2025-10-03 16:11:43,557] INFO Deleted producer state snapshot /bitnami/kafka/data/__cluster_metadata-0/00000000000000246045.snapshot (org.apache.kafka.storage.internals.log.SnapshotFile)
kafka                    | [2025-10-03 16:11:43,660] INFO [ProducerStateManager partition=__cluster_metadata-0]Wrote producer snapshot at offset 216868 with 0 producer ids in 47 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
kafka                    | [2025-10-03 16:11:43,660] INFO [LogLoader partition=__cluster_metadata-0, dir=/bitnami/kafka/data] Producer state recovery took 14ms for snapshot load and 103ms for segment recovery from offset 216868 (kafka.log.UnifiedLog$)
kafka                    | [2025-10-03 16:11:45,497] INFO [ProducerStateManager partition=__cluster_metadata-0]Wrote producer snapshot at offset 245566 with 0 producer ids in 41 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
kafka                    | [2025-10-03 16:11:45,504] INFO [LogLoader partition=__cluster_metadata-0, dir=/bitnami/kafka/data] Recovering unflushed segment 245566. 1/2 recovered for __cluster_metadata-0. (kafka.log.LogLoader)
kafka                    | [2025-10-03 16:11:45,520] INFO [LogLoader partition=__cluster_metadata-0, dir=/bitnami/kafka/data] Loading producer state till offset 245566 with message format version 2 (kafka.log.UnifiedLog$)
kafka                    | [2025-10-03 16:11:45,545] INFO [LogLoader partition=__cluster_metadata-0, dir=/bitnami/kafka/data] Reloading from producer snapshot and rebuilding producer state from offset 245566 (kafka.log.UnifiedLog$)
kafka                    | [2025-10-03 16:11:45,577] INFO [ProducerStateManager partition=__cluster_metadata-0]Loading producer state from snapshot file 'SnapshotFile(offset=245566, file=/bitnami/kafka/data/__cluster_metadata-0/00000000000000245566.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
kafka                    | [2025-10-03 16:11:45,658] INFO [LogLoader partition=__cluster_metadata-0, dir=/bitnami/kafka/data] Producer state recovery took 113ms for snapshot load and 0ms for segment recovery from offset 245566 (kafka.log.UnifiedLog$)
kafka                    | [2025-10-03 16:11:45,697] INFO [ProducerStateManager partition=__cluster_metadata-0]Wrote producer snapshot at offset 246045 with 0 producer ids in 18 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
kafka                    | [2025-10-03 16:11:45,847] INFO [LogLoader partition=__cluster_metadata-0, dir=/bitnami/kafka/data] Loading producer state till offset 246045 with message format version 2 (kafka.log.UnifiedLog$)
kafka                    | [2025-10-03 16:11:45,847] INFO [LogLoader partition=__cluster_metadata-0, dir=/bitnami/kafka/data] Reloading from producer snapshot and rebuilding producer state from offset 246045 (kafka.log.UnifiedLog$)
kafka                    | [2025-10-03 16:11:45,849] INFO Deleted producer state snapshot /bitnami/kafka/data/__cluster_metadata-0/00000000000000216868.snapshot (org.apache.kafka.storage.internals.log.SnapshotFile)
kafka                    | [2025-10-03 16:11:45,849] INFO [ProducerStateManager partition=__cluster_metadata-0]Loading producer state from snapshot file 'SnapshotFile(offset=246045, file=/bitnami/kafka/data/__cluster_metadata-0/00000000000000246045.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
kafka                    | [2025-10-03 16:11:45,849] INFO [LogLoader partition=__cluster_metadata-0, dir=/bitnami/kafka/data] Producer state recovery took 2ms for snapshot load and 0ms for segment recovery from offset 246045 (kafka.log.UnifiedLog$)
kafka                    | [2025-10-03 16:11:46,429] INFO Initialized snapshots with IDs Set(OffsetAndEpoch(offset=243696, epoch=89)) from /bitnami/kafka/data/__cluster_metadata-0 (kafka.raft.KafkaMetadataLog$)
kafka                    | [2025-10-03 16:11:46,654] INFO [raft-expiration-reaper]: Starting (kafka.raft.TimingWheelExpirationService$ExpiredOperationReaper)
kafka                    | [2025-10-03 16:11:48,024] INFO [RaftManager id=1] Completed transition to ResignedState(localId=1, epoch=90, voters=[1], electionTimeoutMs=1525, unackedVoters=[], preferredSuccessors=[]) from null (org.apache.kafka.raft.QuorumState)
kafka                    | [2025-10-03 16:11:48,054] INFO [RaftManager id=1] Completed transition to CandidateState(localId=1, epoch=91, retries=1, voteStates={1=GRANTED}, highWatermark=Optional.empty, electionTimeoutMs=1324) from ResignedState(localId=1, epoch=90, voters=[1], electionTimeoutMs=1525, unackedVoters=[], preferredSuccessors=[]) (org.apache.kafka.raft.QuorumState)
kafka                    | [2025-10-03 16:11:48,115] INFO [RaftManager id=1] Completed transition to Leader(localId=1, epoch=91, epochStartOffset=246045, highWatermark=Optional.empty, voterStates={1=ReplicaState(nodeId=1, endOffset=Optional.empty, lastFetchTimestamp=-1, lastCaughtUpTimestamp=-1, hasAcknowledgedLeader=true)}) from CandidateState(localId=1, epoch=91, retries=1, voteStates={1=GRANTED}, highWatermark=Optional.empty, electionTimeoutMs=1324) (org.apache.kafka.raft.QuorumState)
kafka                    | [2025-10-03 16:11:48,349] INFO [kafka-1-raft-outbound-request-thread]: Starting (kafka.raft.RaftSendThread)
kafka                    | [2025-10-03 16:11:48,350] INFO [kafka-1-raft-io-thread]: Starting (kafka.raft.KafkaRaftManager$RaftIoThread)
notification-service     | 2025-10-03T16:11:48.546Z  INFO 1 --- [bank-shared] [           main] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data JPA repositories in DEFAULT mode.
kafka                    | [2025-10-03 16:11:48,717] INFO [MetadataLoader id=1] initializeNewPublishers: The loader is still catching up because we have loaded up to offset -1, but the high water mark is 246046 (org.apache.kafka.image.loader.MetadataLoader)
kafka                    | [2025-10-03 16:11:48,724] INFO [ControllerServer id=1] Waiting for controller quorum voters future (kafka.server.ControllerServer)
kafka                    | [2025-10-03 16:11:48,724] INFO [ControllerServer id=1] Finished waiting for controller quorum voters future (kafka.server.ControllerServer)
kafka                    | [2025-10-03 16:11:48,731] INFO [RaftManager id=1] High watermark set to LogOffsetMetadata(offset=246046, metadata=Optional[(segmentBaseOffset=245566,relativePositionInSegment=30521)]) for the first time for epoch 91 based on indexOfHw 0 and voters [ReplicaState(nodeId=1, endOffset=Optional[LogOffsetMetadata(offset=246046, metadata=Optional[(segmentBaseOffset=245566,relativePositionInSegment=30521)])], lastFetchTimestamp=-1, lastCaughtUpTimestamp=-1, hasAcknowledgedLeader=true)] (org.apache.kafka.raft.LeaderState)
kafka                    | [2025-10-03 16:11:48,827] INFO [MetadataLoader id=1] initializeNewPublishers: The loader is still catching up because we have loaded up to offset -1, but the high water mark is 246046 (org.apache.kafka.image.loader.MetadataLoader)
kafka                    | [2025-10-03 16:11:48,914] INFO [RaftManager id=1] Registered the listener org.apache.kafka.image.loader.MetadataLoader@724237426 (org.apache.kafka.raft.KafkaRaftClient)
kafka                    | [2025-10-03 16:11:48,935] INFO [MetadataLoader id=1] initializeNewPublishers: The loader is still catching up because we have loaded up to offset -1, but the high water mark is 246046 (org.apache.kafka.image.loader.MetadataLoader)
notification-service     | 2025-10-03T16:11:48.976Z  INFO 1 --- [bank-shared] [           main] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 337 ms. Found 1 JPA repository interface.
kafka                    | [2025-10-03 16:11:49,000] INFO [MetadataLoader id=1] handleLoadSnapshot(00000000000000243696-0000000089): incrementing HandleLoadSnapshotCount to 1. (org.apache.kafka.image.loader.MetadataLoader)
kafka                    | [2025-10-03 16:11:49,184] INFO [QuorumController id=1] Creating new QuorumController with clusterId E51KSUCrSmm3AwlJhhuHuQ. (org.apache.kafka.controller.QuorumController)
kafka                    | [2025-10-03 16:11:49,188] INFO [RaftManager id=1] Registered the listener org.apache.kafka.controller.QuorumController$QuorumMetaLogListener@156727252 (org.apache.kafka.raft.KafkaRaftClient)
kafka                    | [2025-10-03 16:11:49,217] INFO [QuorumController id=1] Starting to load snapshot 00000000000000243696-0000000089. Previous lastCommittedOffset was -1. Previous transactionStartOffset was -1. (org.apache.kafka.controller.OffsetControlManager)
kafka                    | [2025-10-03 16:11:49,234] INFO [QuorumController id=1] Replayed a FeatureLevelRecord setting metadata version to 3.6-IV2 (org.apache.kafka.controller.FeatureControlManager)
kafka                    | [2025-10-03 16:11:49,254] INFO [QuorumController id=1] Replayed initial RegisterBrokerRecord for broker 1: RegisterBrokerRecord(brokerId=1, isMigratingZkBroker=false, incarnationId=J_wFFEOTTf-31iWd8YwAjA, brokerEpoch=236469, endPoints=[BrokerEndpoint(name='EXTERNAL', host='localhost', port=9094, securityProtocol=0), BrokerEndpoint(name='PLAINTEXT', host='kafka', port=9092, securityProtocol=0)], features=[BrokerFeature(name='metadata.version', minSupportedVersion=1, maxSupportedVersion=14)], rack=null, fenced=false, inControlledShutdown=false) (org.apache.kafka.controller.ClusterControlManager)
kafka                    | [2025-10-03 16:11:49,266] INFO [QuorumController id=1] Replayed TopicRecord for topic user.registered with topic ID wA1qIfWQTdGjFnyrGcxRuQ. (org.apache.kafka.controller.ReplicationControlManager)
kafka                    | [2025-10-03 16:11:49,267] INFO [QuorumController id=1] Replayed PartitionRecord for new partition user.registered-0 with topic ID wA1qIfWQTdGjFnyrGcxRuQ and PartitionRegistration(replicas=[1], isr=[1], removingReplicas=[], addingReplicas=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=166, partitionEpoch=166). (org.apache.kafka.controller.ReplicationControlManager)
kafka                    | [2025-10-03 16:11:49,273] INFO [QuorumController id=1] Replayed TopicRecord for topic kyc-events with topic ID xrkFKQ2_RwCJqp4b4WCWXQ. (org.apache.kafka.controller.ReplicationControlManager)
kafka                    | [2025-10-03 16:11:49,278] INFO [QuorumController id=1] Replayed PartitionRecord for new partition kyc-events-0 with topic ID xrkFKQ2_RwCJqp4b4WCWXQ and PartitionRegistration(replicas=[1], isr=[1], removingReplicas=[], addingReplicas=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=20, partitionEpoch=20). (org.apache.kafka.controller.ReplicationControlManager)
kafka                    | [2025-10-03 16:11:49,279] INFO [QuorumController id=1] Replayed TopicRecord for topic transfer.completed with topic ID KnRdX7QnQJmUANpwxqvSDg. (org.apache.kafka.controller.ReplicationControlManager)
kafka                    | [2025-10-03 16:11:49,279] INFO [QuorumController id=1] Replayed PartitionRecord for new partition transfer.completed-0 with topic ID KnRdX7QnQJmUANpwxqvSDg and PartitionRegistration(replicas=[1], isr=[1], removingReplicas=[], addingReplicas=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=166, partitionEpoch=166). (org.apache.kafka.controller.ReplicationControlManager)
kafka                    | [2025-10-03 16:11:49,279] INFO [QuorumController id=1] Replayed TopicRecord for topic transfer-completed-events with topic ID ltyY2IODSnCcb9DcVhT46A. (org.apache.kafka.controller.ReplicationControlManager)
kafka                    | [2025-10-03 16:11:49,280] INFO [QuorumController id=1] Replayed PartitionRecord for new partition transfer-completed-events-0 with topic ID ltyY2IODSnCcb9DcVhT46A and PartitionRegistration(replicas=[1], isr=[1], removingReplicas=[], addingReplicas=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=166, partitionEpoch=166). (org.apache.kafka.controller.ReplicationControlManager)
kafka                    | [2025-10-03 16:11:49,280] INFO [QuorumController id=1] Replayed TopicRecord for topic __consumer_offsets with topic ID iNBYdjYeRpSCdVw9OvuAgQ. (org.apache.kafka.controller.ReplicationControlManager)
kafka                    | [2025-10-03 16:11:49,280] INFO [QuorumController id=1] Replayed PartitionRecord for new partition __consumer_offsets-0 with topic ID iNBYdjYeRpSCdVw9OvuAgQ and PartitionRegistration(replicas=[1], isr=[1], removingReplicas=[], addingReplicas=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=166, partitionEpoch=166). (org.apache.kafka.controller.ReplicationControlManager)
kafka                    | [2025-10-03 16:11:49,282] INFO [QuorumController id=1] Replayed PartitionRecord for new partition __consumer_offsets-1 with topic ID iNBYdjYeRpSCdVw9OvuAgQ and PartitionRegistration(replicas=[1], isr=[1], removingReplicas=[], addingReplicas=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=166, partitionEpoch=166). (org.apache.kafka.controller.ReplicationControlManager)
kafka                    | [2025-10-03 16:11:49,284] INFO [QuorumController id=1] Replayed PartitionRecord for new partition __consumer_offsets-2 with topic ID iNBYdjYeRpSCdVw9OvuAgQ and PartitionRegistration(replicas=[1], isr=[1], removingReplicas=[], addingReplicas=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=166, partitionEpoch=166). (org.apache.kafka.controller.ReplicationControlManager)
kafka                    | [2025-10-03 16:11:49,285] INFO [QuorumController id=1] Replayed PartitionRecord for new partition __consumer_offsets-3 with topic ID iNBYdjYeRpSCdVw9OvuAgQ and PartitionRegistration(replicas=[1], isr=[1], removingReplicas=[], addingReplicas=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=166, partitionEpoch=166). (org.apache.kafka.controller.ReplicationControlManager)
kafka                    | [2025-10-03 16:11:49,286] INFO [QuorumController id=1] Replayed PartitionRecord for new partition __consumer_offsets-4 with topic ID iNBYdjYeRpSCdVw9OvuAgQ and PartitionRegistration(replicas=[1], isr=[1], removingReplicas=[], addingReplicas=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=166, partitionEpoch=166). (org.apache.kafka.controller.ReplicationControlManager)
kafka                    | [2025-10-03 16:11:49,288] INFO [QuorumController id=1] Replayed PartitionRecord for new partition __consumer_offsets-5 with topic ID iNBYdjYeRpSCdVw9OvuAgQ and PartitionRegistration(replicas=[1], isr=[1], removingReplicas=[], addingReplicas=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=166, partitionEpoch=166). (org.apache.kafka.controller.ReplicationControlManager)
kafka                    | [2025-10-03 16:11:49,290] INFO [QuorumController id=1] Replayed PartitionRecord for new partition __consumer_offsets-6 with topic ID iNBYdjYeRpSCdVw9OvuAgQ and PartitionRegistration(replicas=[1], isr=[1], removingReplicas=[], addingReplicas=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=166, partitionEpoch=166). (org.apache.kafka.controller.ReplicationControlManager)
kafka                    | [2025-10-03 16:11:49,290] INFO [QuorumController id=1] Replayed PartitionRecord for new partition __consumer_offsets-7 with topic ID iNBYdjYeRpSCdVw9OvuAgQ and PartitionRegistration(replicas=[1], isr=[1], removingReplicas=[], addingReplicas=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=166, partitionEpoch=166). (org.apache.kafka.controller.ReplicationControlManager)
kafka                    | [2025-10-03 16:11:49,293] INFO [QuorumController id=1] Replayed PartitionRecord for new partition __consumer_offsets-8 with topic ID iNBYdjYeRpSCdVw9OvuAgQ and PartitionRegistration(replicas=[1], isr=[1], removingReplicas=[], addingReplicas=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=166, partitionEpoch=166). (org.apache.kafka.controller.ReplicationControlManager)
kafka                    | [2025-10-03 16:11:49,297] INFO [QuorumController id=1] Replayed PartitionRecord for new partition __consumer_offsets-9 with topic ID iNBYdjYeRpSCdVw9OvuAgQ and PartitionRegistration(replicas=[1], isr=[1], removingReplicas=[], addingReplicas=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=166, partitionEpoch=166). (org.apache.kafka.controller.ReplicationControlManager)
kafka                    | [2025-10-03 16:11:49,277] INFO [MetadataLoader id=1] handleLoadSnapshot(00000000000000243696-0000000089): generated a metadata delta between offset -1 and this snapshot in 273208 us. (org.apache.kafka.image.loader.MetadataLoader)
kafka                    | [2025-10-03 16:11:49,301] INFO [QuorumController id=1] Replayed PartitionRecord for new partition __consumer_offsets-10 with topic ID iNBYdjYeRpSCdVw9OvuAgQ and PartitionRegistration(replicas=[1], isr=[1], removingReplicas=[], addingReplicas=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=166, partitionEpoch=166). (org.apache.kafka.controller.ReplicationControlManager)
kafka                    | [2025-10-03 16:11:49,287] INFO [controller-1-ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
kafka                    | [2025-10-03 16:11:49,302] INFO [QuorumController id=1] Replayed PartitionRecord for new partition __consumer_offsets-11 with topic ID iNBYdjYeRpSCdVw9OvuAgQ and PartitionRegistration(replicas=[1], isr=[1], removingReplicas=[], addingReplicas=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=166, partitionEpoch=166). (org.apache.kafka.controller.ReplicationControlManager)
kafka                    | [2025-10-03 16:11:49,302] INFO [QuorumController id=1] Replayed PartitionRecord for new partition __consumer_offsets-12 with topic ID iNBYdjYeRpSCdVw9OvuAgQ and PartitionRegistration(replicas=[1], isr=[1], removingReplicas=[], addingReplicas=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=166, partitionEpoch=166). (org.apache.kafka.controller.ReplicationControlManager)
kafka                    | [2025-10-03 16:11:49,304] INFO [QuorumController id=1] Replayed PartitionRecord for new partition __consumer_offsets-13 with topic ID iNBYdjYeRpSCdVw9OvuAgQ and PartitionRegistration(replicas=[1], isr=[1], removingReplicas=[], addingReplicas=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=166, partitionEpoch=166). (org.apache.kafka.controller.ReplicationControlManager)
kafka                    | [2025-10-03 16:11:49,311] INFO [QuorumController id=1] Replayed PartitionRecord for new partition __consumer_offsets-14 with topic ID iNBYdjYeRpSCdVw9OvuAgQ and PartitionRegistration(replicas=[1], isr=[1], removingReplicas=[], addingReplicas=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=166, partitionEpoch=166). (org.apache.kafka.controller.ReplicationControlManager)
kafka                    | [2025-10-03 16:11:49,312] INFO [QuorumController id=1] Replayed PartitionRecord for new partition __consumer_offsets-15 with topic ID iNBYdjYeRpSCdVw9OvuAgQ and PartitionRegistration(replicas=[1], isr=[1], removingReplicas=[], addingReplicas=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=166, partitionEpoch=166). (org.apache.kafka.controller.ReplicationControlManager)
kafka                    | [2025-10-03 16:11:49,313] INFO [QuorumController id=1] Replayed PartitionRecord for new partition __consumer_offsets-16 with topic ID iNBYdjYeRpSCdVw9OvuAgQ and PartitionRegistration(replicas=[1], isr=[1], removingReplicas=[], addingReplicas=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=166, partitionEpoch=166). (org.apache.kafka.controller.ReplicationControlManager)
kafka                    | [2025-10-03 16:11:49,313] INFO [QuorumController id=1] Replayed PartitionRecord for new partition __consumer_offsets-17 with topic ID iNBYdjYeRpSCdVw9OvuAgQ and PartitionRegistration(replicas=[1], isr=[1], removingReplicas=[], addingReplicas=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=166, partitionEpoch=166). (org.apache.kafka.controller.ReplicationControlManager)
kafka                    | [2025-10-03 16:11:49,313] INFO [QuorumController id=1] Replayed PartitionRecord for new partition __consumer_offsets-18 with topic ID iNBYdjYeRpSCdVw9OvuAgQ and PartitionRegistration(replicas=[1], isr=[1], removingReplicas=[], addingReplicas=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=166, partitionEpoch=166). (org.apache.kafka.controller.ReplicationControlManager)
kafka                    | [2025-10-03 16:11:49,314] INFO [QuorumController id=1] Replayed PartitionRecord for new partition __consumer_offsets-19 with topic ID iNBYdjYeRpSCdVw9OvuAgQ and PartitionRegistration(replicas=[1], isr=[1], removingReplicas=[], addingReplicas=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=166, partitionEpoch=166). (org.apache.kafka.controller.ReplicationControlManager)
kafka                    | [2025-10-03 16:11:49,314] INFO [QuorumController id=1] Replayed PartitionRecord for new partition __consumer_offsets-20 with topic ID iNBYdjYeRpSCdVw9OvuAgQ and PartitionRegistration(replicas=[1], isr=[1], removingReplicas=[], addingReplicas=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=166, partitionEpoch=166). (org.apache.kafka.controller.ReplicationControlManager)
kafka                    | [2025-10-03 16:11:49,314] INFO [QuorumController id=1] Replayed PartitionRecord for new partition __consumer_offsets-21 with topic ID iNBYdjYeRpSCdVw9OvuAgQ and PartitionRegistration(replicas=[1], isr=[1], removingReplicas=[], addingReplicas=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=166, partitionEpoch=166). (org.apache.kafka.controller.ReplicationControlManager)
kafka                    | [2025-10-03 16:11:49,314] INFO [QuorumController id=1] Replayed PartitionRecord for new partition __consumer_offsets-22 with topic ID iNBYdjYeRpSCdVw9OvuAgQ and PartitionRegistration(replicas=[1], isr=[1], removingReplicas=[], addingReplicas=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=166, partitionEpoch=166). (org.apache.kafka.controller.ReplicationControlManager)
kafka                    | [2025-10-03 16:11:49,314] INFO [QuorumController id=1] Replayed PartitionRecord for new partition __consumer_offsets-23 with topic ID iNBYdjYeRpSCdVw9OvuAgQ and PartitionRegistration(replicas=[1], isr=[1], removingReplicas=[], addingReplicas=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=166, partitionEpoch=166). (org.apache.kafka.controller.ReplicationControlManager)
kafka                    | [2025-10-03 16:11:49,314] INFO [QuorumController id=1] Replayed PartitionRecord for new partition __consumer_offsets-24 with topic ID iNBYdjYeRpSCdVw9OvuAgQ and PartitionRegistration(replicas=[1], isr=[1], removingReplicas=[], addingReplicas=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=166, partitionEpoch=166). (org.apache.kafka.controller.ReplicationControlManager)
kafka                    | [2025-10-03 16:11:49,314] INFO [QuorumController id=1] Replayed PartitionRecord for new partition __consumer_offsets-25 with topic ID iNBYdjYeRpSCdVw9OvuAgQ and PartitionRegistration(replicas=[1], isr=[1], removingReplicas=[], addingReplicas=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=166, partitionEpoch=166). (org.apache.kafka.controller.ReplicationControlManager)
kafka                    | [2025-10-03 16:11:49,305] INFO [controller-1-ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
kafka                    | [2025-10-03 16:11:49,318] INFO [QuorumController id=1] Replayed PartitionRecord for new partition __consumer_offsets-26 with topic ID iNBYdjYeRpSCdVw9OvuAgQ and PartitionRegistration(replicas=[1], isr=[1], removingReplicas=[], addingReplicas=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=166, partitionEpoch=166). (org.apache.kafka.controller.ReplicationControlManager)
kafka                    | [2025-10-03 16:11:49,320] INFO [QuorumController id=1] Replayed PartitionRecord for new partition __consumer_offsets-27 with topic ID iNBYdjYeRpSCdVw9OvuAgQ and PartitionRegistration(replicas=[1], isr=[1], removingReplicas=[], addingReplicas=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=166, partitionEpoch=166). (org.apache.kafka.controller.ReplicationControlManager)
kafka                    | [2025-10-03 16:11:49,321] INFO [QuorumController id=1] Replayed PartitionRecord for new partition __consumer_offsets-28 with topic ID iNBYdjYeRpSCdVw9OvuAgQ and PartitionRegistration(replicas=[1], isr=[1], removingReplicas=[], addingReplicas=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=166, partitionEpoch=166). (org.apache.kafka.controller.ReplicationControlManager)
kafka                    | [2025-10-03 16:11:49,322] INFO [QuorumController id=1] Replayed PartitionRecord for new partition __consumer_offsets-29 with topic ID iNBYdjYeRpSCdVw9OvuAgQ and PartitionRegistration(replicas=[1], isr=[1], removingReplicas=[], addingReplicas=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=166, partitionEpoch=166). (org.apache.kafka.controller.ReplicationControlManager)
kafka                    | [2025-10-03 16:11:49,323] INFO [QuorumController id=1] Replayed PartitionRecord for new partition __consumer_offsets-30 with topic ID iNBYdjYeRpSCdVw9OvuAgQ and PartitionRegistration(replicas=[1], isr=[1], removingReplicas=[], addingReplicas=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=166, partitionEpoch=166). (org.apache.kafka.controller.ReplicationControlManager)
kafka                    | [2025-10-03 16:11:49,323] INFO [QuorumController id=1] Replayed PartitionRecord for new partition __consumer_offsets-31 with topic ID iNBYdjYeRpSCdVw9OvuAgQ and PartitionRegistration(replicas=[1], isr=[1], removingReplicas=[], addingReplicas=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=166, partitionEpoch=166). (org.apache.kafka.controller.ReplicationControlManager)
kafka                    | [2025-10-03 16:11:49,323] INFO [QuorumController id=1] Replayed PartitionRecord for new partition __consumer_offsets-32 with topic ID iNBYdjYeRpSCdVw9OvuAgQ and PartitionRegistration(replicas=[1], isr=[1], removingReplicas=[], addingReplicas=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=166, partitionEpoch=166). (org.apache.kafka.controller.ReplicationControlManager)
kafka                    | [2025-10-03 16:11:49,324] INFO [QuorumController id=1] Replayed PartitionRecord for new partition __consumer_offsets-33 with topic ID iNBYdjYeRpSCdVw9OvuAgQ and PartitionRegistration(replicas=[1], isr=[1], removingReplicas=[], addingReplicas=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=166, partitionEpoch=166). (org.apache.kafka.controller.ReplicationControlManager)
kafka                    | [2025-10-03 16:11:49,324] INFO [QuorumController id=1] Replayed PartitionRecord for new partition __consumer_offsets-34 with topic ID iNBYdjYeRpSCdVw9OvuAgQ and PartitionRegistration(replicas=[1], isr=[1], removingReplicas=[], addingReplicas=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=166, partitionEpoch=166). (org.apache.kafka.controller.ReplicationControlManager)
kafka                    | [2025-10-03 16:11:49,325] INFO [QuorumController id=1] Replayed PartitionRecord for new partition __consumer_offsets-35 with topic ID iNBYdjYeRpSCdVw9OvuAgQ and PartitionRegistration(replicas=[1], isr=[1], removingReplicas=[], addingReplicas=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=166, partitionEpoch=166). (org.apache.kafka.controller.ReplicationControlManager)
kafka                    | [2025-10-03 16:11:49,326] INFO [QuorumController id=1] Replayed PartitionRecord for new partition __consumer_offsets-36 with topic ID iNBYdjYeRpSCdVw9OvuAgQ and PartitionRegistration(replicas=[1], isr=[1], removingReplicas=[], addingReplicas=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=166, partitionEpoch=166). (org.apache.kafka.controller.ReplicationControlManager)
kafka                    | [2025-10-03 16:11:49,326] INFO [QuorumController id=1] Replayed PartitionRecord for new partition __consumer_offsets-37 with topic ID iNBYdjYeRpSCdVw9OvuAgQ and PartitionRegistration(replicas=[1], isr=[1], removingReplicas=[], addingReplicas=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=166, partitionEpoch=166). (org.apache.kafka.controller.ReplicationControlManager)
kafka                    | [2025-10-03 16:11:49,326] INFO [QuorumController id=1] Replayed PartitionRecord for new partition __consumer_offsets-38 with topic ID iNBYdjYeRpSCdVw9OvuAgQ and PartitionRegistration(replicas=[1], isr=[1], removingReplicas=[], addingReplicas=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=166, partitionEpoch=166). (org.apache.kafka.controller.ReplicationControlManager)
kafka                    | [2025-10-03 16:11:49,326] INFO [QuorumController id=1] Replayed PartitionRecord for new partition __consumer_offsets-39 with topic ID iNBYdjYeRpSCdVw9OvuAgQ and PartitionRegistration(replicas=[1], isr=[1], removingReplicas=[], addingReplicas=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=166, partitionEpoch=166). (org.apache.kafka.controller.ReplicationControlManager)
kafka                    | [2025-10-03 16:11:49,327] INFO [QuorumController id=1] Replayed PartitionRecord for new partition __consumer_offsets-40 with topic ID iNBYdjYeRpSCdVw9OvuAgQ and PartitionRegistration(replicas=[1], isr=[1], removingReplicas=[], addingReplicas=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=166, partitionEpoch=166). (org.apache.kafka.controller.ReplicationControlManager)
kafka                    | [2025-10-03 16:11:49,327] INFO [QuorumController id=1] Replayed PartitionRecord for new partition __consumer_offsets-41 with topic ID iNBYdjYeRpSCdVw9OvuAgQ and PartitionRegistration(replicas=[1], isr=[1], removingReplicas=[], addingReplicas=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=166, partitionEpoch=166). (org.apache.kafka.controller.ReplicationControlManager)
kafka                    | [2025-10-03 16:11:49,327] INFO [QuorumController id=1] Replayed PartitionRecord for new partition __consumer_offsets-42 with topic ID iNBYdjYeRpSCdVw9OvuAgQ and PartitionRegistration(replicas=[1], isr=[1], removingReplicas=[], addingReplicas=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=166, partitionEpoch=166). (org.apache.kafka.controller.ReplicationControlManager)
kafka                    | [2025-10-03 16:11:49,327] INFO [QuorumController id=1] Replayed PartitionRecord for new partition __consumer_offsets-43 with topic ID iNBYdjYeRpSCdVw9OvuAgQ and PartitionRegistration(replicas=[1], isr=[1], removingReplicas=[], addingReplicas=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=166, partitionEpoch=166). (org.apache.kafka.controller.ReplicationControlManager)
kafka                    | [2025-10-03 16:11:49,327] INFO [QuorumController id=1] Replayed PartitionRecord for new partition __consumer_offsets-44 with topic ID iNBYdjYeRpSCdVw9OvuAgQ and PartitionRegistration(replicas=[1], isr=[1], removingReplicas=[], addingReplicas=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=166, partitionEpoch=166). (org.apache.kafka.controller.ReplicationControlManager)
kafka                    | [2025-10-03 16:11:49,327] INFO [QuorumController id=1] Replayed PartitionRecord for new partition __consumer_offsets-45 with topic ID iNBYdjYeRpSCdVw9OvuAgQ and PartitionRegistration(replicas=[1], isr=[1], removingReplicas=[], addingReplicas=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=166, partitionEpoch=166). (org.apache.kafka.controller.ReplicationControlManager)
kafka                    | [2025-10-03 16:11:49,328] INFO [QuorumController id=1] Replayed PartitionRecord for new partition __consumer_offsets-46 with topic ID iNBYdjYeRpSCdVw9OvuAgQ and PartitionRegistration(replicas=[1], isr=[1], removingReplicas=[], addingReplicas=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=166, partitionEpoch=166). (org.apache.kafka.controller.ReplicationControlManager)
kafka                    | [2025-10-03 16:11:49,328] INFO [QuorumController id=1] Replayed PartitionRecord for new partition __consumer_offsets-47 with topic ID iNBYdjYeRpSCdVw9OvuAgQ and PartitionRegistration(replicas=[1], isr=[1], removingReplicas=[], addingReplicas=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=166, partitionEpoch=166). (org.apache.kafka.controller.ReplicationControlManager)
kafka                    | [2025-10-03 16:11:49,328] INFO [QuorumController id=1] Replayed PartitionRecord for new partition __consumer_offsets-48 with topic ID iNBYdjYeRpSCdVw9OvuAgQ and PartitionRegistration(replicas=[1], isr=[1], removingReplicas=[], addingReplicas=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=166, partitionEpoch=166). (org.apache.kafka.controller.ReplicationControlManager)
kafka                    | [2025-10-03 16:11:49,328] INFO [QuorumController id=1] Replayed PartitionRecord for new partition __consumer_offsets-49 with topic ID iNBYdjYeRpSCdVw9OvuAgQ and PartitionRegistration(replicas=[1], isr=[1], removingReplicas=[], addingReplicas=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=166, partitionEpoch=166). (org.apache.kafka.controller.ReplicationControlManager)
kafka                    | [2025-10-03 16:11:49,328] INFO [QuorumController id=1] Replayed TopicRecord for topic password.changed with topic ID 7BTLLGtSRcaeR2BnI9Wd5g. (org.apache.kafka.controller.ReplicationControlManager)
kafka                    | [2025-10-03 16:11:49,328] INFO [QuorumController id=1] Replayed PartitionRecord for new partition password.changed-0 with topic ID 7BTLLGtSRcaeR2BnI9Wd5g and PartitionRegistration(replicas=[1], isr=[1], removingReplicas=[], addingReplicas=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=166, partitionEpoch=166). (org.apache.kafka.controller.ReplicationControlManager)
kafka                    | [2025-10-03 16:11:49,328] INFO [QuorumController id=1] Replayed TopicRecord for topic login-attempts-topic with topic ID C9qPgaLVTKmphRtrR47kPQ. (org.apache.kafka.controller.ReplicationControlManager)
kafka                    | [2025-10-03 16:11:49,328] INFO [QuorumController id=1] Replayed PartitionRecord for new partition login-attempts-topic-0 with topic ID C9qPgaLVTKmphRtrR47kPQ and PartitionRegistration(replicas=[1], isr=[1], removingReplicas=[], addingReplicas=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=166, partitionEpoch=166). (org.apache.kafka.controller.ReplicationControlManager)
kafka                    | [2025-10-03 16:11:49,329] INFO [QuorumController id=1] Replayed ConfigRecord for ConfigResource(type=TOPIC, name='__consumer_offsets') which set configuration compression.type to producer (org.apache.kafka.controller.ConfigurationControlManager)
kafka                    | [2025-10-03 16:11:49,329] INFO [MetadataLoader id=1] maybePublishMetadata(SNAPSHOT): The loader is still catching up because we have loaded up to offset 243695, but the high water mark is 246046 (org.apache.kafka.image.loader.MetadataLoader)
kafka                    | [2025-10-03 16:11:49,330] INFO [QuorumController id=1] Replayed ConfigRecord for ConfigResource(type=TOPIC, name='__consumer_offsets') which set configuration cleanup.policy to compact (org.apache.kafka.controller.ConfigurationControlManager)
kafka                    | [2025-10-03 16:11:49,331] INFO [QuorumController id=1] Replayed ConfigRecord for ConfigResource(type=TOPIC, name='__consumer_offsets') which set configuration segment.bytes to 104857600 (org.apache.kafka.controller.ConfigurationControlManager)
kafka                    | [2025-10-03 16:11:49,331] INFO [QuorumController id=1] Replaying ProducerIdsRecord ProducerIdsRecord(brokerId=-1, brokerEpoch=-1, nextProducerId=1000) (org.apache.kafka.controller.ProducerIdControlManager)
kafka                    | [2025-10-03 16:11:49,332] INFO [QuorumController id=1] Successfully loaded snapshot 00000000000000243696-0000000089. (org.apache.kafka.controller.OffsetControlManager)
kafka                    | [2025-10-03 16:11:49,331] INFO [MetadataLoader id=1] initializeNewPublishers: The loader is still catching up because we have loaded up to offset 243695, but the high water mark is 246046 (org.apache.kafka.image.loader.MetadataLoader)
kafka                    | [2025-10-03 16:11:49,349] INFO [controller-1-ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
kafka                    | [2025-10-03 16:11:49,385] INFO [controller-1-ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
kafka                    | [2025-10-03 16:11:49,682] INFO [QuorumController id=1] Replayed BrokerRegistrationChangeRecord modifying the registration for broker 1: BrokerRegistrationChangeRecord(brokerId=1, brokerEpoch=236469, fenced=0, inControlledShutdown=1) (org.apache.kafka.controller.ClusterControlManager)
kafka                    | [2025-10-03 16:11:49,724] INFO [QuorumController id=1] Replayed BrokerRegistrationChangeRecord modifying the registration for broker 1: BrokerRegistrationChangeRecord(brokerId=1, brokerEpoch=236469, fenced=1, inControlledShutdown=0) (org.apache.kafka.controller.ClusterControlManager)
kafka                    | [2025-10-03 16:11:49,746] INFO [QuorumController id=1] Replayed RegisterBrokerRecord establishing a new incarnation of broker 1: RegisterBrokerRecord(brokerId=1, isMigratingZkBroker=false, incarnationId=3wdz3-RxT3iGxg3XoCW6iQ, brokerEpoch=245577, endPoints=[BrokerEndpoint(name='PLAINTEXT', host='kafka', port=9092, securityProtocol=0), BrokerEndpoint(name='EXTERNAL', host='localhost', port=9094, securityProtocol=0)], features=[BrokerFeature(name='metadata.version', minSupportedVersion=1, maxSupportedVersion=14)], rack=null, fenced=true, inControlledShutdown=false) (org.apache.kafka.controller.ClusterControlManager)
settings-service         | 2025-10-03T16:11:49.744Z  INFO 1 --- [bank-shared] [           main] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data JPA repositories in DEFAULT mode.
kafka                    | [2025-10-03 16:11:49,750] INFO [QuorumController id=1] Replayed BrokerRegistrationChangeRecord modifying the registration for broker 1: BrokerRegistrationChangeRecord(brokerId=1, brokerEpoch=245577, fenced=-1, inControlledShutdown=0) (org.apache.kafka.controller.ClusterControlManager)
kafka                    | [2025-10-03 16:11:49,793] INFO [QuorumController id=1] Replayed BrokerRegistrationChangeRecord modifying the registration for broker 1: BrokerRegistrationChangeRecord(brokerId=1, brokerEpoch=245577, fenced=0, inControlledShutdown=1) (org.apache.kafka.controller.ClusterControlManager)
kafka                    | [2025-10-03 16:11:49,804] INFO [QuorumController id=1] Replayed BrokerRegistrationChangeRecord modifying the registration for broker 1: BrokerRegistrationChangeRecord(brokerId=1, brokerEpoch=245577, fenced=1, inControlledShutdown=0) (org.apache.kafka.controller.ClusterControlManager)
kafka                    | [2025-10-03 16:11:49,827] INFO [QuorumController id=1] Becoming the active controller at epoch 91, next write offset 246046. (org.apache.kafka.controller.QuorumController)
kafka                    | [2025-10-03 16:11:49,832] INFO [ExpirationReaper-1-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
kafka                    | [2025-10-03 16:11:49,878] WARN [QuorumController id=1] Performing controller activation. Loaded ZK migration state of NONE. (org.apache.kafka.controller.QuorumController)
kafka                    | [2025-10-03 16:11:50,367] INFO [MetadataLoader id=1] maybePublishMetadata(LOG_DELTA): The loader is still catching up because we have loaded up to offset 245565, but the high water mark is 246046 (org.apache.kafka.image.loader.MetadataLoader)
kafka                    | [2025-10-03 16:11:50,379] INFO [MetadataLoader id=1] initializeNewPublishers: The loader is still catching up because we have loaded up to offset 245565, but the high water mark is 246046 (org.apache.kafka.image.loader.MetadataLoader)
kafka                    | [2025-10-03 16:11:50,415] INFO [ControllerServer id=1] Waiting for the controller metadata publishers to be installed (kafka.server.ControllerServer)
kafka                    | [2025-10-03 16:11:50,421] INFO [MetadataLoader id=1] maybePublishMetadata(LOG_DELTA): The loader finished catching up to the current high water mark of 246046 (org.apache.kafka.image.loader.MetadataLoader)
kafka                    | [2025-10-03 16:11:50,427] INFO [ControllerServer id=1] Finished waiting for the controller metadata publishers to be installed (kafka.server.ControllerServer)
kafka                    | [2025-10-03 16:11:50,428] INFO [SocketServer listenerType=CONTROLLER, nodeId=1] Enabling request processing. (kafka.network.SocketServer)
kafka                    | [2025-10-03 16:11:50,440] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing SnapshotGenerator with a snapshot at offset 246045 (org.apache.kafka.image.loader.MetadataLoader)
kafka                    | [2025-10-03 16:11:50,451] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing FeaturesPublisher with a snapshot at offset 246045 (org.apache.kafka.image.loader.MetadataLoader)
kafka                    | [2025-10-03 16:11:50,451] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing DynamicConfigPublisher controller id=1 with a snapshot at offset 246045 (org.apache.kafka.image.loader.MetadataLoader)
kafka                    | [2025-10-03 16:11:50,460] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing DynamicClientQuotaPublisher controller id=1 with a snapshot at offset 246045 (org.apache.kafka.image.loader.MetadataLoader)
kafka                    | [2025-10-03 16:11:50,462] INFO Awaiting socket connections on 0.0.0.0:9093. (kafka.network.DataPlaneAcceptor)
kafka                    | [2025-10-03 16:11:50,464] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing ScramPublisher controller id=1 with a snapshot at offset 246045 (org.apache.kafka.image.loader.MetadataLoader)
kafka                    | [2025-10-03 16:11:50,472] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing DelegationTokenPublisher controller id=1 with a snapshot at offset 246045 (org.apache.kafka.image.loader.MetadataLoader)
kafka                    | [2025-10-03 16:11:50,477] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing ControllerMetadataMetricsPublisher with a snapshot at offset 246045 (org.apache.kafka.image.loader.MetadataLoader)
kafka                    | [2025-10-03 16:11:50,477] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing AclPublisher controller id=1 with a snapshot at offset 246045 (org.apache.kafka.image.loader.MetadataLoader)
settings-service         | 2025-10-03T16:11:50.485Z  INFO 1 --- [bank-shared] [           main] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 628 ms. Found 1 JPA repository interface.
kafka                    | [2025-10-03 16:11:50,491] INFO [ControllerServer id=1] Waiting for all of the authorizer futures to be completed (kafka.server.ControllerServer)
kafka                    | [2025-10-03 16:11:50,491] INFO [ControllerServer id=1] Finished waiting for all of the authorizer futures to be completed (kafka.server.ControllerServer)
kafka                    | [2025-10-03 16:11:50,491] INFO [ControllerServer id=1] Waiting for all of the SocketServer Acceptors to be started (kafka.server.ControllerServer)
kafka                    | [2025-10-03 16:11:50,491] INFO [ControllerServer id=1] Finished waiting for all of the SocketServer Acceptors to be started (kafka.server.ControllerServer)
kafka                    | [2025-10-03 16:11:50,493] INFO [BrokerServer id=1] Transition from SHUTDOWN to STARTING (kafka.server.BrokerServer)
kafka                    | [2025-10-03 16:11:50,496] INFO [BrokerServer id=1] Starting broker (kafka.server.BrokerServer)
kafka                    | [2025-10-03 16:11:50,535] INFO [broker-1-ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
kafka                    | [2025-10-03 16:11:50,536] INFO [broker-1-ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
kafka                    | [2025-10-03 16:11:50,537] INFO [broker-1-ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
kafka                    | [2025-10-03 16:11:50,540] INFO [broker-1-ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
account-service          | Standard Commons Logging discovery in action with spring-jcl: please remove commons-logging.jar from classpath in order to avoid potential conflicts
kafka                    | [2025-10-03 16:11:50,716] INFO [BrokerServer id=1] Waiting for controller quorum voters future (kafka.server.BrokerServer)
kafka                    | [2025-10-03 16:11:50,716] INFO [BrokerServer id=1] Finished waiting for controller quorum voters future (kafka.server.BrokerServer)
kafka                    | [2025-10-03 16:11:50,778] INFO [broker-1-to-controller-forwarding-channel-manager]: Starting (kafka.server.BrokerToControllerRequestThread)
kafka                    | [2025-10-03 16:11:50,780] INFO [broker-1-to-controller-forwarding-channel-manager]: Recorded new controller, from now on will use node kafka:9093 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
kafka                    | [2025-10-03 16:11:51,231] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
kafka                    | [2025-10-03 16:11:51,262] INFO [SocketServer listenerType=BROKER, nodeId=1] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
kafka                    | [2025-10-03 16:11:51,264] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
kafka                    | [2025-10-03 16:11:51,307] INFO [SocketServer listenerType=BROKER, nodeId=1] Created data-plane acceptor and processors for endpoint : ListenerName(EXTERNAL) (kafka.network.SocketServer)
kafka                    | [2025-10-03 16:11:51,364] INFO [broker-1-to-controller-alter-partition-channel-manager]: Starting (kafka.server.BrokerToControllerRequestThread)
kafka                    | [2025-10-03 16:11:51,364] INFO [broker-1-to-controller-alter-partition-channel-manager]: Recorded new controller, from now on will use node kafka:9093 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
kafka                    | [2025-10-03 16:11:51,480] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
kafka                    | [2025-10-03 16:11:51,490] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
kafka                    | [2025-10-03 16:11:51,493] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
kafka                    | [2025-10-03 16:11:51,505] INFO [ExpirationReaper-1-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
kafka                    | [2025-10-03 16:11:51,533] INFO [ExpirationReaper-1-RemoteFetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
kafka                    | [2025-10-03 16:11:51,688] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
kafka                    | [2025-10-03 16:11:51,716] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
kafka                    | [2025-10-03 16:11:51,905] INFO [broker-1-to-controller-heartbeat-channel-manager]: Starting (kafka.server.BrokerToControllerRequestThread)
kafka                    | [2025-10-03 16:11:51,907] INFO [broker-1-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node kafka:9093 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
kafka                    | [2025-10-03 16:11:51,940] INFO [BrokerLifecycleManager id=1] Incarnation jgEPhHgATnW-dFSrAuAAhA of broker 1 in cluster E51KSUCrSmm3AwlJhhuHuQ is now STARTING. (kafka.server.BrokerLifecycleManager)
kafka                    | [2025-10-03 16:11:52,023] INFO [ExpirationReaper-1-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
kafka                    | [2025-10-03 16:11:52,228] INFO [BrokerServer id=1] Waiting for the broker metadata publishers to be installed (kafka.server.BrokerServer)
kafka                    | [2025-10-03 16:11:52,235] INFO [BrokerServer id=1] Finished waiting for the broker metadata publishers to be installed (kafka.server.BrokerServer)
kafka                    | [2025-10-03 16:11:52,236] INFO [BrokerServer id=1] Waiting for the controller to acknowledge that we are caught up (kafka.server.BrokerServer)
kafka                    | [2025-10-03 16:11:52,236] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing BrokerMetadataPublisher with a snapshot at offset 246049 (org.apache.kafka.image.loader.MetadataLoader)
kafka                    | [2025-10-03 16:11:52,239] INFO [BrokerMetadataPublisher id=1] Publishing initial metadata at offset OffsetAndEpoch(offset=246049, epoch=91) with metadata.version 3.6-IV2. (kafka.server.metadata.BrokerMetadataPublisher)
kafka                    | [2025-10-03 16:11:52,248] INFO Loading logs from log dirs ArrayBuffer(/bitnami/kafka/data) (kafka.log.LogManager)
kafka                    | [2025-10-03 16:11:52,361] INFO Skipping recovery of 56 logs from /bitnami/kafka/data since clean shutdown file was found (kafka.log.LogManager)
kafka                    | [2025-10-03 16:11:52,534] INFO [LogLoader partition=transfer.completed-0, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka                    | [2025-10-03 16:11:52,633] INFO [QuorumController id=1] Replayed RegisterBrokerRecord establishing a new incarnation of broker 1: RegisterBrokerRecord(brokerId=1, isMigratingZkBroker=false, incarnationId=jgEPhHgATnW-dFSrAuAAhA, brokerEpoch=246051, endPoints=[BrokerEndpoint(name='PLAINTEXT', host='kafka', port=9092, securityProtocol=0), BrokerEndpoint(name='EXTERNAL', host='localhost', port=9094, securityProtocol=0)], features=[BrokerFeature(name='metadata.version', minSupportedVersion=1, maxSupportedVersion=14)], rack=null, fenced=true, inControlledShutdown=false) (org.apache.kafka.controller.ClusterControlManager)
kafka                    | [2025-10-03 16:11:52,669] INFO Completed load of Log(dir=/bitnami/kafka/data/transfer.completed-0, topicId=KnRdX7QnQJmUANpwxqvSDg, topic=transfer.completed, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 186ms (1/56 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka                    | [2025-10-03 16:11:52,677] INFO [BrokerLifecycleManager id=1] Successfully registered broker 1 with broker epoch 246051 (kafka.server.BrokerLifecycleManager)
kafka                    | [2025-10-03 16:11:52,740] INFO [LogLoader partition=__consumer_offsets-36, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka                    | [2025-10-03 16:11:52,764] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-36, topicId=iNBYdjYeRpSCdVw9OvuAgQ, topic=__consumer_offsets, partition=36, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 89ms (2/56 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka                    | [2025-10-03 16:11:52,822] INFO [LogLoader partition=__consumer_offsets-13, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka                    | [2025-10-03 16:11:52,828] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-13, topicId=iNBYdjYeRpSCdVw9OvuAgQ, topic=__consumer_offsets, partition=13, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 63ms (3/56 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka                    | [2025-10-03 16:11:52,879] INFO [LogLoader partition=__consumer_offsets-20, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka                    | [2025-10-03 16:11:52,895] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-20, topicId=iNBYdjYeRpSCdVw9OvuAgQ, topic=__consumer_offsets, partition=20, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 64ms (4/56 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka                    | [2025-10-03 16:11:52,929] INFO [LogLoader partition=kyc-events-0, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka                    | [2025-10-03 16:11:52,939] INFO Completed load of Log(dir=/bitnami/kafka/data/kyc-events-0, topicId=xrkFKQ2_RwCJqp4b4WCWXQ, topic=kyc-events, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 44ms (5/56 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka                    | [2025-10-03 16:11:53,002] INFO [LogLoader partition=__consumer_offsets-2, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka                    | [2025-10-03 16:11:53,024] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-2, topicId=iNBYdjYeRpSCdVw9OvuAgQ, topic=__consumer_offsets, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 84ms (6/56 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka                    | [2025-10-03 16:11:53,113] INFO [LogLoader partition=__consumer_offsets-34, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka                    | [2025-10-03 16:11:53,136] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-34, topicId=iNBYdjYeRpSCdVw9OvuAgQ, topic=__consumer_offsets, partition=34, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 112ms (7/56 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka                    | [2025-10-03 16:11:53,199] INFO [LogLoader partition=__consumer_offsets-15, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka                    | [2025-10-03 16:11:53,212] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-15, topicId=iNBYdjYeRpSCdVw9OvuAgQ, topic=__consumer_offsets, partition=15, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 57ms (8/56 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka                    | [2025-10-03 16:11:53,248] INFO [LogLoader partition=__consumer_offsets-16, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka                    | [2025-10-03 16:11:53,273] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-16, topicId=iNBYdjYeRpSCdVw9OvuAgQ, topic=__consumer_offsets, partition=16, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 61ms (9/56 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka                    | [2025-10-03 16:11:53,326] INFO [LogLoader partition=__consumer_offsets-26, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka                    | [2025-10-03 16:11:53,337] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-26, topicId=iNBYdjYeRpSCdVw9OvuAgQ, topic=__consumer_offsets, partition=26, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 64ms (10/56 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka                    | [2025-10-03 16:11:53,364] INFO [LogLoader partition=__consumer_offsets-31, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka                    | [2025-10-03 16:11:53,365] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-31, topicId=iNBYdjYeRpSCdVw9OvuAgQ, topic=__consumer_offsets, partition=31, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 24ms (11/56 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka                    | [2025-10-03 16:11:53,408] INFO [LogLoader partition=__consumer_offsets-39, dir=/bitnami/kafka/data] Loading producer state till offset 168 with message format version 2 (kafka.log.UnifiedLog$)
kafka                    | [2025-10-03 16:11:53,408] INFO [LogLoader partition=__consumer_offsets-39, dir=/bitnami/kafka/data] Reloading from producer snapshot and rebuilding producer state from offset 168 (kafka.log.UnifiedLog$)
kafka                    | [2025-10-03 16:11:53,408] INFO [ProducerStateManager partition=__consumer_offsets-39]Loading producer state from snapshot file 'SnapshotFile(offset=168, file=/bitnami/kafka/data/__consumer_offsets-39/00000000000000000168.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
kafka                    | [2025-10-03 16:11:53,410] INFO [LogLoader partition=__consumer_offsets-39, dir=/bitnami/kafka/data] Producer state recovery took 2ms for snapshot load and 0ms for segment recovery from offset 168 (kafka.log.UnifiedLog$)
kafka                    | [2025-10-03 16:11:53,415] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-39, topicId=iNBYdjYeRpSCdVw9OvuAgQ, topic=__consumer_offsets, partition=39, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=168) with 2 segments, local-log-start-offset 0 and log-end-offset 168 in 49ms (12/56 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka                    | [2025-10-03 16:11:53,467] INFO [LogLoader partition=__consumer_offsets-27, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka                    | [2025-10-03 16:11:53,486] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-27, topicId=iNBYdjYeRpSCdVw9OvuAgQ, topic=__consumer_offsets, partition=27, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 67ms (13/56 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka                    | [2025-10-03 16:11:53,555] INFO [LogLoader partition=password.changed-0, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka                    | [2025-10-03 16:11:53,558] INFO Completed load of Log(dir=/bitnami/kafka/data/password.changed-0, topicId=7BTLLGtSRcaeR2BnI9Wd5g, topic=password.changed, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 67ms (14/56 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka                    | [2025-10-03 16:11:53,577] INFO [LogLoader partition=__consumer_offsets-37, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka                    | [2025-10-03 16:11:53,578] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-37, topicId=iNBYdjYeRpSCdVw9OvuAgQ, topic=__consumer_offsets, partition=37, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 16ms (15/56 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka                    | [2025-10-03 16:11:53,614] INFO [LogLoader partition=__consumer_offsets-4, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka                    | [2025-10-03 16:11:53,632] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-4, topicId=iNBYdjYeRpSCdVw9OvuAgQ, topic=__consumer_offsets, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 53ms (16/56 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka                    | [2025-10-03 16:11:53,683] INFO [LogLoader partition=__consumer_offsets-30, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka                    | [2025-10-03 16:11:53,684] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-30, topicId=iNBYdjYeRpSCdVw9OvuAgQ, topic=__consumer_offsets, partition=30, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 52ms (17/56 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka                    | [2025-10-03 16:11:53,732] INFO [LogLoader partition=__consumer_offsets-11, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka                    | [2025-10-03 16:11:53,745] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-11, topicId=iNBYdjYeRpSCdVw9OvuAgQ, topic=__consumer_offsets, partition=11, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 52ms (18/56 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka                    | [2025-10-03 16:11:53,811] INFO [LogLoader partition=__consumer_offsets-23, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka                    | [2025-10-03 16:11:53,857] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-23, topicId=iNBYdjYeRpSCdVw9OvuAgQ, topic=__consumer_offsets, partition=23, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 112ms (19/56 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka                    | [2025-10-03 16:11:53,893] INFO [LogLoader partition=__consumer_offsets-24, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka                    | [2025-10-03 16:11:53,906] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-24, topicId=iNBYdjYeRpSCdVw9OvuAgQ, topic=__consumer_offsets, partition=24, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 26ms (20/56 completed in /bitnami/kafka/data) (kafka.log.LogManager)
fraud-detection          | 2025-10-03T16:11:53.981Z  INFO 1 --- [fraud-detection] [           main] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data JPA repositories in DEFAULT mode.
kafka                    | [2025-10-03 16:11:53,976] INFO [LogLoader partition=__consumer_offsets-29, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka                    | [2025-10-03 16:11:54,009] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-29, topicId=iNBYdjYeRpSCdVw9OvuAgQ, topic=__consumer_offsets, partition=29, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 103ms (21/56 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka                    | [2025-10-03 16:11:54,066] INFO [LogLoader partition=__consumer_offsets-5, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka                    | [2025-10-03 16:11:54,086] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-5, topicId=iNBYdjYeRpSCdVw9OvuAgQ, topic=__consumer_offsets, partition=5, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 65ms (22/56 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka                    | [2025-10-03 16:11:54,137] INFO [LogLoader partition=__consumer_offsets-18, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka                    | [2025-10-03 16:11:54,147] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-18, topicId=iNBYdjYeRpSCdVw9OvuAgQ, topic=__consumer_offsets, partition=18, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 61ms (23/56 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka                    | [2025-10-03 16:11:54,190] INFO [LogLoader partition=__consumer_offsets-19, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka                    | [2025-10-03 16:11:54,209] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-19, topicId=iNBYdjYeRpSCdVw9OvuAgQ, topic=__consumer_offsets, partition=19, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 57ms (24/56 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka                    | [2025-10-03 16:11:54,265] INFO [LogLoader partition=login-attempts-topic-0, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka                    | [2025-10-03 16:11:54,271] INFO Completed load of Log(dir=/bitnami/kafka/data/login-attempts-topic-0, topicId=C9qPgaLVTKmphRtrR47kPQ, topic=login-attempts-topic, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 50ms (25/56 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka                    | [2025-10-03 16:11:54,290] INFO [LogLoader partition=__consumer_offsets-0, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka                    | [2025-10-03 16:11:54,299] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-0, topicId=iNBYdjYeRpSCdVw9OvuAgQ, topic=__consumer_offsets, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 23ms (26/56 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka                    | [2025-10-03 16:11:54,331] INFO [LogLoader partition=__consumer_offsets-22, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka                    | [2025-10-03 16:11:54,334] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-22, topicId=iNBYdjYeRpSCdVw9OvuAgQ, topic=__consumer_offsets, partition=22, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 35ms (27/56 completed in /bitnami/kafka/data) (kafka.log.LogManager)
fraud-detection          | 2025-10-03T16:11:54.357Z  INFO 1 --- [fraud-detection] [           main] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 200 ms. Found 0 JPA repository interfaces.
kafka                    | [2025-10-03 16:11:54,357] INFO [LogLoader partition=user.registered-0, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka                    | [2025-10-03 16:11:54,360] INFO Completed load of Log(dir=/bitnami/kafka/data/user.registered-0, topicId=wA1qIfWQTdGjFnyrGcxRuQ, topic=user.registered, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 26ms (28/56 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka                    | [2025-10-03 16:11:54,385] INFO [LogLoader partition=__consumer_offsets-12, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka                    | [2025-10-03 16:11:54,386] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-12, topicId=iNBYdjYeRpSCdVw9OvuAgQ, topic=__consumer_offsets, partition=12, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 26ms (29/56 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka                    | [2025-10-03 16:11:54,412] INFO [LogLoader partition=transfer-completed-events-0, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka                    | [2025-10-03 16:11:54,426] INFO Completed load of Log(dir=/bitnami/kafka/data/transfer-completed-events-0, topicId=ltyY2IODSnCcb9DcVhT46A, topic=transfer-completed-events, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 40ms (30/56 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka                    | [2025-10-03 16:11:54,475] INFO [LogLoader partition=__consumer_offsets-10, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka                    | [2025-10-03 16:11:54,499] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-10, topicId=iNBYdjYeRpSCdVw9OvuAgQ, topic=__consumer_offsets, partition=10, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 73ms (31/56 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka                    | [2025-10-03 16:11:54,585] INFO [LogLoader partition=__consumer_offsets-48, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka                    | [2025-10-03 16:11:54,642] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-48, topicId=iNBYdjYeRpSCdVw9OvuAgQ, topic=__consumer_offsets, partition=48, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 128ms (32/56 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka                    | [2025-10-03 16:11:54,707] INFO [LogLoader partition=__consumer_offsets-3, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka                    | [2025-10-03 16:11:54,855] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-3, topicId=iNBYdjYeRpSCdVw9OvuAgQ, topic=__consumer_offsets, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 213ms (33/56 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka                    | [2025-10-03 16:11:54,904] INFO [LogLoader partition=__consumer_offsets-46, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka                    | [2025-10-03 16:11:54,915] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-46, topicId=iNBYdjYeRpSCdVw9OvuAgQ, topic=__consumer_offsets, partition=46, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 50ms (34/56 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka                    | [2025-10-03 16:11:54,979] INFO [LogLoader partition=__consumer_offsets-8, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka                    | [2025-10-03 16:11:54,987] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-8, topicId=iNBYdjYeRpSCdVw9OvuAgQ, topic=__consumer_offsets, partition=8, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 64ms (35/56 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka                    | [2025-10-03 16:11:55,036] INFO [LogLoader partition=__consumer_offsets-25, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka                    | [2025-10-03 16:11:55,043] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-25, topicId=iNBYdjYeRpSCdVw9OvuAgQ, topic=__consumer_offsets, partition=25, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 47ms (36/56 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka                    | [2025-10-03 16:11:55,189] INFO [LogLoader partition=__consumer_offsets-38, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka                    | [2025-10-03 16:11:55,195] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-38, topicId=iNBYdjYeRpSCdVw9OvuAgQ, topic=__consumer_offsets, partition=38, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 149ms (37/56 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka                    | [2025-10-03 16:11:55,313] INFO [LogLoader partition=__consumer_offsets-44, dir=/bitnami/kafka/data] Loading producer state till offset 161 with message format version 2 (kafka.log.UnifiedLog$)
kafka                    | [2025-10-03 16:11:55,313] INFO [LogLoader partition=__consumer_offsets-44, dir=/bitnami/kafka/data] Reloading from producer snapshot and rebuilding producer state from offset 161 (kafka.log.UnifiedLog$)
kafka                    | [2025-10-03 16:11:55,313] INFO [ProducerStateManager partition=__consumer_offsets-44]Loading producer state from snapshot file 'SnapshotFile(offset=161, file=/bitnami/kafka/data/__consumer_offsets-44/00000000000000000161.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
kafka                    | [2025-10-03 16:11:55,331] INFO [LogLoader partition=__consumer_offsets-44, dir=/bitnami/kafka/data] Producer state recovery took 17ms for snapshot load and 1ms for segment recovery from offset 161 (kafka.log.UnifiedLog$)
kafka                    | [2025-10-03 16:11:55,362] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-44, topicId=iNBYdjYeRpSCdVw9OvuAgQ, topic=__consumer_offsets, partition=44, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=161) with 2 segments, local-log-start-offset 0 and log-end-offset 161 in 166ms (38/56 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka                    | [2025-10-03 16:11:55,512] INFO [LogLoader partition=__consumer_offsets-28, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka                    | [2025-10-03 16:11:55,658] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-28, topicId=iNBYdjYeRpSCdVw9OvuAgQ, topic=__consumer_offsets, partition=28, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 279ms (39/56 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka                    | [2025-10-03 16:11:55,865] INFO [LogLoader partition=__consumer_offsets-1, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka                    | [2025-10-03 16:11:55,902] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-1, topicId=iNBYdjYeRpSCdVw9OvuAgQ, topic=__consumer_offsets, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 242ms (40/56 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka                    | [2025-10-03 16:11:55,975] INFO [LogLoader partition=__consumer_offsets-40, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka                    | [2025-10-03 16:11:56,077] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-40, topicId=iNBYdjYeRpSCdVw9OvuAgQ, topic=__consumer_offsets, partition=40, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 147ms (41/56 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka                    | [2025-10-03 16:11:56,134] INFO [LogLoader partition=__consumer_offsets-41, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka                    | [2025-10-03 16:11:56,150] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-41, topicId=iNBYdjYeRpSCdVw9OvuAgQ, topic=__consumer_offsets, partition=41, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 61ms (42/56 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka                    | [2025-10-03 16:11:56,202] INFO [LogLoader partition=__consumer_offsets-9, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka                    | [2025-10-03 16:11:56,222] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-9, topicId=iNBYdjYeRpSCdVw9OvuAgQ, topic=__consumer_offsets, partition=9, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 72ms (43/56 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka                    | [2025-10-03 16:11:56,473] INFO [LogLoader partition=__consumer_offsets-7, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka                    | [2025-10-03 16:11:56,483] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-7, topicId=iNBYdjYeRpSCdVw9OvuAgQ, topic=__consumer_offsets, partition=7, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 232ms (44/56 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka                    | [2025-10-03 16:11:56,543] INFO [LogLoader partition=__consumer_offsets-33, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka                    | [2025-10-03 16:11:56,647] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-33, topicId=iNBYdjYeRpSCdVw9OvuAgQ, topic=__consumer_offsets, partition=33, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 146ms (45/56 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka                    | [2025-10-03 16:11:56,792] INFO [LogLoader partition=__consumer_offsets-6, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka                    | [2025-10-03 16:11:56,863] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-6, topicId=iNBYdjYeRpSCdVw9OvuAgQ, topic=__consumer_offsets, partition=6, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 208ms (46/56 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka                    | [2025-10-03 16:11:56,981] INFO [LogLoader partition=__consumer_offsets-32, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka                    | [2025-10-03 16:11:56,992] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-32, topicId=iNBYdjYeRpSCdVw9OvuAgQ, topic=__consumer_offsets, partition=32, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 120ms (47/56 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka                    | [2025-10-03 16:11:57,290] INFO [LogLoader partition=__consumer_offsets-17, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka                    | [2025-10-03 16:11:57,303] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-17, topicId=iNBYdjYeRpSCdVw9OvuAgQ, topic=__consumer_offsets, partition=17, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 310ms (48/56 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka                    | [2025-10-03 16:11:57,518] INFO [LogLoader partition=__consumer_offsets-47, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka                    | [2025-10-03 16:11:57,566] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-47, topicId=iNBYdjYeRpSCdVw9OvuAgQ, topic=__consumer_offsets, partition=47, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 262ms (49/56 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka                    | [2025-10-03 16:11:57,704] INFO [LogLoader partition=__consumer_offsets-35, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka                    | [2025-10-03 16:11:57,722] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-35, topicId=iNBYdjYeRpSCdVw9OvuAgQ, topic=__consumer_offsets, partition=35, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 155ms (50/56 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka                    | [2025-10-03 16:11:57,839] INFO [LogLoader partition=__consumer_offsets-43, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka                    | [2025-10-03 16:11:57,919] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-43, topicId=iNBYdjYeRpSCdVw9OvuAgQ, topic=__consumer_offsets, partition=43, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 174ms (51/56 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka                    | [2025-10-03 16:11:58,205] INFO [LogLoader partition=__consumer_offsets-49, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka                    | [2025-10-03 16:11:58,240] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-49, topicId=iNBYdjYeRpSCdVw9OvuAgQ, topic=__consumer_offsets, partition=49, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 314ms (52/56 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka                    | [2025-10-03 16:11:58,322] INFO [LogLoader partition=__consumer_offsets-45, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka                    | [2025-10-03 16:11:58,355] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-45, topicId=iNBYdjYeRpSCdVw9OvuAgQ, topic=__consumer_offsets, partition=45, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 111ms (53/56 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka                    | [2025-10-03 16:11:58,494] INFO [LogLoader partition=__consumer_offsets-14, dir=/bitnami/kafka/data] Loading producer state till offset 162 with message format version 2 (kafka.log.UnifiedLog$)
kafka                    | [2025-10-03 16:11:58,494] INFO [LogLoader partition=__consumer_offsets-14, dir=/bitnami/kafka/data] Reloading from producer snapshot and rebuilding producer state from offset 162 (kafka.log.UnifiedLog$)
kafka                    | [2025-10-03 16:11:58,505] INFO [ProducerStateManager partition=__consumer_offsets-14]Loading producer state from snapshot file 'SnapshotFile(offset=162, file=/bitnami/kafka/data/__consumer_offsets-14/00000000000000000162.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
kafka                    | [2025-10-03 16:11:58,506] INFO [LogLoader partition=__consumer_offsets-14, dir=/bitnami/kafka/data] Producer state recovery took 12ms for snapshot load and 0ms for segment recovery from offset 162 (kafka.log.UnifiedLog$)
kafka                    | [2025-10-03 16:11:58,523] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-14, topicId=iNBYdjYeRpSCdVw9OvuAgQ, topic=__consumer_offsets, partition=14, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=162) with 2 segments, local-log-start-offset 0 and log-end-offset 162 in 161ms (54/56 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka                    | [2025-10-03 16:11:58,672] INFO [LogLoader partition=__consumer_offsets-21, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka                    | [2025-10-03 16:11:58,708] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-21, topicId=iNBYdjYeRpSCdVw9OvuAgQ, topic=__consumer_offsets, partition=21, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 177ms (55/56 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka                    | [2025-10-03 16:11:58,825] INFO [LogLoader partition=__consumer_offsets-42, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka                    | [2025-10-03 16:11:58,856] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-42, topicId=iNBYdjYeRpSCdVw9OvuAgQ, topic=__consumer_offsets, partition=42, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 140ms (56/56 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka                    | [2025-10-03 16:11:59,465] INFO Loaded 56 logs in 7169ms (kafka.log.LogManager)
kafka                    | [2025-10-03 16:11:59,480] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
kafka                    | [2025-10-03 16:11:59,579] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
kafka                    | [2025-10-03 16:12:00,525] INFO Starting the log cleaner (kafka.log.LogCleaner)
api-gateway-1            | 2025-10-03T16:12:03.173Z  INFO 1 --- [api-gateway] [           main] o.s.cloud.context.scope.GenericScope     : BeanFactory id=8e8817ed-cdf8-356f-afc4-42eacde1b65a
kafka                    | [2025-10-03 16:12:05,482] INFO [kafka-log-cleaner-thread-0]: Starting (kafka.log.LogCleaner$CleanerThread)
kafka                    | [2025-10-03 16:12:06,070] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
kafka                    | [2025-10-03 16:12:06,305] INFO [AddPartitionsToTxnSenderThread-1]: Starting (kafka.server.AddPartitionsToTxnManager)
kafka                    | [2025-10-03 16:12:06,526] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
kafka                    | [2025-10-03 16:12:06,826] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
kafka                    | [2025-10-03 16:12:07,126] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
kafka                    | [2025-10-03 16:12:07,622] INFO [TxnMarkerSenderThread-1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
kafka                    | [2025-10-03 16:12:07,636] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
kafka                    | [2025-10-03 16:12:07,732] INFO [BrokerMetadataPublisher id=1] Updating metadata.version to 14 at offset OffsetAndEpoch(offset=246049, epoch=91). (kafka.server.metadata.BrokerMetadataPublisher)
kafka                    | [2025-10-03 16:12:07,992] INFO [Broker id=1] Transitioning 56 partition(s) to local followers. (state.change.logger)
kafka                    | [2025-10-03 16:12:08,354] INFO [Broker id=1] Creating new partition __consumer_offsets-13 with topic id iNBYdjYeRpSCdVw9OvuAgQ. (state.change.logger)
settings-service         | 2025-10-03T16:12:08.582Z  INFO 1 --- [bank-shared] [           main] o.s.b.w.embedded.tomcat.TomcatWebServer  : Tomcat initialized with port 8080 (http)
settings-service         | 2025-10-03T16:12:08.983Z  INFO 1 --- [bank-shared] [           main] o.apache.catalina.core.StandardService   : Starting service [Tomcat]
settings-service         | 2025-10-03T16:12:08.996Z  INFO 1 --- [bank-shared] [           main] o.apache.catalina.core.StandardEngine    : Starting Servlet engine: [Apache Tomcat/10.1.41]
kyc-service              | 
kyc-service              |   .   ____          _            __ _ _
kyc-service              |  /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \
kyc-service              | ( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \
kyc-service              |  \\/  ___)| |_)| | | | | || (_| |  ) ) ) )
kyc-service              |   '  |____| .__|_| |_|_| |_\__, | / / / /
kyc-service              |  =========|_|==============|___/=/_/_/_/
kyc-service              | 
kyc-service              |  :: Spring Boot ::                (v3.5.0)
kyc-service              | 
settings-service         | 2025-10-03T16:12:09.561Z  INFO 1 --- [bank-shared] [           main] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring embedded WebApplicationContext
settings-service         | 2025-10-03T16:12:09.618Z  INFO 1 --- [bank-shared] [           main] w.s.c.ServletWebServerApplicationContext : Root WebApplicationContext: initialization completed in 36325 ms
kafka                    | [2025-10-03 16:12:10,221] INFO [Partition __consumer_offsets-13 broker=1] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
kafka                    | [2025-10-03 16:12:10,320] INFO [Broker id=1] Follower __consumer_offsets-13 starts at leader epoch 169 from offset 0 with partition epoch 169 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 169. (state.change.logger)
kafka                    | [2025-10-03 16:12:10,346] INFO [Broker id=1] Creating new partition password.changed-0 with topic id 7BTLLGtSRcaeR2BnI9Wd5g. (state.change.logger)
kafka                    | [2025-10-03 16:12:10,404] INFO [Partition password.changed-0 broker=1] Log loaded for partition password.changed-0 with initial high watermark 0 (kafka.cluster.Partition)
kafka                    | [2025-10-03 16:12:10,404] INFO [Broker id=1] Follower password.changed-0 starts at leader epoch 169 from offset 0 with partition epoch 169 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 169. (state.change.logger)
kafka                    | [2025-10-03 16:12:10,404] INFO [Broker id=1] Creating new partition __consumer_offsets-46 with topic id iNBYdjYeRpSCdVw9OvuAgQ. (state.change.logger)
kafka                    | [2025-10-03 16:12:10,405] INFO [Partition __consumer_offsets-46 broker=1] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)
kafka                    | [2025-10-03 16:12:10,405] INFO [Broker id=1] Follower __consumer_offsets-46 starts at leader epoch 169 from offset 0 with partition epoch 169 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 169. (state.change.logger)
kafka                    | [2025-10-03 16:12:10,405] INFO [Broker id=1] Creating new partition __consumer_offsets-9 with topic id iNBYdjYeRpSCdVw9OvuAgQ. (state.change.logger)
kafka                    | [2025-10-03 16:12:10,500] INFO [Partition __consumer_offsets-9 broker=1] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
kafka                    | [2025-10-03 16:12:10,500] INFO [Broker id=1] Follower __consumer_offsets-9 starts at leader epoch 169 from offset 0 with partition epoch 169 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 169. (state.change.logger)
kafka                    | [2025-10-03 16:12:10,507] INFO [Broker id=1] Creating new partition __consumer_offsets-42 with topic id iNBYdjYeRpSCdVw9OvuAgQ. (state.change.logger)
kafka                    | [2025-10-03 16:12:10,508] INFO [Partition __consumer_offsets-42 broker=1] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
kafka                    | [2025-10-03 16:12:10,508] INFO [Broker id=1] Follower __consumer_offsets-42 starts at leader epoch 169 from offset 0 with partition epoch 169 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 169. (state.change.logger)
kafka                    | [2025-10-03 16:12:10,508] INFO [Broker id=1] Creating new partition __consumer_offsets-21 with topic id iNBYdjYeRpSCdVw9OvuAgQ. (state.change.logger)
kafka                    | [2025-10-03 16:12:10,508] INFO [Partition __consumer_offsets-21 broker=1] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
kafka                    | [2025-10-03 16:12:10,509] INFO [Broker id=1] Follower __consumer_offsets-21 starts at leader epoch 169 from offset 0 with partition epoch 169 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 169. (state.change.logger)
kafka                    | [2025-10-03 16:12:10,509] INFO [Broker id=1] Creating new partition __consumer_offsets-17 with topic id iNBYdjYeRpSCdVw9OvuAgQ. (state.change.logger)
kafka                    | [2025-10-03 16:12:10,509] INFO [Partition __consumer_offsets-17 broker=1] Log loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Partition)
kafka                    | [2025-10-03 16:12:10,509] INFO [Broker id=1] Follower __consumer_offsets-17 starts at leader epoch 169 from offset 0 with partition epoch 169 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 169. (state.change.logger)
kafka                    | [2025-10-03 16:12:10,509] INFO [Broker id=1] Creating new partition __consumer_offsets-30 with topic id iNBYdjYeRpSCdVw9OvuAgQ. (state.change.logger)
kafka                    | [2025-10-03 16:12:10,552] INFO [Partition __consumer_offsets-30 broker=1] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
kafka                    | [2025-10-03 16:12:10,553] INFO [Broker id=1] Follower __consumer_offsets-30 starts at leader epoch 169 from offset 0 with partition epoch 169 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 169. (state.change.logger)
kafka                    | [2025-10-03 16:12:10,553] INFO [Broker id=1] Creating new partition __consumer_offsets-26 with topic id iNBYdjYeRpSCdVw9OvuAgQ. (state.change.logger)
kafka                    | [2025-10-03 16:12:10,553] INFO [Partition __consumer_offsets-26 broker=1] Log loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Partition)
kafka                    | [2025-10-03 16:12:10,553] INFO [Broker id=1] Follower __consumer_offsets-26 starts at leader epoch 169 from offset 0 with partition epoch 169 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 169. (state.change.logger)
kafka                    | [2025-10-03 16:12:10,553] INFO [Broker id=1] Creating new partition __consumer_offsets-5 with topic id iNBYdjYeRpSCdVw9OvuAgQ. (state.change.logger)
kafka                    | [2025-10-03 16:12:10,573] INFO [Partition __consumer_offsets-5 broker=1] Log loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Partition)
kafka                    | [2025-10-03 16:12:10,573] INFO [Broker id=1] Follower __consumer_offsets-5 starts at leader epoch 169 from offset 0 with partition epoch 169 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 169. (state.change.logger)
kafka                    | [2025-10-03 16:12:10,573] INFO [Broker id=1] Creating new partition __consumer_offsets-38 with topic id iNBYdjYeRpSCdVw9OvuAgQ. (state.change.logger)
kafka                    | [2025-10-03 16:12:10,574] INFO [Partition __consumer_offsets-38 broker=1] Log loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Partition)
kafka                    | [2025-10-03 16:12:10,574] INFO [Broker id=1] Follower __consumer_offsets-38 starts at leader epoch 169 from offset 0 with partition epoch 169 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 169. (state.change.logger)
kafka                    | [2025-10-03 16:12:10,574] INFO [Broker id=1] Creating new partition __consumer_offsets-1 with topic id iNBYdjYeRpSCdVw9OvuAgQ. (state.change.logger)
kafka                    | [2025-10-03 16:12:10,574] INFO [Partition __consumer_offsets-1 broker=1] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
kafka                    | [2025-10-03 16:12:10,574] INFO [Broker id=1] Follower __consumer_offsets-1 starts at leader epoch 169 from offset 0 with partition epoch 169 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 169. (state.change.logger)
kafka                    | [2025-10-03 16:12:10,574] INFO [Broker id=1] Creating new partition user.registered-0 with topic id wA1qIfWQTdGjFnyrGcxRuQ. (state.change.logger)
kafka                    | [2025-10-03 16:12:10,575] INFO [Partition user.registered-0 broker=1] Log loaded for partition user.registered-0 with initial high watermark 0 (kafka.cluster.Partition)
kafka                    | [2025-10-03 16:12:10,575] INFO [Broker id=1] Follower user.registered-0 starts at leader epoch 169 from offset 0 with partition epoch 169 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 169. (state.change.logger)
kafka                    | [2025-10-03 16:12:10,575] INFO [Broker id=1] Creating new partition __consumer_offsets-34 with topic id iNBYdjYeRpSCdVw9OvuAgQ. (state.change.logger)
kafka                    | [2025-10-03 16:12:10,575] INFO [Partition __consumer_offsets-34 broker=1] Log loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Partition)
kafka                    | [2025-10-03 16:12:10,621] INFO [Broker id=1] Follower __consumer_offsets-34 starts at leader epoch 169 from offset 0 with partition epoch 169 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 169. (state.change.logger)
kafka                    | [2025-10-03 16:12:10,621] INFO [Broker id=1] Creating new partition __consumer_offsets-16 with topic id iNBYdjYeRpSCdVw9OvuAgQ. (state.change.logger)
kafka                    | [2025-10-03 16:12:10,622] INFO [Partition __consumer_offsets-16 broker=1] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
kafka                    | [2025-10-03 16:12:10,623] INFO [Broker id=1] Follower __consumer_offsets-16 starts at leader epoch 169 from offset 0 with partition epoch 169 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 169. (state.change.logger)
kafka                    | [2025-10-03 16:12:10,623] INFO [Broker id=1] Creating new partition __consumer_offsets-45 with topic id iNBYdjYeRpSCdVw9OvuAgQ. (state.change.logger)
kafka                    | [2025-10-03 16:12:10,646] INFO [Partition __consumer_offsets-45 broker=1] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
kafka                    | [2025-10-03 16:12:10,646] INFO [Broker id=1] Follower __consumer_offsets-45 starts at leader epoch 169 from offset 0 with partition epoch 169 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 169. (state.change.logger)
kafka                    | [2025-10-03 16:12:10,646] INFO [Broker id=1] Creating new partition __consumer_offsets-12 with topic id iNBYdjYeRpSCdVw9OvuAgQ. (state.change.logger)
kafka                    | [2025-10-03 16:12:10,661] INFO [Partition __consumer_offsets-12 broker=1] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
kafka                    | [2025-10-03 16:12:10,661] INFO [Broker id=1] Follower __consumer_offsets-12 starts at leader epoch 169 from offset 0 with partition epoch 169 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 169. (state.change.logger)
kafka                    | [2025-10-03 16:12:10,661] INFO [Broker id=1] Creating new partition __consumer_offsets-41 with topic id iNBYdjYeRpSCdVw9OvuAgQ. (state.change.logger)
kafka                    | [2025-10-03 16:12:10,676] INFO [Partition __consumer_offsets-41 broker=1] Log loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Partition)
kafka                    | [2025-10-03 16:12:10,676] INFO [Broker id=1] Follower __consumer_offsets-41 starts at leader epoch 169 from offset 0 with partition epoch 169 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 169. (state.change.logger)
kafka                    | [2025-10-03 16:12:10,676] INFO [Broker id=1] Creating new partition __consumer_offsets-24 with topic id iNBYdjYeRpSCdVw9OvuAgQ. (state.change.logger)
kafka                    | [2025-10-03 16:12:10,677] INFO [Partition __consumer_offsets-24 broker=1] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
kafka                    | [2025-10-03 16:12:10,677] INFO [Broker id=1] Follower __consumer_offsets-24 starts at leader epoch 169 from offset 0 with partition epoch 169 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 169. (state.change.logger)
kafka                    | [2025-10-03 16:12:10,677] INFO [Broker id=1] Creating new partition __consumer_offsets-20 with topic id iNBYdjYeRpSCdVw9OvuAgQ. (state.change.logger)
kafka                    | [2025-10-03 16:12:10,677] INFO [Partition __consumer_offsets-20 broker=1] Log loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Partition)
kafka                    | [2025-10-03 16:12:10,677] INFO [Broker id=1] Follower __consumer_offsets-20 starts at leader epoch 169 from offset 0 with partition epoch 169 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 169. (state.change.logger)
kafka                    | [2025-10-03 16:12:10,677] INFO [Broker id=1] Creating new partition __consumer_offsets-49 with topic id iNBYdjYeRpSCdVw9OvuAgQ. (state.change.logger)
kafka                    | [2025-10-03 16:12:10,678] INFO [Partition __consumer_offsets-49 broker=1] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
kafka                    | [2025-10-03 16:12:10,678] INFO [Broker id=1] Follower __consumer_offsets-49 starts at leader epoch 169 from offset 0 with partition epoch 169 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 169. (state.change.logger)
kafka                    | [2025-10-03 16:12:10,678] INFO [Broker id=1] Creating new partition __consumer_offsets-0 with topic id iNBYdjYeRpSCdVw9OvuAgQ. (state.change.logger)
kafka                    | [2025-10-03 16:12:10,692] INFO [Partition __consumer_offsets-0 broker=1] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
kafka                    | [2025-10-03 16:12:10,692] INFO [Broker id=1] Follower __consumer_offsets-0 starts at leader epoch 169 from offset 0 with partition epoch 169 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 169. (state.change.logger)
kafka                    | [2025-10-03 16:12:10,692] INFO [Broker id=1] Creating new partition __consumer_offsets-29 with topic id iNBYdjYeRpSCdVw9OvuAgQ. (state.change.logger)
kafka                    | [2025-10-03 16:12:10,707] INFO [Partition __consumer_offsets-29 broker=1] Log loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Partition)
kafka                    | [2025-10-03 16:12:10,707] INFO [Broker id=1] Follower __consumer_offsets-29 starts at leader epoch 169 from offset 0 with partition epoch 169 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 169. (state.change.logger)
kafka                    | [2025-10-03 16:12:10,708] INFO [Broker id=1] Creating new partition __consumer_offsets-25 with topic id iNBYdjYeRpSCdVw9OvuAgQ. (state.change.logger)
kafka                    | [2025-10-03 16:12:10,709] INFO [Partition __consumer_offsets-25 broker=1] Log loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Partition)
kafka                    | [2025-10-03 16:12:10,709] INFO [Broker id=1] Follower __consumer_offsets-25 starts at leader epoch 169 from offset 0 with partition epoch 169 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 169. (state.change.logger)
kafka                    | [2025-10-03 16:12:10,709] INFO [Broker id=1] Creating new partition __consumer_offsets-8 with topic id iNBYdjYeRpSCdVw9OvuAgQ. (state.change.logger)
kafka                    | [2025-10-03 16:12:10,709] INFO [Partition __consumer_offsets-8 broker=1] Log loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Partition)
kafka                    | [2025-10-03 16:12:10,725] INFO [Broker id=1] Follower __consumer_offsets-8 starts at leader epoch 169 from offset 0 with partition epoch 169 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 169. (state.change.logger)
kafka                    | [2025-10-03 16:12:10,725] INFO [Broker id=1] Creating new partition __consumer_offsets-37 with topic id iNBYdjYeRpSCdVw9OvuAgQ. (state.change.logger)
kafka                    | [2025-10-03 16:12:10,726] INFO [Partition __consumer_offsets-37 broker=1] Log loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Partition)
kafka                    | [2025-10-03 16:12:10,726] INFO [Broker id=1] Follower __consumer_offsets-37 starts at leader epoch 169 from offset 0 with partition epoch 169 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 169. (state.change.logger)
kafka                    | [2025-10-03 16:12:10,726] INFO [Broker id=1] Creating new partition __consumer_offsets-4 with topic id iNBYdjYeRpSCdVw9OvuAgQ. (state.change.logger)
kafka                    | [2025-10-03 16:12:10,727] INFO [Partition __consumer_offsets-4 broker=1] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
kafka                    | [2025-10-03 16:12:10,727] INFO [Broker id=1] Follower __consumer_offsets-4 starts at leader epoch 169 from offset 0 with partition epoch 169 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 169. (state.change.logger)
kafka                    | [2025-10-03 16:12:10,727] INFO [Broker id=1] Creating new partition __consumer_offsets-33 with topic id iNBYdjYeRpSCdVw9OvuAgQ. (state.change.logger)
kafka                    | [2025-10-03 16:12:10,727] INFO [Partition __consumer_offsets-33 broker=1] Log loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Partition)
kafka                    | [2025-10-03 16:12:10,727] INFO [Broker id=1] Follower __consumer_offsets-33 starts at leader epoch 169 from offset 0 with partition epoch 169 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 169. (state.change.logger)
kafka                    | [2025-10-03 16:12:10,749] INFO [Broker id=1] Creating new partition __consumer_offsets-15 with topic id iNBYdjYeRpSCdVw9OvuAgQ. (state.change.logger)
kafka                    | [2025-10-03 16:12:10,751] INFO [Partition __consumer_offsets-15 broker=1] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
kafka                    | [2025-10-03 16:12:10,757] INFO [Broker id=1] Follower __consumer_offsets-15 starts at leader epoch 169 from offset 0 with partition epoch 169 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 169. (state.change.logger)
kafka                    | [2025-10-03 16:12:10,761] INFO [Broker id=1] Creating new partition __consumer_offsets-48 with topic id iNBYdjYeRpSCdVw9OvuAgQ. (state.change.logger)
kafka                    | [2025-10-03 16:12:10,775] INFO [Partition __consumer_offsets-48 broker=1] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
kafka                    | [2025-10-03 16:12:10,783] INFO [Broker id=1] Follower __consumer_offsets-48 starts at leader epoch 169 from offset 0 with partition epoch 169 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 169. (state.change.logger)
kafka                    | [2025-10-03 16:12:10,789] INFO [Broker id=1] Creating new partition __consumer_offsets-11 with topic id iNBYdjYeRpSCdVw9OvuAgQ. (state.change.logger)
kafka                    | [2025-10-03 16:12:10,793] INFO [Partition __consumer_offsets-11 broker=1] Log loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Partition)
kafka                    | [2025-10-03 16:12:10,803] INFO [Broker id=1] Follower __consumer_offsets-11 starts at leader epoch 169 from offset 0 with partition epoch 169 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 169. (state.change.logger)
kafka                    | [2025-10-03 16:12:10,803] INFO [Broker id=1] Creating new partition __consumer_offsets-44 with topic id iNBYdjYeRpSCdVw9OvuAgQ. (state.change.logger)
kafka                    | [2025-10-03 16:12:10,813] INFO [Partition __consumer_offsets-44 broker=1] Log loaded for partition __consumer_offsets-44 with initial high watermark 161 (kafka.cluster.Partition)
kafka                    | [2025-10-03 16:12:10,822] INFO [Broker id=1] Follower __consumer_offsets-44 starts at leader epoch 169 from offset 161 with partition epoch 169 and high watermark 161. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 169. (state.change.logger)
kafka                    | [2025-10-03 16:12:10,822] INFO [Broker id=1] Creating new partition __consumer_offsets-23 with topic id iNBYdjYeRpSCdVw9OvuAgQ. (state.change.logger)
kafka                    | [2025-10-03 16:12:10,824] INFO [Partition __consumer_offsets-23 broker=1] Log loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Partition)
kafka                    | [2025-10-03 16:12:10,841] INFO [Broker id=1] Follower __consumer_offsets-23 starts at leader epoch 169 from offset 0 with partition epoch 169 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 169. (state.change.logger)
kafka                    | [2025-10-03 16:12:10,841] INFO [Broker id=1] Creating new partition __consumer_offsets-19 with topic id iNBYdjYeRpSCdVw9OvuAgQ. (state.change.logger)
kafka                    | [2025-10-03 16:12:10,857] INFO [Partition __consumer_offsets-19 broker=1] Log loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Partition)
kafka                    | [2025-10-03 16:12:10,858] INFO [Broker id=1] Follower __consumer_offsets-19 starts at leader epoch 169 from offset 0 with partition epoch 169 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 169. (state.change.logger)
kafka                    | [2025-10-03 16:12:10,858] INFO [Broker id=1] Creating new partition __consumer_offsets-32 with topic id iNBYdjYeRpSCdVw9OvuAgQ. (state.change.logger)
kafka                    | [2025-10-03 16:12:10,878] INFO [Partition __consumer_offsets-32 broker=1] Log loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Partition)
kafka                    | [2025-10-03 16:12:10,878] INFO [Broker id=1] Follower __consumer_offsets-32 starts at leader epoch 169 from offset 0 with partition epoch 169 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 169. (state.change.logger)
kafka                    | [2025-10-03 16:12:10,878] INFO [Broker id=1] Creating new partition __consumer_offsets-28 with topic id iNBYdjYeRpSCdVw9OvuAgQ. (state.change.logger)
kafka                    | [2025-10-03 16:12:10,879] INFO [Partition __consumer_offsets-28 broker=1] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)
kafka                    | [2025-10-03 16:12:10,885] INFO [Broker id=1] Follower __consumer_offsets-28 starts at leader epoch 169 from offset 0 with partition epoch 169 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 169. (state.change.logger)
kafka                    | [2025-10-03 16:12:10,893] INFO [Broker id=1] Creating new partition __consumer_offsets-7 with topic id iNBYdjYeRpSCdVw9OvuAgQ. (state.change.logger)
kafka                    | [2025-10-03 16:12:10,936] INFO [Partition __consumer_offsets-7 broker=1] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
kafka                    | [2025-10-03 16:12:10,936] INFO [Broker id=1] Follower __consumer_offsets-7 starts at leader epoch 169 from offset 0 with partition epoch 169 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 169. (state.change.logger)
kafka                    | [2025-10-03 16:12:10,936] INFO [Broker id=1] Creating new partition __consumer_offsets-40 with topic id iNBYdjYeRpSCdVw9OvuAgQ. (state.change.logger)
kafka                    | [2025-10-03 16:12:10,950] INFO [Partition __consumer_offsets-40 broker=1] Log loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Partition)
kafka                    | [2025-10-03 16:12:10,954] INFO [Broker id=1] Follower __consumer_offsets-40 starts at leader epoch 169 from offset 0 with partition epoch 169 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 169. (state.change.logger)
kafka                    | [2025-10-03 16:12:10,961] INFO [Broker id=1] Creating new partition __consumer_offsets-3 with topic id iNBYdjYeRpSCdVw9OvuAgQ. (state.change.logger)
kafka                    | [2025-10-03 16:12:10,962] INFO [Partition __consumer_offsets-3 broker=1] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
kafka                    | [2025-10-03 16:12:10,965] INFO [Broker id=1] Follower __consumer_offsets-3 starts at leader epoch 169 from offset 0 with partition epoch 169 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 169. (state.change.logger)
kafka                    | [2025-10-03 16:12:10,965] INFO [Broker id=1] Creating new partition __consumer_offsets-36 with topic id iNBYdjYeRpSCdVw9OvuAgQ. (state.change.logger)
kafka                    | [2025-10-03 16:12:10,967] INFO [Partition __consumer_offsets-36 broker=1] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)
kafka                    | [2025-10-03 16:12:10,969] INFO [Broker id=1] Follower __consumer_offsets-36 starts at leader epoch 169 from offset 0 with partition epoch 169 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 169. (state.change.logger)
kafka                    | [2025-10-03 16:12:10,974] INFO [Broker id=1] Creating new partition __consumer_offsets-47 with topic id iNBYdjYeRpSCdVw9OvuAgQ. (state.change.logger)
kafka                    | [2025-10-03 16:12:10,983] INFO [Partition __consumer_offsets-47 broker=1] Log loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Partition)
kafka                    | [2025-10-03 16:12:10,983] INFO [Broker id=1] Follower __consumer_offsets-47 starts at leader epoch 169 from offset 0 with partition epoch 169 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 169. (state.change.logger)
kafka                    | [2025-10-03 16:12:10,984] INFO [Broker id=1] Creating new partition __consumer_offsets-14 with topic id iNBYdjYeRpSCdVw9OvuAgQ. (state.change.logger)
kafka                    | [2025-10-03 16:12:10,993] INFO [Partition __consumer_offsets-14 broker=1] Log loaded for partition __consumer_offsets-14 with initial high watermark 162 (kafka.cluster.Partition)
kafka                    | [2025-10-03 16:12:10,994] INFO [Broker id=1] Follower __consumer_offsets-14 starts at leader epoch 169 from offset 162 with partition epoch 169 and high watermark 162. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 169. (state.change.logger)
kafka                    | [2025-10-03 16:12:10,995] INFO [Broker id=1] Creating new partition __consumer_offsets-43 with topic id iNBYdjYeRpSCdVw9OvuAgQ. (state.change.logger)
kafka                    | [2025-10-03 16:12:11,002] INFO [Partition __consumer_offsets-43 broker=1] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)
kafka                    | [2025-10-03 16:12:11,032] INFO [Broker id=1] Follower __consumer_offsets-43 starts at leader epoch 169 from offset 0 with partition epoch 169 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 169. (state.change.logger)
kafka                    | [2025-10-03 16:12:11,041] INFO [Broker id=1] Creating new partition __consumer_offsets-10 with topic id iNBYdjYeRpSCdVw9OvuAgQ. (state.change.logger)
kafka                    | [2025-10-03 16:12:11,045] INFO [Partition __consumer_offsets-10 broker=1] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
kafka                    | [2025-10-03 16:12:11,045] INFO [Broker id=1] Follower __consumer_offsets-10 starts at leader epoch 169 from offset 0 with partition epoch 169 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 169. (state.change.logger)
kafka                    | [2025-10-03 16:12:11,045] INFO [Broker id=1] Creating new partition transfer.completed-0 with topic id KnRdX7QnQJmUANpwxqvSDg. (state.change.logger)
kafka                    | [2025-10-03 16:12:11,056] INFO [Partition transfer.completed-0 broker=1] Log loaded for partition transfer.completed-0 with initial high watermark 0 (kafka.cluster.Partition)
kafka                    | [2025-10-03 16:12:11,057] INFO [Broker id=1] Follower transfer.completed-0 starts at leader epoch 169 from offset 0 with partition epoch 169 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 169. (state.change.logger)
kafka                    | [2025-10-03 16:12:11,061] INFO [Broker id=1] Creating new partition __consumer_offsets-22 with topic id iNBYdjYeRpSCdVw9OvuAgQ. (state.change.logger)
kafka                    | [2025-10-03 16:12:11,063] INFO [Partition __consumer_offsets-22 broker=1] Log loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Partition)
kafka                    | [2025-10-03 16:12:11,069] INFO [Broker id=1] Follower __consumer_offsets-22 starts at leader epoch 169 from offset 0 with partition epoch 169 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 169. (state.change.logger)
kafka                    | [2025-10-03 16:12:11,070] INFO [Broker id=1] Creating new partition kyc-events-0 with topic id xrkFKQ2_RwCJqp4b4WCWXQ. (state.change.logger)
kafka                    | [2025-10-03 16:12:11,073] INFO [Partition kyc-events-0 broker=1] Log loaded for partition kyc-events-0 with initial high watermark 0 (kafka.cluster.Partition)
kafka                    | [2025-10-03 16:12:11,074] INFO [Broker id=1] Follower kyc-events-0 starts at leader epoch 23 from offset 0 with partition epoch 23 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 23. (state.change.logger)
kafka                    | [2025-10-03 16:12:11,074] INFO [Broker id=1] Creating new partition __consumer_offsets-18 with topic id iNBYdjYeRpSCdVw9OvuAgQ. (state.change.logger)
kafka                    | [2025-10-03 16:12:11,075] INFO [Partition __consumer_offsets-18 broker=1] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
kafka                    | [2025-10-03 16:12:11,076] INFO [Broker id=1] Follower __consumer_offsets-18 starts at leader epoch 169 from offset 0 with partition epoch 169 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 169. (state.change.logger)
kafka                    | [2025-10-03 16:12:11,076] INFO [Broker id=1] Creating new partition __consumer_offsets-31 with topic id iNBYdjYeRpSCdVw9OvuAgQ. (state.change.logger)
kafka                    | [2025-10-03 16:12:11,078] INFO [Partition __consumer_offsets-31 broker=1] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)
kafka                    | [2025-10-03 16:12:11,078] INFO [Broker id=1] Follower __consumer_offsets-31 starts at leader epoch 169 from offset 0 with partition epoch 169 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 169. (state.change.logger)
kafka                    | [2025-10-03 16:12:11,078] INFO [Broker id=1] Creating new partition __consumer_offsets-27 with topic id iNBYdjYeRpSCdVw9OvuAgQ. (state.change.logger)
kafka                    | [2025-10-03 16:12:11,080] INFO [Partition __consumer_offsets-27 broker=1] Log loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Partition)
kafka                    | [2025-10-03 16:12:11,080] INFO [Broker id=1] Follower __consumer_offsets-27 starts at leader epoch 169 from offset 0 with partition epoch 169 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 169. (state.change.logger)
kafka                    | [2025-10-03 16:12:11,080] INFO [Broker id=1] Creating new partition transfer-completed-events-0 with topic id ltyY2IODSnCcb9DcVhT46A. (state.change.logger)
kafka                    | [2025-10-03 16:12:11,083] INFO [Partition transfer-completed-events-0 broker=1] Log loaded for partition transfer-completed-events-0 with initial high watermark 0 (kafka.cluster.Partition)
kafka                    | [2025-10-03 16:12:11,083] INFO [Broker id=1] Follower transfer-completed-events-0 starts at leader epoch 169 from offset 0 with partition epoch 169 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 169. (state.change.logger)
kafka                    | [2025-10-03 16:12:11,095] INFO [Broker id=1] Creating new partition __consumer_offsets-39 with topic id iNBYdjYeRpSCdVw9OvuAgQ. (state.change.logger)
kafka                    | [2025-10-03 16:12:11,096] INFO [Partition __consumer_offsets-39 broker=1] Log loaded for partition __consumer_offsets-39 with initial high watermark 168 (kafka.cluster.Partition)
kafka                    | [2025-10-03 16:12:11,097] INFO [Broker id=1] Follower __consumer_offsets-39 starts at leader epoch 169 from offset 168 with partition epoch 169 and high watermark 168. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 169. (state.change.logger)
kafka                    | [2025-10-03 16:12:11,097] INFO [Broker id=1] Creating new partition __consumer_offsets-6 with topic id iNBYdjYeRpSCdVw9OvuAgQ. (state.change.logger)
kafka                    | [2025-10-03 16:12:11,103] INFO [Partition __consumer_offsets-6 broker=1] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
kafka                    | [2025-10-03 16:12:11,106] INFO [Broker id=1] Follower __consumer_offsets-6 starts at leader epoch 169 from offset 0 with partition epoch 169 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 169. (state.change.logger)
kafka                    | [2025-10-03 16:12:11,106] INFO [Broker id=1] Creating new partition login-attempts-topic-0 with topic id C9qPgaLVTKmphRtrR47kPQ. (state.change.logger)
kafka                    | [2025-10-03 16:12:11,107] INFO [Partition login-attempts-topic-0 broker=1] Log loaded for partition login-attempts-topic-0 with initial high watermark 0 (kafka.cluster.Partition)
kafka                    | [2025-10-03 16:12:11,109] INFO [Broker id=1] Follower login-attempts-topic-0 starts at leader epoch 169 from offset 0 with partition epoch 169 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 169. (state.change.logger)
kafka                    | [2025-10-03 16:12:11,110] INFO [Broker id=1] Creating new partition __consumer_offsets-35 with topic id iNBYdjYeRpSCdVw9OvuAgQ. (state.change.logger)
kafka                    | [2025-10-03 16:12:11,118] INFO [Partition __consumer_offsets-35 broker=1] Log loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Partition)
kafka                    | [2025-10-03 16:12:11,119] INFO [Broker id=1] Follower __consumer_offsets-35 starts at leader epoch 169 from offset 0 with partition epoch 169 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 169. (state.change.logger)
kafka                    | [2025-10-03 16:12:11,119] INFO [Broker id=1] Creating new partition __consumer_offsets-2 with topic id iNBYdjYeRpSCdVw9OvuAgQ. (state.change.logger)
kafka                    | [2025-10-03 16:12:11,122] INFO [Partition __consumer_offsets-2 broker=1] Log loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Partition)
kafka                    | [2025-10-03 16:12:11,122] INFO [Broker id=1] Follower __consumer_offsets-2 starts at leader epoch 169 from offset 0 with partition epoch 169 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 169. (state.change.logger)
kafka                    | [2025-10-03 16:12:11,147] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(__consumer_offsets-49, __consumer_offsets-38, __consumer_offsets-27, __consumer_offsets-16, __consumer_offsets-8, __consumer_offsets-19, transfer.completed-0, __consumer_offsets-2, __consumer_offsets-13, __consumer_offsets-35, __consumer_offsets-24, __consumer_offsets-46, __consumer_offsets-5, __consumer_offsets-43, __consumer_offsets-21, __consumer_offsets-32, login-attempts-topic-0, __consumer_offsets-10, __consumer_offsets-37, __consumer_offsets-48, __consumer_offsets-29, __consumer_offsets-40, __consumer_offsets-18, __consumer_offsets-7, __consumer_offsets-45, __consumer_offsets-34, __consumer_offsets-23, __consumer_offsets-26, __consumer_offsets-4, __consumer_offsets-15, __consumer_offsets-42, __consumer_offsets-20, __consumer_offsets-9, __consumer_offsets-31, __consumer_offsets-12, password.changed-0, __consumer_offsets-1, transfer-completed-events-0, __consumer_offsets-17, __consumer_offsets-28, __consumer_offsets-6, kyc-events-0, __consumer_offsets-39, __consumer_offsets-44, __consumer_offsets-36, __consumer_offsets-47, __consumer_offsets-25, __consumer_offsets-3, __consumer_offsets-14, __consumer_offsets-41, __consumer_offsets-30, user.registered-0, __consumer_offsets-33, __consumer_offsets-11, __consumer_offsets-22, __consumer_offsets-0) (kafka.server.ReplicaFetcherManager)
kafka                    | [2025-10-03 16:12:11,149] INFO [Broker id=1] Stopped fetchers as part of become-follower for 56 partitions (state.change.logger)
kafka                    | [2025-10-03 16:12:11,179] INFO [Broker id=1] Started fetchers as part of become-follower for 56 partitions (state.change.logger)
kafka                    | [2025-10-03 16:12:11,469] INFO [GroupCoordinator 1]: Resigned as the group coordinator for partition 13 in epoch OptionalInt[169] (kafka.coordinator.group.GroupCoordinator)
kafka                    | [2025-10-03 16:12:11,492] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-13 (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:11,504] INFO [GroupCoordinator 1]: Resigned as the group coordinator for partition 46 in epoch OptionalInt[169] (kafka.coordinator.group.GroupCoordinator)
kafka                    | [2025-10-03 16:12:11,504] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-46 (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:11,507] INFO [GroupCoordinator 1]: Resigned as the group coordinator for partition 9 in epoch OptionalInt[169] (kafka.coordinator.group.GroupCoordinator)
kafka                    | [2025-10-03 16:12:11,512] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-9 (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:11,517] INFO [GroupCoordinator 1]: Resigned as the group coordinator for partition 42 in epoch OptionalInt[169] (kafka.coordinator.group.GroupCoordinator)
kafka                    | [2025-10-03 16:12:11,519] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-42 (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:11,521] INFO [GroupCoordinator 1]: Resigned as the group coordinator for partition 21 in epoch OptionalInt[169] (kafka.coordinator.group.GroupCoordinator)
kafka                    | [2025-10-03 16:12:11,521] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-21 (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:11,521] INFO [GroupCoordinator 1]: Resigned as the group coordinator for partition 17 in epoch OptionalInt[169] (kafka.coordinator.group.GroupCoordinator)
kafka                    | [2025-10-03 16:12:11,521] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-17 (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:11,521] INFO [GroupCoordinator 1]: Resigned as the group coordinator for partition 30 in epoch OptionalInt[169] (kafka.coordinator.group.GroupCoordinator)
kafka                    | [2025-10-03 16:12:11,521] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-30 (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:11,521] INFO [GroupCoordinator 1]: Resigned as the group coordinator for partition 26 in epoch OptionalInt[169] (kafka.coordinator.group.GroupCoordinator)
kafka                    | [2025-10-03 16:12:11,521] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-26 (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:11,521] INFO [GroupCoordinator 1]: Resigned as the group coordinator for partition 5 in epoch OptionalInt[169] (kafka.coordinator.group.GroupCoordinator)
kafka                    | [2025-10-03 16:12:11,521] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-5 (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:11,521] INFO [GroupCoordinator 1]: Resigned as the group coordinator for partition 38 in epoch OptionalInt[169] (kafka.coordinator.group.GroupCoordinator)
kafka                    | [2025-10-03 16:12:11,521] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-38 (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:11,521] INFO [GroupCoordinator 1]: Resigned as the group coordinator for partition 1 in epoch OptionalInt[169] (kafka.coordinator.group.GroupCoordinator)
kafka                    | [2025-10-03 16:12:11,521] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-1 (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:11,521] INFO [GroupCoordinator 1]: Resigned as the group coordinator for partition 34 in epoch OptionalInt[169] (kafka.coordinator.group.GroupCoordinator)
kafka                    | [2025-10-03 16:12:11,521] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-34 (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:11,521] INFO [GroupCoordinator 1]: Resigned as the group coordinator for partition 16 in epoch OptionalInt[169] (kafka.coordinator.group.GroupCoordinator)
kafka                    | [2025-10-03 16:12:11,521] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-16 (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:11,521] INFO [GroupCoordinator 1]: Resigned as the group coordinator for partition 45 in epoch OptionalInt[169] (kafka.coordinator.group.GroupCoordinator)
kafka                    | [2025-10-03 16:12:11,521] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-45 (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:11,521] INFO [GroupCoordinator 1]: Resigned as the group coordinator for partition 12 in epoch OptionalInt[169] (kafka.coordinator.group.GroupCoordinator)
kafka                    | [2025-10-03 16:12:11,521] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-12 (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:11,521] INFO [GroupCoordinator 1]: Resigned as the group coordinator for partition 41 in epoch OptionalInt[169] (kafka.coordinator.group.GroupCoordinator)
kafka                    | [2025-10-03 16:12:11,521] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-41 (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:11,521] INFO [GroupCoordinator 1]: Resigned as the group coordinator for partition 24 in epoch OptionalInt[169] (kafka.coordinator.group.GroupCoordinator)
kafka                    | [2025-10-03 16:12:11,521] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-24 (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:11,521] INFO [GroupCoordinator 1]: Resigned as the group coordinator for partition 20 in epoch OptionalInt[169] (kafka.coordinator.group.GroupCoordinator)
kafka                    | [2025-10-03 16:12:11,521] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-20 (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:11,521] INFO [GroupCoordinator 1]: Resigned as the group coordinator for partition 49 in epoch OptionalInt[169] (kafka.coordinator.group.GroupCoordinator)
kafka                    | [2025-10-03 16:12:11,528] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-49 (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:11,530] INFO [GroupCoordinator 1]: Resigned as the group coordinator for partition 0 in epoch OptionalInt[169] (kafka.coordinator.group.GroupCoordinator)
kafka                    | [2025-10-03 16:12:11,543] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-0 (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:11,544] INFO [GroupCoordinator 1]: Resigned as the group coordinator for partition 29 in epoch OptionalInt[169] (kafka.coordinator.group.GroupCoordinator)
kafka                    | [2025-10-03 16:12:11,544] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-29 (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:11,544] INFO [GroupCoordinator 1]: Resigned as the group coordinator for partition 25 in epoch OptionalInt[169] (kafka.coordinator.group.GroupCoordinator)
kafka                    | [2025-10-03 16:12:11,544] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-25 (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:11,544] INFO [GroupCoordinator 1]: Resigned as the group coordinator for partition 8 in epoch OptionalInt[169] (kafka.coordinator.group.GroupCoordinator)
kafka                    | [2025-10-03 16:12:11,544] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-8 (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:11,544] INFO [GroupCoordinator 1]: Resigned as the group coordinator for partition 37 in epoch OptionalInt[169] (kafka.coordinator.group.GroupCoordinator)
kafka                    | [2025-10-03 16:12:11,544] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-37 (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:11,544] INFO [GroupCoordinator 1]: Resigned as the group coordinator for partition 4 in epoch OptionalInt[169] (kafka.coordinator.group.GroupCoordinator)
kafka                    | [2025-10-03 16:12:11,544] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-4 (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:11,544] INFO [GroupCoordinator 1]: Resigned as the group coordinator for partition 33 in epoch OptionalInt[169] (kafka.coordinator.group.GroupCoordinator)
kafka                    | [2025-10-03 16:12:11,544] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-33 (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:11,544] INFO [GroupCoordinator 1]: Resigned as the group coordinator for partition 15 in epoch OptionalInt[169] (kafka.coordinator.group.GroupCoordinator)
kafka                    | [2025-10-03 16:12:11,544] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-15 (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:11,544] INFO [GroupCoordinator 1]: Resigned as the group coordinator for partition 48 in epoch OptionalInt[169] (kafka.coordinator.group.GroupCoordinator)
kafka                    | [2025-10-03 16:12:11,544] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-48 (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:11,544] INFO [GroupCoordinator 1]: Resigned as the group coordinator for partition 11 in epoch OptionalInt[169] (kafka.coordinator.group.GroupCoordinator)
kafka                    | [2025-10-03 16:12:11,544] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-11 (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:11,544] INFO [GroupCoordinator 1]: Resigned as the group coordinator for partition 44 in epoch OptionalInt[169] (kafka.coordinator.group.GroupCoordinator)
kafka                    | [2025-10-03 16:12:11,544] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-44 (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:11,544] INFO [GroupCoordinator 1]: Resigned as the group coordinator for partition 23 in epoch OptionalInt[169] (kafka.coordinator.group.GroupCoordinator)
kafka                    | [2025-10-03 16:12:11,544] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-23 (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:11,544] INFO [GroupCoordinator 1]: Resigned as the group coordinator for partition 19 in epoch OptionalInt[169] (kafka.coordinator.group.GroupCoordinator)
kafka                    | [2025-10-03 16:12:11,545] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-19 (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:11,545] INFO [GroupCoordinator 1]: Resigned as the group coordinator for partition 32 in epoch OptionalInt[169] (kafka.coordinator.group.GroupCoordinator)
kafka                    | [2025-10-03 16:12:11,545] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-32 (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:11,545] INFO [GroupCoordinator 1]: Resigned as the group coordinator for partition 28 in epoch OptionalInt[169] (kafka.coordinator.group.GroupCoordinator)
kafka                    | [2025-10-03 16:12:11,545] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-28 (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:11,545] INFO [GroupCoordinator 1]: Resigned as the group coordinator for partition 7 in epoch OptionalInt[169] (kafka.coordinator.group.GroupCoordinator)
kafka                    | [2025-10-03 16:12:11,545] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-7 (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:11,545] INFO [GroupCoordinator 1]: Resigned as the group coordinator for partition 40 in epoch OptionalInt[169] (kafka.coordinator.group.GroupCoordinator)
kafka                    | [2025-10-03 16:12:11,546] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-40 (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:11,546] INFO [GroupCoordinator 1]: Resigned as the group coordinator for partition 3 in epoch OptionalInt[169] (kafka.coordinator.group.GroupCoordinator)
kafka                    | [2025-10-03 16:12:11,546] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-3 (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:11,546] INFO [GroupCoordinator 1]: Resigned as the group coordinator for partition 36 in epoch OptionalInt[169] (kafka.coordinator.group.GroupCoordinator)
kafka                    | [2025-10-03 16:12:11,546] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-36 (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:11,546] INFO [GroupCoordinator 1]: Resigned as the group coordinator for partition 47 in epoch OptionalInt[169] (kafka.coordinator.group.GroupCoordinator)
kafka                    | [2025-10-03 16:12:11,546] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-47 (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:11,546] INFO [GroupCoordinator 1]: Resigned as the group coordinator for partition 14 in epoch OptionalInt[169] (kafka.coordinator.group.GroupCoordinator)
kafka                    | [2025-10-03 16:12:11,546] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-14 (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:11,547] INFO [GroupCoordinator 1]: Resigned as the group coordinator for partition 43 in epoch OptionalInt[169] (kafka.coordinator.group.GroupCoordinator)
kafka                    | [2025-10-03 16:12:11,548] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-43 (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:11,549] INFO [GroupCoordinator 1]: Resigned as the group coordinator for partition 10 in epoch OptionalInt[169] (kafka.coordinator.group.GroupCoordinator)
kafka                    | [2025-10-03 16:12:11,549] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-10 (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:11,549] INFO [GroupCoordinator 1]: Resigned as the group coordinator for partition 22 in epoch OptionalInt[169] (kafka.coordinator.group.GroupCoordinator)
kafka                    | [2025-10-03 16:12:11,549] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-22 (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:11,550] INFO [GroupCoordinator 1]: Resigned as the group coordinator for partition 18 in epoch OptionalInt[169] (kafka.coordinator.group.GroupCoordinator)
kafka                    | [2025-10-03 16:12:11,550] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-18 (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:11,550] INFO [GroupCoordinator 1]: Resigned as the group coordinator for partition 31 in epoch OptionalInt[169] (kafka.coordinator.group.GroupCoordinator)
kafka                    | [2025-10-03 16:12:11,556] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-31 (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:11,556] INFO [GroupCoordinator 1]: Resigned as the group coordinator for partition 27 in epoch OptionalInt[169] (kafka.coordinator.group.GroupCoordinator)
kafka                    | [2025-10-03 16:12:11,556] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-27 (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:11,556] INFO [GroupCoordinator 1]: Resigned as the group coordinator for partition 39 in epoch OptionalInt[169] (kafka.coordinator.group.GroupCoordinator)
kafka                    | [2025-10-03 16:12:11,556] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-39 (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:11,556] INFO [GroupCoordinator 1]: Resigned as the group coordinator for partition 6 in epoch OptionalInt[169] (kafka.coordinator.group.GroupCoordinator)
kafka                    | [2025-10-03 16:12:11,556] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-6 (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:11,557] INFO [GroupCoordinator 1]: Resigned as the group coordinator for partition 35 in epoch OptionalInt[169] (kafka.coordinator.group.GroupCoordinator)
bankapp                  | 
bankapp                  |   .   ____          _            __ _ _
bankapp                  |  /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \
bankapp                  | ( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \
bankapp                  |  \\/  ___)| |_)| | | | | || (_| |  ) ) ) )
bankapp                  |   '  |____| .__|_| |_|_| |_\__, | / / / /
bankapp                  |  =========|_|==============|___/=/_/_/_/
bankapp                  | 
kafka                    | [2025-10-03 16:12:11,557] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-35 (kafka.coordinator.group.GroupMetadataManager)
bankapp                  |  :: Spring Boot ::                (v3.5.0)
bankapp                  | 
kafka                    | [2025-10-03 16:12:11,557] INFO [GroupCoordinator 1]: Resigned as the group coordinator for partition 2 in epoch OptionalInt[169] (kafka.coordinator.group.GroupCoordinator)
kafka                    | [2025-10-03 16:12:11,557] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-2 (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:11,619] INFO [DynamicConfigPublisher broker id=1] Updating topic __consumer_offsets with new configuration : cleanup.policy -> compact,segment.bytes -> 104857600,compression.type -> producer (kafka.server.metadata.DynamicConfigPublisher)
kafka                    | [2025-10-03 16:12:11,637] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-13 for coordinator epoch OptionalInt[169]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:11,638] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-46 for coordinator epoch OptionalInt[169]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:11,638] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-9 for coordinator epoch OptionalInt[169]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:11,638] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-42 for coordinator epoch OptionalInt[169]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:11,638] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-21 for coordinator epoch OptionalInt[169]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:11,638] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-17 for coordinator epoch OptionalInt[169]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:11,638] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-30 for coordinator epoch OptionalInt[169]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:11,638] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-26 for coordinator epoch OptionalInt[169]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:11,638] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-5 for coordinator epoch OptionalInt[169]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:11,638] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-38 for coordinator epoch OptionalInt[169]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:11,638] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-1 for coordinator epoch OptionalInt[169]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:11,638] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-34 for coordinator epoch OptionalInt[169]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:11,638] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-16 for coordinator epoch OptionalInt[169]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:11,638] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-45 for coordinator epoch OptionalInt[169]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:11,638] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-12 for coordinator epoch OptionalInt[169]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:11,638] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-41 for coordinator epoch OptionalInt[169]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:11,638] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-24 for coordinator epoch OptionalInt[169]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:11,638] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-20 for coordinator epoch OptionalInt[169]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:11,638] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-49 for coordinator epoch OptionalInt[169]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:11,638] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-0 for coordinator epoch OptionalInt[169]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:11,639] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-29 for coordinator epoch OptionalInt[169]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:11,639] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-25 for coordinator epoch OptionalInt[169]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:11,639] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-8 for coordinator epoch OptionalInt[169]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:11,639] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-37 for coordinator epoch OptionalInt[169]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:11,639] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-4 for coordinator epoch OptionalInt[169]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:11,639] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-33 for coordinator epoch OptionalInt[169]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:11,639] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-15 for coordinator epoch OptionalInt[169]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:11,658] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-48 for coordinator epoch OptionalInt[169]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:11,658] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-11 for coordinator epoch OptionalInt[169]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:11,658] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-44 for coordinator epoch OptionalInt[169]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:11,658] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-23 for coordinator epoch OptionalInt[169]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:11,658] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-19 for coordinator epoch OptionalInt[169]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:11,659] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-32 for coordinator epoch OptionalInt[169]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:11,659] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-28 for coordinator epoch OptionalInt[169]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:11,659] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-7 for coordinator epoch OptionalInt[169]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:11,675] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-40 for coordinator epoch OptionalInt[169]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:11,675] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-3 for coordinator epoch OptionalInt[169]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:11,675] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-36 for coordinator epoch OptionalInt[169]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:11,675] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-47 for coordinator epoch OptionalInt[169]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:11,700] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-14 for coordinator epoch OptionalInt[169]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:11,700] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-43 for coordinator epoch OptionalInt[169]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:11,700] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-10 for coordinator epoch OptionalInt[169]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:11,700] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-22 for coordinator epoch OptionalInt[169]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:11,700] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-18 for coordinator epoch OptionalInt[169]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:11,701] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-31 for coordinator epoch OptionalInt[169]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:11,701] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-27 for coordinator epoch OptionalInt[169]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:11,701] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-39 for coordinator epoch OptionalInt[169]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:11,702] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-6 for coordinator epoch OptionalInt[169]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:11,702] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-35 for coordinator epoch OptionalInt[169]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:11,702] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-2 for coordinator epoch OptionalInt[169]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
auth-statistics-service  | 
auth-statistics-service  |   .   ____          _            __ _ _
auth-statistics-service  |  /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \
auth-statistics-service  | ( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \
auth-statistics-service  |  \\/  ___)| |_)| | | | | || (_| |  ) ) ) )
auth-statistics-service  |   '  |____| .__|_| |_|_| |_\__, | / / / /
auth-statistics-service  |  =========|_|==============|___/=/_/_/_/
auth-statistics-service  | 
auth-statistics-service  |  :: Spring Boot ::                (v3.5.0)
auth-statistics-service  | 
kafka                    | [2025-10-03 16:12:12,046] INFO [BrokerLifecycleManager id=1] The broker has caught up. Transitioning from STARTING to RECOVERY. (kafka.server.BrokerLifecycleManager)
kafka                    | [2025-10-03 16:12:12,077] INFO [BrokerServer id=1] Finished waiting for the controller to acknowledge that we are caught up (kafka.server.BrokerServer)
kafka                    | [2025-10-03 16:12:12,078] INFO [BrokerServer id=1] Waiting for the initial broker metadata update to be published (kafka.server.BrokerServer)
kafka                    | [2025-10-03 16:12:12,079] INFO [BrokerServer id=1] Finished waiting for the initial broker metadata update to be published (kafka.server.BrokerServer)
kafka                    | [2025-10-03 16:12:12,222] INFO [BrokerLifecycleManager id=1] The broker is in RECOVERY. (kafka.server.BrokerLifecycleManager)
kafka                    | [2025-10-03 16:12:12,237] INFO KafkaConfig values: 
kafka                    | 	advertised.listeners = PLAINTEXT://kafka:9092,EXTERNAL://localhost:9094
kafka                    | 	alter.config.policy.class.name = null
kafka                    | 	alter.log.dirs.replication.quota.window.num = 11
kafka                    | 	alter.log.dirs.replication.quota.window.size.seconds = 1
kafka                    | 	authorizer.class.name = 
kafka                    | 	auto.create.topics.enable = true
kafka                    | 	auto.include.jmx.reporter = true
kafka                    | 	auto.leader.rebalance.enable = true
kafka                    | 	background.threads = 10
kafka                    | 	broker.heartbeat.interval.ms = 2000
kafka                    | 	broker.id = 1
kafka                    | 	broker.id.generation.enable = true
kafka                    | 	broker.rack = null
kafka                    | 	broker.session.timeout.ms = 9000
kafka                    | 	client.quota.callback.class = null
kafka                    | 	compression.type = producer
kafka                    | 	connection.failed.authentication.delay.ms = 100
kafka                    | 	connections.max.idle.ms = 600000
kafka                    | 	connections.max.reauth.ms = 0
kafka                    | 	control.plane.listener.name = null
kafka                    | 	controlled.shutdown.enable = true
kafka                    | 	controlled.shutdown.max.retries = 3
kafka                    | 	controlled.shutdown.retry.backoff.ms = 5000
kafka                    | 	controller.listener.names = CONTROLLER
kafka                    | 	controller.quorum.append.linger.ms = 25
kafka                    | 	controller.quorum.election.backoff.max.ms = 1000
kafka                    | 	controller.quorum.election.timeout.ms = 1000
kafka                    | 	controller.quorum.fetch.timeout.ms = 2000
kafka                    | 	controller.quorum.request.timeout.ms = 2000
kafka                    | 	controller.quorum.retry.backoff.ms = 20
kafka                    | 	controller.quorum.voters = [1@kafka:9093]
kafka                    | 	controller.quota.window.num = 11
kafka                    | 	controller.quota.window.size.seconds = 1
kafka                    | 	controller.socket.timeout.ms = 30000
kafka                    | 	create.topic.policy.class.name = null
kafka                    | 	default.replication.factor = 1
kafka                    | 	delegation.token.expiry.check.interval.ms = 3600000
kafka                    | 	delegation.token.expiry.time.ms = 86400000
kafka                    | 	delegation.token.master.key = null
kafka                    | 	delegation.token.max.lifetime.ms = 604800000
kafka                    | 	delegation.token.secret.key = null
kafka                    | 	delete.records.purgatory.purge.interval.requests = 1
kafka                    | 	delete.topic.enable = true
kafka                    | 	early.start.listeners = null
kafka                    | 	fetch.max.bytes = 57671680
kafka                    | 	fetch.purgatory.purge.interval.requests = 1000
kafka                    | 	group.consumer.assignors = [org.apache.kafka.coordinator.group.assignor.RangeAssignor]
kafka                    | 	group.consumer.heartbeat.interval.ms = 5000
kafka                    | 	group.consumer.max.heartbeat.interval.ms = 15000
kafka                    | 	group.consumer.max.session.timeout.ms = 60000
kafka                    | 	group.consumer.max.size = 2147483647
kafka                    | 	group.consumer.min.heartbeat.interval.ms = 5000
kafka                    | 	group.consumer.min.session.timeout.ms = 45000
kafka                    | 	group.consumer.session.timeout.ms = 45000
kafka                    | 	group.coordinator.new.enable = false
kafka                    | 	group.coordinator.threads = 1
kafka                    | 	group.initial.rebalance.delay.ms = 3000
kafka                    | 	group.max.session.timeout.ms = 1800000
kafka                    | 	group.max.size = 2147483647
kafka                    | 	group.min.session.timeout.ms = 6000
kafka                    | 	initial.broker.registration.timeout.ms = 60000
kafka                    | 	inter.broker.listener.name = PLAINTEXT
kafka                    | 	inter.broker.protocol.version = 3.6-IV2
kafka                    | 	kafka.metrics.polling.interval.secs = 10
kafka                    | 	kafka.metrics.reporters = []
kafka                    | 	leader.imbalance.check.interval.seconds = 300
kafka                    | 	leader.imbalance.per.broker.percentage = 10
kafka                    | 	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,EXTERNAL:PLAINTEXT,CONTROLLER:PLAINTEXT
kafka                    | 	listeners = PLAINTEXT://0.0.0.0:9092,EXTERNAL://0.0.0.0:9094,CONTROLLER://0.0.0.0:9093
kafka                    | 	log.cleaner.backoff.ms = 15000
kafka                    | 	log.cleaner.dedupe.buffer.size = 134217728
kafka                    | 	log.cleaner.delete.retention.ms = 86400000
kafka                    | 	log.cleaner.enable = true
kafka                    | 	log.cleaner.io.buffer.load.factor = 0.9
kafka                    | 	log.cleaner.io.buffer.size = 524288
kafka                    | 	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
kafka                    | 	log.cleaner.max.compaction.lag.ms = 9223372036854775807
kafka                    | 	log.cleaner.min.cleanable.ratio = 0.5
kafka                    | 	log.cleaner.min.compaction.lag.ms = 0
kafka                    | 	log.cleaner.threads = 1
kafka                    | 	log.cleanup.policy = [delete]
kafka                    | 	log.dir = /tmp/kafka-logs
kafka                    | 	log.dirs = /bitnami/kafka/data
kafka                    | 	log.flush.interval.messages = 9223372036854775807
kafka                    | 	log.flush.interval.ms = null
kafka                    | 	log.flush.offset.checkpoint.interval.ms = 60000
kafka                    | 	log.flush.scheduler.interval.ms = 9223372036854775807
kafka                    | 	log.flush.start.offset.checkpoint.interval.ms = 60000
kafka                    | 	log.index.interval.bytes = 4096
kafka                    | 	log.index.size.max.bytes = 10485760
kafka                    | 	log.local.retention.bytes = -2
kafka                    | 	log.local.retention.ms = -2
kafka                    | 	log.message.downconversion.enable = true
kafka                    | 	log.message.format.version = 3.0-IV1
kafka                    | 	log.message.timestamp.after.max.ms = 9223372036854775807
kafka                    | 	log.message.timestamp.before.max.ms = 9223372036854775807
kafka                    | 	log.message.timestamp.difference.max.ms = 9223372036854775807
kafka                    | 	log.message.timestamp.type = CreateTime
kafka                    | 	log.preallocate = false
kafka                    | 	log.retention.bytes = -1
kafka                    | 	log.retention.check.interval.ms = 300000
kafka                    | 	log.retention.hours = 168
kafka                    | 	log.retention.minutes = null
kafka                    | 	log.retention.ms = null
kafka                    | 	log.roll.hours = 168
kafka                    | 	log.roll.jitter.hours = 0
kafka                    | 	log.roll.jitter.ms = null
kafka                    | 	log.roll.ms = null
kafka                    | 	log.segment.bytes = 1073741824
kafka                    | 	log.segment.delete.delay.ms = 60000
kafka                    | 	max.connection.creation.rate = 2147483647
kafka                    | 	max.connections = 2147483647
kafka                    | 	max.connections.per.ip = 2147483647
kafka                    | 	max.connections.per.ip.overrides = 
kafka                    | 	max.incremental.fetch.session.cache.slots = 1000
kafka                    | 	message.max.bytes = 1048588
kafka                    | 	metadata.log.dir = null
kafka                    | 	metadata.log.max.record.bytes.between.snapshots = 20971520
kafka                    | 	metadata.log.max.snapshot.interval.ms = 3600000
kafka                    | 	metadata.log.segment.bytes = 1073741824
kafka                    | 	metadata.log.segment.min.bytes = 8388608
kafka                    | 	metadata.log.segment.ms = 604800000
kafka                    | 	metadata.max.idle.interval.ms = 500
kafka                    | 	metadata.max.retention.bytes = 104857600
kafka                    | 	metadata.max.retention.ms = 604800000
kafka                    | 	metric.reporters = []
kafka                    | 	metrics.num.samples = 2
kafka                    | 	metrics.recording.level = INFO
kafka                    | 	metrics.sample.window.ms = 30000
kafka                    | 	min.insync.replicas = 1
kafka                    | 	node.id = 1
kafka                    | 	num.io.threads = 8
kafka                    | 	num.network.threads = 3
kafka                    | 	num.partitions = 1
kafka                    | 	num.recovery.threads.per.data.dir = 1
kafka                    | 	num.replica.alter.log.dirs.threads = null
kafka                    | 	num.replica.fetchers = 1
kafka                    | 	offset.metadata.max.bytes = 4096
kafka                    | 	offsets.commit.required.acks = -1
kafka                    | 	offsets.commit.timeout.ms = 5000
kafka                    | 	offsets.load.buffer.size = 5242880
kafka                    | 	offsets.retention.check.interval.ms = 600000
kafka                    | 	offsets.retention.minutes = 10080
kafka                    | 	offsets.topic.compression.codec = 0
kafka                    | 	offsets.topic.num.partitions = 50
kafka                    | 	offsets.topic.replication.factor = 1
kafka                    | 	offsets.topic.segment.bytes = 104857600
kafka                    | 	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
kafka                    | 	password.encoder.iterations = 4096
kafka                    | 	password.encoder.key.length = 128
kafka                    | 	password.encoder.keyfactory.algorithm = null
kafka                    | 	password.encoder.old.secret = null
kafka                    | 	password.encoder.secret = null
kafka                    | 	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
kafka                    | 	process.roles = [controller, broker]
kafka                    | 	producer.id.expiration.check.interval.ms = 600000
kafka                    | 	producer.id.expiration.ms = 86400000
kafka                    | 	producer.purgatory.purge.interval.requests = 1000
kafka                    | 	queued.max.request.bytes = -1
kafka                    | 	queued.max.requests = 500
kafka                    | 	quota.window.num = 11
kafka                    | 	quota.window.size.seconds = 1
kafka                    | 	remote.log.index.file.cache.total.size.bytes = 1073741824
kafka                    | 	remote.log.manager.task.interval.ms = 30000
kafka                    | 	remote.log.manager.task.retry.backoff.max.ms = 30000
kafka                    | 	remote.log.manager.task.retry.backoff.ms = 500
kafka                    | 	remote.log.manager.task.retry.jitter = 0.2
kafka                    | 	remote.log.manager.thread.pool.size = 10
kafka                    | 	remote.log.metadata.custom.metadata.max.bytes = 128
kafka                    | 	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
kafka                    | 	remote.log.metadata.manager.class.path = null
kafka                    | 	remote.log.metadata.manager.impl.prefix = rlmm.config.
kafka                    | 	remote.log.metadata.manager.listener.name = null
kafka                    | 	remote.log.reader.max.pending.tasks = 100
kafka                    | 	remote.log.reader.threads = 10
kafka                    | 	remote.log.storage.manager.class.name = null
kafka                    | 	remote.log.storage.manager.class.path = null
kafka                    | 	remote.log.storage.manager.impl.prefix = rsm.config.
kafka                    | 	remote.log.storage.system.enable = false
kafka                    | 	replica.fetch.backoff.ms = 1000
kafka                    | 	replica.fetch.max.bytes = 1048576
kafka                    | 	replica.fetch.min.bytes = 1
kafka                    | 	replica.fetch.response.max.bytes = 10485760
kafka                    | 	replica.fetch.wait.max.ms = 500
kafka                    | 	replica.high.watermark.checkpoint.interval.ms = 5000
kafka                    | 	replica.lag.time.max.ms = 30000
kafka                    | 	replica.selector.class = null
kafka                    | 	replica.socket.receive.buffer.bytes = 65536
kafka                    | 	replica.socket.timeout.ms = 30000
kafka                    | 	replication.quota.window.num = 11
kafka                    | 	replication.quota.window.size.seconds = 1
kafka                    | 	request.timeout.ms = 30000
kafka                    | 	reserved.broker.max.id = 1000
kafka                    | 	sasl.client.callback.handler.class = null
kafka                    | 	sasl.enabled.mechanisms = [PLAIN, SCRAM-SHA-256, SCRAM-SHA-512]
kafka                    | 	sasl.jaas.config = null
kafka                    | 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
kafka                    | 	sasl.kerberos.min.time.before.relogin = 60000
kafka                    | 	sasl.kerberos.principal.to.local.rules = [DEFAULT]
kafka                    | 	sasl.kerberos.service.name = null
kafka                    | 	sasl.kerberos.ticket.renew.jitter = 0.05
kafka                    | 	sasl.kerberos.ticket.renew.window.factor = 0.8
kafka                    | 	sasl.login.callback.handler.class = null
kafka                    | 	sasl.login.class = null
kafka                    | 	sasl.login.connect.timeout.ms = null
kafka                    | 	sasl.login.read.timeout.ms = null
kafka                    | 	sasl.login.refresh.buffer.seconds = 300
kafka                    | 	sasl.login.refresh.min.period.seconds = 60
kafka                    | 	sasl.login.refresh.window.factor = 0.8
kafka                    | 	sasl.login.refresh.window.jitter = 0.05
kafka                    | 	sasl.login.retry.backoff.max.ms = 10000
kafka                    | 	sasl.login.retry.backoff.ms = 100
kafka                    | 	sasl.mechanism.controller.protocol = GSSAPI
kafka                    | 	sasl.mechanism.inter.broker.protocol = GSSAPI
kafka                    | 	sasl.oauthbearer.clock.skew.seconds = 30
kafka                    | 	sasl.oauthbearer.expected.audience = null
kafka                    | 	sasl.oauthbearer.expected.issuer = null
kafka                    | 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
kafka                    | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
kafka                    | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
kafka                    | 	sasl.oauthbearer.jwks.endpoint.url = null
kafka                    | 	sasl.oauthbearer.scope.claim.name = scope
kafka                    | 	sasl.oauthbearer.sub.claim.name = sub
kafka                    | 	sasl.oauthbearer.token.endpoint.url = null
kafka                    | 	sasl.server.callback.handler.class = null
kafka                    | 	sasl.server.max.receive.size = 524288
kafka                    | 	security.inter.broker.protocol = PLAINTEXT
kafka                    | 	security.providers = null
kafka                    | 	server.max.startup.time.ms = 9223372036854775807
kafka                    | 	socket.connection.setup.timeout.max.ms = 30000
kafka                    | 	socket.connection.setup.timeout.ms = 10000
kafka                    | 	socket.listen.backlog.size = 50
kafka                    | 	socket.receive.buffer.bytes = 102400
kafka                    | 	socket.request.max.bytes = 104857600
kafka                    | 	socket.send.buffer.bytes = 102400
kafka                    | 	ssl.cipher.suites = []
kafka                    | 	ssl.client.auth = none
kafka                    | 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
kafka                    | 	ssl.endpoint.identification.algorithm = https
kafka                    | 	ssl.engine.factory.class = null
kafka                    | 	ssl.key.password = null
kafka                    | 	ssl.keymanager.algorithm = SunX509
kafka                    | 	ssl.keystore.certificate.chain = null
kafka                    | 	ssl.keystore.key = null
kafka                    | 	ssl.keystore.location = null
kafka                    | 	ssl.keystore.password = null
kafka                    | 	ssl.keystore.type = JKS
kafka                    | 	ssl.principal.mapping.rules = DEFAULT
kafka                    | 	ssl.protocol = TLSv1.3
kafka                    | 	ssl.provider = null
kafka                    | 	ssl.secure.random.implementation = null
kafka                    | 	ssl.trustmanager.algorithm = PKIX
kafka                    | 	ssl.truststore.certificates = null
kafka                    | 	ssl.truststore.location = null
kafka                    | 	ssl.truststore.password = null
kafka                    | 	ssl.truststore.type = JKS
kafka                    | 	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
kafka                    | 	transaction.max.timeout.ms = 900000
kafka                    | 	transaction.partition.verification.enable = true
kafka                    | 	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
kafka                    | 	transaction.state.log.load.buffer.size = 5242880
kafka                    | 	transaction.state.log.min.isr = 1
kafka                    | 	transaction.state.log.num.partitions = 50
kafka                    | 	transaction.state.log.replication.factor = 1
kafka                    | 	transaction.state.log.segment.bytes = 104857600
kafka                    | 	transactional.id.expiration.ms = 604800000
kafka                    | 	unclean.leader.election.enable = false
kafka                    | 	unstable.api.versions.enable = false
kafka                    | 	zookeeper.clientCnxnSocket = null
kafka                    | 	zookeeper.connect = null
kafka                    | 	zookeeper.connection.timeout.ms = null
kafka                    | 	zookeeper.max.in.flight.requests = 10
kafka                    | 	zookeeper.metadata.migration.enable = false
kafka                    | 	zookeeper.metadata.migration.min.batch.size = 200
kafka                    | 	zookeeper.session.timeout.ms = 18000
kafka                    | 	zookeeper.set.acl = false
kafka                    | 	zookeeper.ssl.cipher.suites = null
kafka                    | 	zookeeper.ssl.client.enable = false
kafka                    | 	zookeeper.ssl.crl.enable = false
kafka                    | 	zookeeper.ssl.enabled.protocols = null
kafka                    | 	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
kafka                    | 	zookeeper.ssl.keystore.location = null
kafka                    | 	zookeeper.ssl.keystore.password = null
kafka                    | 	zookeeper.ssl.keystore.type = null
kafka                    | 	zookeeper.ssl.ocsp.enable = false
kafka                    | 	zookeeper.ssl.protocol = TLSv1.2
kafka                    | 	zookeeper.ssl.truststore.location = null
kafka                    | 	zookeeper.ssl.truststore.password = null
kafka                    | 	zookeeper.ssl.truststore.type = null
kafka                    |  (kafka.server.KafkaConfig)
kafka                    | [2025-10-03 16:12:12,288] INFO [BrokerServer id=1] Waiting for the broker to be unfenced (kafka.server.BrokerServer)
kafka                    | [2025-10-03 16:12:12,290] INFO [QuorumController id=1] The request from broker 1 to unfence has been granted because it has caught up with the offset of its register broker record 246051. (org.apache.kafka.controller.BrokerHeartbeatManager)
kafka                    | [2025-10-03 16:12:12,483] INFO [QuorumController id=1] handleBrokerUnfenced: changing 56 partition(s) (org.apache.kafka.controller.ReplicationControlManager)
kafka                    | [2025-10-03 16:12:12,523] INFO [QuorumController id=1] Replayed BrokerRegistrationChangeRecord modifying the registration for broker 1: BrokerRegistrationChangeRecord(brokerId=1, brokerEpoch=246051, fenced=-1, inControlledShutdown=0) (org.apache.kafka.controller.ClusterControlManager)
kafka                    | [2025-10-03 16:12:12,661] INFO [Broker id=1] Transitioning 56 partition(s) to local leaders. (state.change.logger)
kafka                    | [2025-10-03 16:12:12,666] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(__consumer_offsets-13, password.changed-0, __consumer_offsets-46, __consumer_offsets-9, __consumer_offsets-42, __consumer_offsets-21, __consumer_offsets-17, __consumer_offsets-30, __consumer_offsets-26, __consumer_offsets-5, __consumer_offsets-38, __consumer_offsets-1, user.registered-0, __consumer_offsets-34, __consumer_offsets-16, __consumer_offsets-45, __consumer_offsets-12, __consumer_offsets-41, __consumer_offsets-24, __consumer_offsets-20, __consumer_offsets-49, __consumer_offsets-0, __consumer_offsets-29, __consumer_offsets-25, __consumer_offsets-8, __consumer_offsets-37, __consumer_offsets-4, __consumer_offsets-33, __consumer_offsets-15, __consumer_offsets-48, __consumer_offsets-11, __consumer_offsets-44, __consumer_offsets-23, __consumer_offsets-19, __consumer_offsets-32, __consumer_offsets-28, __consumer_offsets-7, __consumer_offsets-40, __consumer_offsets-3, __consumer_offsets-36, __consumer_offsets-47, __consumer_offsets-14, __consumer_offsets-43, __consumer_offsets-10, transfer.completed-0, __consumer_offsets-22, kyc-events-0, __consumer_offsets-18, __consumer_offsets-31, __consumer_offsets-27, transfer-completed-events-0, __consumer_offsets-39, __consumer_offsets-6, login-attempts-topic-0, __consumer_offsets-35, __consumer_offsets-2) (kafka.server.ReplicaFetcherManager)
kafka                    | [2025-10-03 16:12:12,685] INFO [BrokerLifecycleManager id=1] The broker has been unfenced. Transitioning from RECOVERY to RUNNING. (kafka.server.BrokerLifecycleManager)
kafka                    | [2025-10-03 16:12:12,707] INFO [BrokerServer id=1] Finished waiting for the broker to be unfenced (kafka.server.BrokerServer)
kafka                    | [2025-10-03 16:12:12,721] INFO authorizerStart completed for endpoint EXTERNAL. Endpoint is now READY. (org.apache.kafka.server.network.EndpointReadyFutures)
kafka                    | [2025-10-03 16:12:12,722] INFO authorizerStart completed for endpoint PLAINTEXT. Endpoint is now READY. (org.apache.kafka.server.network.EndpointReadyFutures)
kafka                    | [2025-10-03 16:12:12,720] INFO [Broker id=1] Leader __consumer_offsets-13 with topic id Some(iNBYdjYeRpSCdVw9OvuAgQ) starts at leader epoch 170 from offset 0 with partition epoch 170, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 169. (state.change.logger)
kafka                    | [2025-10-03 16:12:12,725] INFO [SocketServer listenerType=BROKER, nodeId=1] Enabling request processing. (kafka.network.SocketServer)
kafka                    | [2025-10-03 16:12:12,730] INFO Awaiting socket connections on 0.0.0.0:9094. (kafka.network.DataPlaneAcceptor)
kafka                    | [2025-10-03 16:12:12,826] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.DataPlaneAcceptor)
kafka                    | [2025-10-03 16:12:12,838] INFO [Broker id=1] Leader password.changed-0 with topic id Some(7BTLLGtSRcaeR2BnI9Wd5g) starts at leader epoch 170 from offset 0 with partition epoch 170, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 169. (state.change.logger)
kafka                    | [2025-10-03 16:12:12,886] INFO [Broker id=1] Leader __consumer_offsets-46 with topic id Some(iNBYdjYeRpSCdVw9OvuAgQ) starts at leader epoch 170 from offset 0 with partition epoch 170, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 169. (state.change.logger)
kafka                    | [2025-10-03 16:12:12,923] INFO [Broker id=1] Leader __consumer_offsets-9 with topic id Some(iNBYdjYeRpSCdVw9OvuAgQ) starts at leader epoch 170 from offset 0 with partition epoch 170, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 169. (state.change.logger)
kafka                    | [2025-10-03 16:12:12,977] INFO [Broker id=1] Leader __consumer_offsets-42 with topic id Some(iNBYdjYeRpSCdVw9OvuAgQ) starts at leader epoch 170 from offset 0 with partition epoch 170, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 169. (state.change.logger)
kafka                    | [2025-10-03 16:12:12,986] INFO [BrokerServer id=1] Waiting for all of the authorizer futures to be completed (kafka.server.BrokerServer)
kafka                    | [2025-10-03 16:12:12,989] INFO [BrokerServer id=1] Finished waiting for all of the authorizer futures to be completed (kafka.server.BrokerServer)
kafka                    | [2025-10-03 16:12:12,993] INFO [BrokerServer id=1] Waiting for all of the SocketServer Acceptors to be started (kafka.server.BrokerServer)
kafka                    | [2025-10-03 16:12:12,994] INFO [BrokerServer id=1] Finished waiting for all of the SocketServer Acceptors to be started (kafka.server.BrokerServer)
kafka                    | [2025-10-03 16:12:12,995] INFO [BrokerServer id=1] Transition from STARTING to STARTED (kafka.server.BrokerServer)
kafka                    | [2025-10-03 16:12:13,008] INFO [Broker id=1] Leader __consumer_offsets-21 with topic id Some(iNBYdjYeRpSCdVw9OvuAgQ) starts at leader epoch 170 from offset 0 with partition epoch 170, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 169. (state.change.logger)
kafka                    | [2025-10-03 16:12:13,023] INFO Kafka version: 3.6.2 (org.apache.kafka.common.utils.AppInfoParser)
kafka                    | [2025-10-03 16:12:13,027] INFO Kafka commitId: c4deed513057c94e (org.apache.kafka.common.utils.AppInfoParser)
kafka                    | [2025-10-03 16:12:13,027] INFO Kafka startTimeMs: 1759507932996 (org.apache.kafka.common.utils.AppInfoParser)
kafka                    | [2025-10-03 16:12:13,068] INFO [Broker id=1] Leader __consumer_offsets-17 with topic id Some(iNBYdjYeRpSCdVw9OvuAgQ) starts at leader epoch 170 from offset 0 with partition epoch 170, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 169. (state.change.logger)
kafka                    | [2025-10-03 16:12:13,095] INFO [KafkaRaftServer nodeId=1] Kafka Server started (kafka.server.KafkaRaftServer)
kafka                    | [2025-10-03 16:12:13,121] INFO [Broker id=1] Leader __consumer_offsets-30 with topic id Some(iNBYdjYeRpSCdVw9OvuAgQ) starts at leader epoch 170 from offset 0 with partition epoch 170, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 169. (state.change.logger)
kafka                    | [2025-10-03 16:12:13,135] INFO [Broker id=1] Leader __consumer_offsets-26 with topic id Some(iNBYdjYeRpSCdVw9OvuAgQ) starts at leader epoch 170 from offset 0 with partition epoch 170, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 169. (state.change.logger)
kafka                    | [2025-10-03 16:12:13,170] INFO [Broker id=1] Leader __consumer_offsets-5 with topic id Some(iNBYdjYeRpSCdVw9OvuAgQ) starts at leader epoch 170 from offset 0 with partition epoch 170, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 169. (state.change.logger)
kafka                    | [2025-10-03 16:12:13,188] INFO [Broker id=1] Leader __consumer_offsets-38 with topic id Some(iNBYdjYeRpSCdVw9OvuAgQ) starts at leader epoch 170 from offset 0 with partition epoch 170, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 169. (state.change.logger)
kafka                    | [2025-10-03 16:12:13,211] INFO [Broker id=1] Leader __consumer_offsets-1 with topic id Some(iNBYdjYeRpSCdVw9OvuAgQ) starts at leader epoch 170 from offset 0 with partition epoch 170, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 169. (state.change.logger)
kafka                    | [2025-10-03 16:12:13,246] INFO [Broker id=1] Leader user.registered-0 with topic id Some(wA1qIfWQTdGjFnyrGcxRuQ) starts at leader epoch 170 from offset 0 with partition epoch 170, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 169. (state.change.logger)
kafka                    | [2025-10-03 16:12:13,262] INFO [Broker id=1] Leader __consumer_offsets-34 with topic id Some(iNBYdjYeRpSCdVw9OvuAgQ) starts at leader epoch 170 from offset 0 with partition epoch 170, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 169. (state.change.logger)
kafka                    | [2025-10-03 16:12:13,280] INFO [Broker id=1] Leader __consumer_offsets-16 with topic id Some(iNBYdjYeRpSCdVw9OvuAgQ) starts at leader epoch 170 from offset 0 with partition epoch 170, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 169. (state.change.logger)
kafka                    | [2025-10-03 16:12:13,301] INFO [Broker id=1] Leader __consumer_offsets-45 with topic id Some(iNBYdjYeRpSCdVw9OvuAgQ) starts at leader epoch 170 from offset 0 with partition epoch 170, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 169. (state.change.logger)
kafka                    | [2025-10-03 16:12:13,316] INFO [Broker id=1] Leader __consumer_offsets-12 with topic id Some(iNBYdjYeRpSCdVw9OvuAgQ) starts at leader epoch 170 from offset 0 with partition epoch 170, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 169. (state.change.logger)
kafka                    | [2025-10-03 16:12:13,328] INFO [Broker id=1] Leader __consumer_offsets-41 with topic id Some(iNBYdjYeRpSCdVw9OvuAgQ) starts at leader epoch 170 from offset 0 with partition epoch 170, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 169. (state.change.logger)
kafka                    | [2025-10-03 16:12:13,353] INFO [Broker id=1] Leader __consumer_offsets-24 with topic id Some(iNBYdjYeRpSCdVw9OvuAgQ) starts at leader epoch 170 from offset 0 with partition epoch 170, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 169. (state.change.logger)
kafka                    | [2025-10-03 16:12:13,367] INFO [Broker id=1] Leader __consumer_offsets-20 with topic id Some(iNBYdjYeRpSCdVw9OvuAgQ) starts at leader epoch 170 from offset 0 with partition epoch 170, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 169. (state.change.logger)
kafka                    | [2025-10-03 16:12:13,382] INFO [Broker id=1] Leader __consumer_offsets-49 with topic id Some(iNBYdjYeRpSCdVw9OvuAgQ) starts at leader epoch 170 from offset 0 with partition epoch 170, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 169. (state.change.logger)
kafka                    | [2025-10-03 16:12:13,411] INFO [Broker id=1] Leader __consumer_offsets-0 with topic id Some(iNBYdjYeRpSCdVw9OvuAgQ) starts at leader epoch 170 from offset 0 with partition epoch 170, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 169. (state.change.logger)
kafka                    | [2025-10-03 16:12:13,427] INFO [Broker id=1] Leader __consumer_offsets-29 with topic id Some(iNBYdjYeRpSCdVw9OvuAgQ) starts at leader epoch 170 from offset 0 with partition epoch 170, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 169. (state.change.logger)
kafka                    | [2025-10-03 16:12:13,433] INFO [Broker id=1] Leader __consumer_offsets-25 with topic id Some(iNBYdjYeRpSCdVw9OvuAgQ) starts at leader epoch 170 from offset 0 with partition epoch 170, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 169. (state.change.logger)
kafka                    | [2025-10-03 16:12:13,449] INFO [Broker id=1] Leader __consumer_offsets-8 with topic id Some(iNBYdjYeRpSCdVw9OvuAgQ) starts at leader epoch 170 from offset 0 with partition epoch 170, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 169. (state.change.logger)
kafka                    | [2025-10-03 16:12:13,462] INFO [Broker id=1] Leader __consumer_offsets-37 with topic id Some(iNBYdjYeRpSCdVw9OvuAgQ) starts at leader epoch 170 from offset 0 with partition epoch 170, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 169. (state.change.logger)
kafka                    | [2025-10-03 16:12:13,478] INFO [Broker id=1] Leader __consumer_offsets-4 with topic id Some(iNBYdjYeRpSCdVw9OvuAgQ) starts at leader epoch 170 from offset 0 with partition epoch 170, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 169. (state.change.logger)
kafka                    | [2025-10-03 16:12:13,490] INFO [Broker id=1] Leader __consumer_offsets-33 with topic id Some(iNBYdjYeRpSCdVw9OvuAgQ) starts at leader epoch 170 from offset 0 with partition epoch 170, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 169. (state.change.logger)
kafka                    | [2025-10-03 16:12:13,505] INFO [Broker id=1] Leader __consumer_offsets-15 with topic id Some(iNBYdjYeRpSCdVw9OvuAgQ) starts at leader epoch 170 from offset 0 with partition epoch 170, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 169. (state.change.logger)
kafka                    | [2025-10-03 16:12:13,515] INFO [Broker id=1] Leader __consumer_offsets-48 with topic id Some(iNBYdjYeRpSCdVw9OvuAgQ) starts at leader epoch 170 from offset 0 with partition epoch 170, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 169. (state.change.logger)
kafka                    | [2025-10-03 16:12:13,542] INFO [Broker id=1] Leader __consumer_offsets-11 with topic id Some(iNBYdjYeRpSCdVw9OvuAgQ) starts at leader epoch 170 from offset 0 with partition epoch 170, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 169. (state.change.logger)
kafka                    | [2025-10-03 16:12:13,549] INFO [Broker id=1] Leader __consumer_offsets-44 with topic id Some(iNBYdjYeRpSCdVw9OvuAgQ) starts at leader epoch 170 from offset 161 with partition epoch 170, high watermark 161, ISR [1], adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 169. (state.change.logger)
kafka                    | [2025-10-03 16:12:13,562] INFO [Broker id=1] Leader __consumer_offsets-23 with topic id Some(iNBYdjYeRpSCdVw9OvuAgQ) starts at leader epoch 170 from offset 0 with partition epoch 170, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 169. (state.change.logger)
kafka                    | [2025-10-03 16:12:13,576] INFO [Broker id=1] Leader __consumer_offsets-19 with topic id Some(iNBYdjYeRpSCdVw9OvuAgQ) starts at leader epoch 170 from offset 0 with partition epoch 170, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 169. (state.change.logger)
kafka                    | [2025-10-03 16:12:13,597] INFO [Broker id=1] Leader __consumer_offsets-32 with topic id Some(iNBYdjYeRpSCdVw9OvuAgQ) starts at leader epoch 170 from offset 0 with partition epoch 170, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 169. (state.change.logger)
kafka                    | [2025-10-03 16:12:13,653] INFO [Broker id=1] Leader __consumer_offsets-28 with topic id Some(iNBYdjYeRpSCdVw9OvuAgQ) starts at leader epoch 170 from offset 0 with partition epoch 170, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 169. (state.change.logger)
kafka                    | [2025-10-03 16:12:13,673] INFO [Broker id=1] Leader __consumer_offsets-7 with topic id Some(iNBYdjYeRpSCdVw9OvuAgQ) starts at leader epoch 170 from offset 0 with partition epoch 170, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 169. (state.change.logger)
kafka                    | [2025-10-03 16:12:13,681] INFO [Broker id=1] Leader __consumer_offsets-40 with topic id Some(iNBYdjYeRpSCdVw9OvuAgQ) starts at leader epoch 170 from offset 0 with partition epoch 170, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 169. (state.change.logger)
kafka                    | [2025-10-03 16:12:13,698] INFO [Broker id=1] Leader __consumer_offsets-3 with topic id Some(iNBYdjYeRpSCdVw9OvuAgQ) starts at leader epoch 170 from offset 0 with partition epoch 170, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 169. (state.change.logger)
kafka                    | [2025-10-03 16:12:13,708] INFO [Broker id=1] Leader __consumer_offsets-36 with topic id Some(iNBYdjYeRpSCdVw9OvuAgQ) starts at leader epoch 170 from offset 0 with partition epoch 170, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 169. (state.change.logger)
kafka                    | [2025-10-03 16:12:13,718] INFO [Broker id=1] Leader __consumer_offsets-47 with topic id Some(iNBYdjYeRpSCdVw9OvuAgQ) starts at leader epoch 170 from offset 0 with partition epoch 170, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 169. (state.change.logger)
kafka                    | [2025-10-03 16:12:13,729] INFO [Broker id=1] Leader __consumer_offsets-14 with topic id Some(iNBYdjYeRpSCdVw9OvuAgQ) starts at leader epoch 170 from offset 162 with partition epoch 170, high watermark 162, ISR [1], adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 169. (state.change.logger)
kafka                    | [2025-10-03 16:12:13,740] INFO [Broker id=1] Leader __consumer_offsets-43 with topic id Some(iNBYdjYeRpSCdVw9OvuAgQ) starts at leader epoch 170 from offset 0 with partition epoch 170, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 169. (state.change.logger)
kafka                    | [2025-10-03 16:12:13,751] INFO [Broker id=1] Leader __consumer_offsets-10 with topic id Some(iNBYdjYeRpSCdVw9OvuAgQ) starts at leader epoch 170 from offset 0 with partition epoch 170, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 169. (state.change.logger)
kafka                    | [2025-10-03 16:12:13,758] INFO [Broker id=1] Leader transfer.completed-0 with topic id Some(KnRdX7QnQJmUANpwxqvSDg) starts at leader epoch 170 from offset 0 with partition epoch 170, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 169. (state.change.logger)
kafka                    | [2025-10-03 16:12:13,805] INFO [Broker id=1] Leader __consumer_offsets-22 with topic id Some(iNBYdjYeRpSCdVw9OvuAgQ) starts at leader epoch 170 from offset 0 with partition epoch 170, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 169. (state.change.logger)
kafka                    | [2025-10-03 16:12:13,828] INFO [Broker id=1] Leader kyc-events-0 with topic id Some(xrkFKQ2_RwCJqp4b4WCWXQ) starts at leader epoch 24 from offset 0 with partition epoch 24, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 23. (state.change.logger)
kafka                    | [2025-10-03 16:12:13,838] INFO [Broker id=1] Leader __consumer_offsets-18 with topic id Some(iNBYdjYeRpSCdVw9OvuAgQ) starts at leader epoch 170 from offset 0 with partition epoch 170, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 169. (state.change.logger)
kafka                    | [2025-10-03 16:12:13,854] INFO [Broker id=1] Leader __consumer_offsets-31 with topic id Some(iNBYdjYeRpSCdVw9OvuAgQ) starts at leader epoch 170 from offset 0 with partition epoch 170, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 169. (state.change.logger)
kafka                    | [2025-10-03 16:12:13,867] INFO [Broker id=1] Leader __consumer_offsets-27 with topic id Some(iNBYdjYeRpSCdVw9OvuAgQ) starts at leader epoch 170 from offset 0 with partition epoch 170, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 169. (state.change.logger)
kafka                    | [2025-10-03 16:12:13,879] INFO [Broker id=1] Leader transfer-completed-events-0 with topic id Some(ltyY2IODSnCcb9DcVhT46A) starts at leader epoch 170 from offset 0 with partition epoch 170, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 169. (state.change.logger)
kafka                    | [2025-10-03 16:12:13,893] INFO [Broker id=1] Leader __consumer_offsets-39 with topic id Some(iNBYdjYeRpSCdVw9OvuAgQ) starts at leader epoch 170 from offset 168 with partition epoch 170, high watermark 168, ISR [1], adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 169. (state.change.logger)
kafka                    | [2025-10-03 16:12:13,912] INFO [Broker id=1] Leader __consumer_offsets-6 with topic id Some(iNBYdjYeRpSCdVw9OvuAgQ) starts at leader epoch 170 from offset 0 with partition epoch 170, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 169. (state.change.logger)
kafka                    | [2025-10-03 16:12:13,925] INFO [Broker id=1] Leader login-attempts-topic-0 with topic id Some(C9qPgaLVTKmphRtrR47kPQ) starts at leader epoch 170 from offset 0 with partition epoch 170, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 169. (state.change.logger)
kafka                    | [2025-10-03 16:12:13,941] INFO [Broker id=1] Leader __consumer_offsets-35 with topic id Some(iNBYdjYeRpSCdVw9OvuAgQ) starts at leader epoch 170 from offset 0 with partition epoch 170, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 169. (state.change.logger)
kafka                    | [2025-10-03 16:12:13,970] INFO [Broker id=1] Leader __consumer_offsets-2 with topic id Some(iNBYdjYeRpSCdVw9OvuAgQ) starts at leader epoch 170 from offset 0 with partition epoch 170, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 169. (state.change.logger)
kafka                    | [2025-10-03 16:12:14,014] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 13 in epoch 170 (kafka.coordinator.group.GroupCoordinator)
kafka                    | [2025-10-03 16:12:14,024] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-13 for epoch 170 (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:14,040] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 46 in epoch 170 (kafka.coordinator.group.GroupCoordinator)
kafka                    | [2025-10-03 16:12:14,040] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-46 for epoch 170 (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:14,040] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 9 in epoch 170 (kafka.coordinator.group.GroupCoordinator)
kafka                    | [2025-10-03 16:12:14,043] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-9 for epoch 170 (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:14,043] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 42 in epoch 170 (kafka.coordinator.group.GroupCoordinator)
kafka                    | [2025-10-03 16:12:14,043] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-42 for epoch 170 (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:14,044] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 21 in epoch 170 (kafka.coordinator.group.GroupCoordinator)
kafka                    | [2025-10-03 16:12:14,044] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-21 for epoch 170 (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:14,044] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 17 in epoch 170 (kafka.coordinator.group.GroupCoordinator)
kafka                    | [2025-10-03 16:12:14,044] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-17 for epoch 170 (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:14,044] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 30 in epoch 170 (kafka.coordinator.group.GroupCoordinator)
kafka                    | [2025-10-03 16:12:14,044] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-30 for epoch 170 (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:14,044] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 26 in epoch 170 (kafka.coordinator.group.GroupCoordinator)
kafka                    | [2025-10-03 16:12:14,044] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-26 for epoch 170 (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:14,044] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 5 in epoch 170 (kafka.coordinator.group.GroupCoordinator)
kafka                    | [2025-10-03 16:12:14,044] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-5 for epoch 170 (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:14,044] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 38 in epoch 170 (kafka.coordinator.group.GroupCoordinator)
kafka                    | [2025-10-03 16:12:14,044] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-38 for epoch 170 (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:14,044] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 1 in epoch 170 (kafka.coordinator.group.GroupCoordinator)
kafka                    | [2025-10-03 16:12:14,044] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-1 for epoch 170 (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:14,044] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 34 in epoch 170 (kafka.coordinator.group.GroupCoordinator)
kafka                    | [2025-10-03 16:12:14,044] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-34 for epoch 170 (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:14,044] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 16 in epoch 170 (kafka.coordinator.group.GroupCoordinator)
kafka                    | [2025-10-03 16:12:14,044] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-16 for epoch 170 (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:14,044] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 45 in epoch 170 (kafka.coordinator.group.GroupCoordinator)
kafka                    | [2025-10-03 16:12:14,044] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-45 for epoch 170 (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:14,045] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 12 in epoch 170 (kafka.coordinator.group.GroupCoordinator)
kafka                    | [2025-10-03 16:12:14,045] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-12 for epoch 170 (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:14,045] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 41 in epoch 170 (kafka.coordinator.group.GroupCoordinator)
kafka                    | [2025-10-03 16:12:14,045] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-41 for epoch 170 (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:14,045] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 24 in epoch 170 (kafka.coordinator.group.GroupCoordinator)
kafka                    | [2025-10-03 16:12:14,045] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-24 for epoch 170 (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:14,045] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 20 in epoch 170 (kafka.coordinator.group.GroupCoordinator)
kafka                    | [2025-10-03 16:12:14,045] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-20 for epoch 170 (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:14,045] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 49 in epoch 170 (kafka.coordinator.group.GroupCoordinator)
kafka                    | [2025-10-03 16:12:14,045] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-49 for epoch 170 (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:14,045] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 0 in epoch 170 (kafka.coordinator.group.GroupCoordinator)
kafka                    | [2025-10-03 16:12:14,045] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-0 for epoch 170 (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:14,045] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 29 in epoch 170 (kafka.coordinator.group.GroupCoordinator)
kafka                    | [2025-10-03 16:12:14,045] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-29 for epoch 170 (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:14,045] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 25 in epoch 170 (kafka.coordinator.group.GroupCoordinator)
kafka                    | [2025-10-03 16:12:14,046] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-25 for epoch 170 (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:14,046] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 8 in epoch 170 (kafka.coordinator.group.GroupCoordinator)
kafka                    | [2025-10-03 16:12:14,046] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-8 for epoch 170 (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:14,046] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 37 in epoch 170 (kafka.coordinator.group.GroupCoordinator)
kafka                    | [2025-10-03 16:12:14,046] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-37 for epoch 170 (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:14,046] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 4 in epoch 170 (kafka.coordinator.group.GroupCoordinator)
kafka                    | [2025-10-03 16:12:14,046] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-4 for epoch 170 (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:14,046] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 33 in epoch 170 (kafka.coordinator.group.GroupCoordinator)
kafka                    | [2025-10-03 16:12:14,046] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-33 for epoch 170 (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:14,046] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 15 in epoch 170 (kafka.coordinator.group.GroupCoordinator)
kafka                    | [2025-10-03 16:12:14,046] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-15 for epoch 170 (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:14,046] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 48 in epoch 170 (kafka.coordinator.group.GroupCoordinator)
kafka                    | [2025-10-03 16:12:14,046] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-48 for epoch 170 (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:14,046] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 11 in epoch 170 (kafka.coordinator.group.GroupCoordinator)
kafka                    | [2025-10-03 16:12:14,046] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-11 for epoch 170 (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:14,046] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 44 in epoch 170 (kafka.coordinator.group.GroupCoordinator)
kafka                    | [2025-10-03 16:12:14,051] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-44 for epoch 170 (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:14,051] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 23 in epoch 170 (kafka.coordinator.group.GroupCoordinator)
kafka                    | [2025-10-03 16:12:14,051] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-23 for epoch 170 (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:14,051] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 19 in epoch 170 (kafka.coordinator.group.GroupCoordinator)
kafka                    | [2025-10-03 16:12:14,051] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-19 for epoch 170 (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:14,051] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 32 in epoch 170 (kafka.coordinator.group.GroupCoordinator)
kafka                    | [2025-10-03 16:12:14,051] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-32 for epoch 170 (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:14,051] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 28 in epoch 170 (kafka.coordinator.group.GroupCoordinator)
kafka                    | [2025-10-03 16:12:14,051] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-28 for epoch 170 (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:14,051] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 7 in epoch 170 (kafka.coordinator.group.GroupCoordinator)
kafka                    | [2025-10-03 16:12:14,051] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-7 for epoch 170 (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:14,051] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 40 in epoch 170 (kafka.coordinator.group.GroupCoordinator)
kafka                    | [2025-10-03 16:12:14,051] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-40 for epoch 170 (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:14,052] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 3 in epoch 170 (kafka.coordinator.group.GroupCoordinator)
kafka                    | [2025-10-03 16:12:14,052] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-3 for epoch 170 (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:14,052] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 36 in epoch 170 (kafka.coordinator.group.GroupCoordinator)
kafka                    | [2025-10-03 16:12:14,052] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-36 for epoch 170 (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:14,052] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 47 in epoch 170 (kafka.coordinator.group.GroupCoordinator)
kafka                    | [2025-10-03 16:12:14,052] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-47 for epoch 170 (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:14,052] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 14 in epoch 170 (kafka.coordinator.group.GroupCoordinator)
kafka                    | [2025-10-03 16:12:14,052] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-14 for epoch 170 (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:14,052] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 43 in epoch 170 (kafka.coordinator.group.GroupCoordinator)
kafka                    | [2025-10-03 16:12:14,052] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-43 for epoch 170 (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:14,052] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 10 in epoch 170 (kafka.coordinator.group.GroupCoordinator)
kafka                    | [2025-10-03 16:12:14,052] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-10 for epoch 170 (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:14,052] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 22 in epoch 170 (kafka.coordinator.group.GroupCoordinator)
kafka                    | [2025-10-03 16:12:14,052] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-22 for epoch 170 (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:14,052] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 18 in epoch 170 (kafka.coordinator.group.GroupCoordinator)
kafka                    | [2025-10-03 16:12:14,052] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-18 for epoch 170 (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:14,052] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 31 in epoch 170 (kafka.coordinator.group.GroupCoordinator)
kafka                    | [2025-10-03 16:12:14,052] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-31 for epoch 170 (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:14,052] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 27 in epoch 170 (kafka.coordinator.group.GroupCoordinator)
kafka                    | [2025-10-03 16:12:14,052] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-27 for epoch 170 (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:14,052] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 39 in epoch 170 (kafka.coordinator.group.GroupCoordinator)
kafka                    | [2025-10-03 16:12:14,052] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-39 for epoch 170 (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:14,052] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 6 in epoch 170 (kafka.coordinator.group.GroupCoordinator)
kafka                    | [2025-10-03 16:12:14,052] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-6 for epoch 170 (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:14,052] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 35 in epoch 170 (kafka.coordinator.group.GroupCoordinator)
kafka                    | [2025-10-03 16:12:14,052] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-35 for epoch 170 (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:14,052] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 2 in epoch 170 (kafka.coordinator.group.GroupCoordinator)
kafka                    | [2025-10-03 16:12:14,052] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-2 for epoch 170 (kafka.coordinator.group.GroupMetadataManager)
account-service          | 
account-service          |   .   ____          _            __ _ _
account-service          |  /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \
account-service          | ( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \
account-service          |  \\/  ___)| |_)| | | | | || (_| |  ) ) ) )
account-service          |   '  |____| .__|_| |_|_| |_\__, | / / / /
account-service          |  =========|_|==============|___/=/_/_/_/
account-service          | 
account-service          |  :: Spring Boot ::                (v3.5.0)
account-service          | 
fraud-detection          | 2025-10-03T16:12:14.222Z  INFO 1 --- [fraud-detection] [           main] o.s.b.w.embedded.tomcat.TomcatWebServer  : Tomcat initialized with port 8080 (http)
kafka                    | [2025-10-03 16:12:14,219] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-13 in 172 milliseconds for epoch 170, of which 19 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:14,236] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-46 in 196 milliseconds for epoch 170, of which 194 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:14,245] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-9 in 202 milliseconds for epoch 170, of which 201 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:14,254] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-42 in 211 milliseconds for epoch 170, of which 210 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:14,256] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-21 in 212 milliseconds for epoch 170, of which 212 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:14,283] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-17 in 238 milliseconds for epoch 170, of which 224 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:14,284] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-30 in 240 milliseconds for epoch 170, of which 239 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:14,293] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-26 in 240 milliseconds for epoch 170, of which 240 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:14,307] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-5 in 263 milliseconds for epoch 170, of which 262 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:14,317] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-38 in 273 milliseconds for epoch 170, of which 266 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:14,318] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-1 in 274 milliseconds for epoch 170, of which 274 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:14,327] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-34 in 283 milliseconds for epoch 170, of which 282 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:14,343] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-16 in 299 milliseconds for epoch 170, of which 297 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:14,344] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-45 in 300 milliseconds for epoch 170, of which 299 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:14,344] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-12 in 299 milliseconds for epoch 170, of which 299 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:14,349] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-41 in 303 milliseconds for epoch 170, of which 299 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:14,349] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-24 in 304 milliseconds for epoch 170, of which 304 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:14,349] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-20 in 304 milliseconds for epoch 170, of which 304 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:14,349] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-49 in 304 milliseconds for epoch 170, of which 304 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:14,350] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-0 in 305 milliseconds for epoch 170, of which 304 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:14,350] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-29 in 305 milliseconds for epoch 170, of which 305 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:14,350] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-25 in 304 milliseconds for epoch 170, of which 304 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:14,350] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-8 in 304 milliseconds for epoch 170, of which 304 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:14,351] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-37 in 305 milliseconds for epoch 170, of which 305 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:14,351] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-4 in 305 milliseconds for epoch 170, of which 305 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:14,351] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-33 in 305 milliseconds for epoch 170, of which 305 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:14,351] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-15 in 305 milliseconds for epoch 170, of which 305 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:14,351] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-48 in 305 milliseconds for epoch 170, of which 305 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:14,351] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-11 in 305 milliseconds for epoch 170, of which 305 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:14,795] INFO Loaded member MemberMetadata(memberId=consumer-auth-statistics-group-1-a2108768-06c3-4eed-b49a-313fa3ad9568, groupInstanceId=None, clientId=consumer-auth-statistics-group-1, clientHost=/172.18.0.12, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group auth-statistics-group with generation 113. (kafka.coordinator.group.GroupMetadata$)
kafka                    | [2025-10-03 16:12:14,852] INFO Loaded member MemberMetadata(memberId=consumer-auth-statistics-group-1-ec807713-af3d-4bb7-92fd-f6ab41556f47, groupInstanceId=None, clientId=consumer-auth-statistics-group-1, clientHost=/172.18.0.8, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group auth-statistics-group with generation 115. (kafka.coordinator.group.GroupMetadata$)
kafka                    | [2025-10-03 16:12:14,862] INFO Loaded member MemberMetadata(memberId=consumer-auth-statistics-group-1-dce885cb-0ce1-4036-a575-ae4aaeaeb6b2, groupInstanceId=None, clientId=consumer-auth-statistics-group-1, clientHost=/172.18.0.8, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group auth-statistics-group with generation 117. (kafka.coordinator.group.GroupMetadata$)
kafka                    | [2025-10-03 16:12:14,870] INFO Loaded member MemberMetadata(memberId=consumer-auth-statistics-group-1-bff3219f-b37f-48b7-b14b-216c55cff327, groupInstanceId=None, clientId=consumer-auth-statistics-group-1, clientHost=/172.18.0.8, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group auth-statistics-group with generation 119. (kafka.coordinator.group.GroupMetadata$)
kafka                    | [2025-10-03 16:12:14,887] INFO Loaded member MemberMetadata(memberId=consumer-auth-statistics-group-1-f09a99cf-4474-4b13-b7de-1ceca7c3171d, groupInstanceId=None, clientId=consumer-auth-statistics-group-1, clientHost=/172.18.0.12, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group auth-statistics-group with generation 121. (kafka.coordinator.group.GroupMetadata$)
kafka                    | [2025-10-03 16:12:14,891] INFO Loaded member MemberMetadata(memberId=consumer-auth-statistics-group-1-9427394d-6d0f-4694-8c77-1bc90f18047c, groupInstanceId=None, clientId=consumer-auth-statistics-group-1, clientHost=/172.18.0.14, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group auth-statistics-group with generation 123. (kafka.coordinator.group.GroupMetadata$)
kafka                    | [2025-10-03 16:12:14,923] INFO [GroupCoordinator 1]: Loading group metadata for auth-statistics-group with generation 124 (kafka.coordinator.group.GroupCoordinator)
kafka                    | [2025-10-03 16:12:14,925] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-44 in 874 milliseconds for epoch 170, of which 300 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:14,932] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-23 in 880 milliseconds for epoch 170, of which 875 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:14,932] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-19 in 881 milliseconds for epoch 170, of which 881 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:14,940] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-32 in 889 milliseconds for epoch 170, of which 882 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:14,945] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-28 in 894 milliseconds for epoch 170, of which 889 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:14,945] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-7 in 894 milliseconds for epoch 170, of which 894 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:14,945] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-40 in 894 milliseconds for epoch 170, of which 894 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:14,946] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-3 in 894 milliseconds for epoch 170, of which 894 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:14,946] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-36 in 894 milliseconds for epoch 170, of which 894 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:14,946] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-47 in 894 milliseconds for epoch 170, of which 894 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
fraud-detection          | 2025-10-03T16:12:15.010Z  INFO 1 --- [fraud-detection] [           main] o.apache.catalina.core.StandardService   : Starting service [Tomcat]
fraud-detection          | 2025-10-03T16:12:15.050Z  INFO 1 --- [fraud-detection] [           main] o.apache.catalina.core.StandardEngine    : Starting Servlet engine: [Apache Tomcat/10.1.41]
kafka                    | [2025-10-03 16:12:15,409] INFO Loaded member MemberMetadata(memberId=consumer-fraud-detection-group-1-3a7b27fa-d73e-4534-b27f-df5c76c10f6a, groupInstanceId=None, clientId=consumer-fraud-detection-group-1, clientHost=/172.18.0.14, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group fraud-detection-group with generation 150. (kafka.coordinator.group.GroupMetadata$)
kafka                    | [2025-10-03 16:12:15,418] INFO Loaded member MemberMetadata(memberId=consumer-fraud-detection-group-1-f06ed417-1d1e-4719-aa7e-63ecd16e75b7, groupInstanceId=None, clientId=consumer-fraud-detection-group-1, clientHost=/172.18.0.9, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group fraud-detection-group with generation 152. (kafka.coordinator.group.GroupMetadata$)
kafka                    | [2025-10-03 16:12:15,419] INFO Loaded member MemberMetadata(memberId=consumer-fraud-detection-group-1-068c431a-9f68-4d0c-b813-edf436095703, groupInstanceId=None, clientId=consumer-fraud-detection-group-1, clientHost=/172.18.0.12, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group fraud-detection-group with generation 154. (kafka.coordinator.group.GroupMetadata$)
kafka                    | [2025-10-03 16:12:15,421] INFO Loaded member MemberMetadata(memberId=consumer-fraud-detection-group-1-8e23f7ee-2e1c-445c-8b18-e455aec439ff, groupInstanceId=None, clientId=consumer-fraud-detection-group-1, clientHost=/172.18.0.13, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group fraud-detection-group with generation 156. (kafka.coordinator.group.GroupMetadata$)
kafka                    | [2025-10-03 16:12:15,436] INFO Loaded member MemberMetadata(memberId=consumer-fraud-detection-group-1-efe1b47b-8e55-4e15-bb3b-35c64a735f04, groupInstanceId=None, clientId=consumer-fraud-detection-group-1, clientHost=/172.18.0.13, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group fraud-detection-group with generation 158. (kafka.coordinator.group.GroupMetadata$)
kafka                    | [2025-10-03 16:12:15,442] INFO Loaded member MemberMetadata(memberId=consumer-fraud-detection-group-1-ecef1e31-e939-4791-acb0-da1d30acf27c, groupInstanceId=None, clientId=consumer-fraud-detection-group-1, clientHost=/172.18.0.9, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group fraud-detection-group with generation 160. (kafka.coordinator.group.GroupMetadata$)
kafka                    | [2025-10-03 16:12:15,474] INFO [GroupCoordinator 1]: Loading group metadata for fraud-detection-group with generation 161 (kafka.coordinator.group.GroupCoordinator)
kafka                    | [2025-10-03 16:12:15,476] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-14 in 1424 milliseconds for epoch 170, of which 894 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:15,496] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-43 in 1444 milliseconds for epoch 170, of which 1424 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:15,506] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-10 in 1454 milliseconds for epoch 170, of which 1453 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:15,507] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-22 in 1455 milliseconds for epoch 170, of which 1454 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:15,512] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-18 in 1460 milliseconds for epoch 170, of which 1455 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:15,513] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-31 in 1461 milliseconds for epoch 170, of which 1461 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:15,514] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-27 in 1462 milliseconds for epoch 170, of which 1462 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:16,142] INFO Loaded member MemberMetadata(memberId=consumer-notification-service-2-f7dbb89d-b37b-4f24-94c6-b3dcb736025a, groupInstanceId=None, clientId=consumer-notification-service-2, clientHost=/172.18.0.13, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group notification-service with generation 153. (kafka.coordinator.group.GroupMetadata$)
kafka                    | [2025-10-03 16:12:16,179] INFO Loaded member MemberMetadata(memberId=consumer-notification-service-1-a9296331-cef6-46d7-b9db-1f423c599d20, groupInstanceId=None, clientId=consumer-notification-service-1, clientHost=/172.18.0.13, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group notification-service with generation 153. (kafka.coordinator.group.GroupMetadata$)
kafka                    | [2025-10-03 16:12:16,188] INFO Loaded member MemberMetadata(memberId=consumer-notification-service-3-00fec3d0-75dc-4fac-9551-2867b1063c0c, groupInstanceId=None, clientId=consumer-notification-service-3, clientHost=/172.18.0.13, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group notification-service with generation 153. (kafka.coordinator.group.GroupMetadata$)
kafka                    | [2025-10-03 16:12:16,218] INFO Loaded member MemberMetadata(memberId=consumer-notification-service-3-5419a2fe-fe89-48de-974d-42c11d38b584, groupInstanceId=None, clientId=consumer-notification-service-3, clientHost=/172.18.0.13, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group notification-service with generation 155. (kafka.coordinator.group.GroupMetadata$)
kafka                    | [2025-10-03 16:12:16,223] INFO Loaded member MemberMetadata(memberId=consumer-notification-service-2-5fa8ae88-ba21-420f-a24c-6becba28c74f, groupInstanceId=None, clientId=consumer-notification-service-2, clientHost=/172.18.0.13, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group notification-service with generation 155. (kafka.coordinator.group.GroupMetadata$)
kafka                    | [2025-10-03 16:12:16,224] INFO Loaded member MemberMetadata(memberId=consumer-notification-service-1-c35cc73e-f3ff-42bd-9d3c-9c40aac84ca3, groupInstanceId=None, clientId=consumer-notification-service-1, clientHost=/172.18.0.13, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group notification-service with generation 155. (kafka.coordinator.group.GroupMetadata$)
kafka                    | [2025-10-03 16:12:16,229] INFO Loaded member MemberMetadata(memberId=consumer-notification-service-1-a8c016d2-10c5-498b-a4d8-819e99c0b152, groupInstanceId=None, clientId=consumer-notification-service-1, clientHost=/172.18.0.11, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group notification-service with generation 157. (kafka.coordinator.group.GroupMetadata$)
kafka                    | [2025-10-03 16:12:16,229] INFO Loaded member MemberMetadata(memberId=consumer-notification-service-2-40242dea-99b2-422c-8fa8-1a382c7e5e91, groupInstanceId=None, clientId=consumer-notification-service-2, clientHost=/172.18.0.11, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group notification-service with generation 157. (kafka.coordinator.group.GroupMetadata$)
kafka                    | [2025-10-03 16:12:16,233] INFO Loaded member MemberMetadata(memberId=consumer-notification-service-3-3fad72db-b44d-4a3d-9d63-46141fe70d4a, groupInstanceId=None, clientId=consumer-notification-service-3, clientHost=/172.18.0.11, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group notification-service with generation 157. (kafka.coordinator.group.GroupMetadata$)
kafka                    | [2025-10-03 16:12:16,257] INFO Loaded member MemberMetadata(memberId=consumer-notification-service-1-b73a301a-b073-41a6-bad3-58901639aeb7, groupInstanceId=None, clientId=consumer-notification-service-1, clientHost=/172.18.0.12, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group notification-service with generation 159. (kafka.coordinator.group.GroupMetadata$)
kafka                    | [2025-10-03 16:12:16,261] INFO Loaded member MemberMetadata(memberId=consumer-notification-service-3-db352783-3733-4806-9b1a-093775e5411c, groupInstanceId=None, clientId=consumer-notification-service-3, clientHost=/172.18.0.12, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group notification-service with generation 159. (kafka.coordinator.group.GroupMetadata$)
kafka                    | [2025-10-03 16:12:16,275] INFO Loaded member MemberMetadata(memberId=consumer-notification-service-2-558329b0-10b3-4ba2-a0a4-82d6361ac4d9, groupInstanceId=None, clientId=consumer-notification-service-2, clientHost=/172.18.0.12, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group notification-service with generation 159. (kafka.coordinator.group.GroupMetadata$)
kafka                    | [2025-10-03 16:12:16,309] INFO Loaded member MemberMetadata(memberId=consumer-notification-service-2-787ea0ed-e07c-4bb8-9009-716a1b552a73, groupInstanceId=None, clientId=consumer-notification-service-2, clientHost=/172.18.0.10, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group notification-service with generation 161. (kafka.coordinator.group.GroupMetadata$)
kafka                    | [2025-10-03 16:12:16,311] INFO Loaded member MemberMetadata(memberId=consumer-notification-service-3-25464642-4a47-4385-ae1b-4e91a2930687, groupInstanceId=None, clientId=consumer-notification-service-3, clientHost=/172.18.0.10, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group notification-service with generation 161. (kafka.coordinator.group.GroupMetadata$)
kafka                    | [2025-10-03 16:12:16,314] INFO Loaded member MemberMetadata(memberId=consumer-notification-service-1-df5088ca-c48f-48e8-b8b1-ee9d54daf3d8, groupInstanceId=None, clientId=consumer-notification-service-1, clientHost=/172.18.0.10, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group notification-service with generation 161. (kafka.coordinator.group.GroupMetadata$)
kafka                    | [2025-10-03 16:12:16,315] INFO Loaded member MemberMetadata(memberId=consumer-notification-service-1-29140a06-9d02-4891-8d75-27584e63cfaf, groupInstanceId=None, clientId=consumer-notification-service-1, clientHost=/172.18.0.12, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group notification-service with generation 163. (kafka.coordinator.group.GroupMetadata$)
kafka                    | [2025-10-03 16:12:16,316] INFO Loaded member MemberMetadata(memberId=consumer-notification-service-2-24265adb-88cd-4ec2-b16f-9af742a07e56, groupInstanceId=None, clientId=consumer-notification-service-2, clientHost=/172.18.0.12, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group notification-service with generation 163. (kafka.coordinator.group.GroupMetadata$)
kafka                    | [2025-10-03 16:12:16,317] INFO Loaded member MemberMetadata(memberId=consumer-notification-service-3-33498810-334d-432b-8aa7-20eb84649338, groupInstanceId=None, clientId=consumer-notification-service-3, clientHost=/172.18.0.12, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group notification-service with generation 163. (kafka.coordinator.group.GroupMetadata$)
kyc-service              | 2025-10-03T16:12:15.104Z  INFO 1 --- [bank-shared] [           main] r.k.kycservice.KycServiceApplication     : Starting KycServiceApplication v0.0.1-SNAPSHOT using Java 21.0.8 with PID 1 (/app/app.jar started by root in /app)
kafka                    | [2025-10-03 16:12:16,322] INFO Loaded member MemberMetadata(memberId=consumer-notification-service-1-9e82600b-32fe-41dd-8070-a6aa7f643ede, groupInstanceId=None, clientId=consumer-notification-service-1, clientHost=/172.18.0.12, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group notification-service with generation 164. (kafka.coordinator.group.GroupMetadata$)
kafka                    | [2025-10-03 16:12:16,330] INFO Loaded member MemberMetadata(memberId=consumer-notification-service-2-24265adb-88cd-4ec2-b16f-9af742a07e56, groupInstanceId=None, clientId=consumer-notification-service-2, clientHost=/172.18.0.12, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group notification-service with generation 164. (kafka.coordinator.group.GroupMetadata$)
kafka                    | [2025-10-03 16:12:16,331] INFO Loaded member MemberMetadata(memberId=consumer-notification-service-3-fc5d174c-ae49-41fa-b477-7724b8e0be9b, groupInstanceId=None, clientId=consumer-notification-service-3, clientHost=/172.18.0.12, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group notification-service with generation 164. (kafka.coordinator.group.GroupMetadata$)
kafka                    | [2025-10-03 16:12:16,345] INFO [GroupCoordinator 1]: Loading group metadata for notification-service with generation 165 (kafka.coordinator.group.GroupCoordinator)
kafka                    | [2025-10-03 16:12:16,347] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-39 in 2295 milliseconds for epoch 170, of which 1462 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:16,351] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-6 in 2299 milliseconds for epoch 170, of which 2298 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:16,353] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-35 in 2301 milliseconds for epoch 170, of which 2300 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka                    | [2025-10-03 16:12:16,363] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-2 in 2306 milliseconds for epoch 170, of which 2305 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kyc-service              | 2025-10-03T16:12:16.417Z  INFO 1 --- [bank-shared] [           main] r.k.kycservice.KycServiceApplication     : No active profile set, falling back to 1 default profile: "default"
fraud-detection          | 2025-10-03T16:12:16.460Z  INFO 1 --- [fraud-detection] [           main] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring embedded WebApplicationContext
fraud-detection          | 2025-10-03T16:12:16.464Z  INFO 1 --- [fraud-detection] [           main] w.s.c.ServletWebServerApplicationContext : Root WebApplicationContext: initialization completed in 40072 ms
bankapp                  | 2025-10-03T16:12:17.124Z  INFO 1 --- [bank-shared] [           main] r.k.bank_app.BankAppApplication          : Starting BankAppApplication v0.0.1-SNAPSHOT using Java 21.0.8 with PID 1 (/app/app.jar started by root in /app)
bankapp                  | 2025-10-03T16:12:17.814Z  INFO 1 --- [bank-shared] [           main] r.k.bank_app.BankAppApplication          : No active profile set, falling back to 1 default profile: "default"
notification-service     | 2025-10-03T16:12:18.652Z  INFO 1 --- [bank-shared] [           main] o.s.b.w.embedded.tomcat.TomcatWebServer  : Tomcat initialized with port 8080 (http)
notification-service     | 2025-10-03T16:12:18.863Z  INFO 1 --- [bank-shared] [           main] o.apache.catalina.core.StandardService   : Starting service [Tomcat]
notification-service     | 2025-10-03T16:12:18.865Z  INFO 1 --- [bank-shared] [           main] o.apache.catalina.core.StandardEngine    : Starting Servlet engine: [Apache Tomcat/10.1.41]
settings-service         | 2025-10-03T16:12:18.504Z  INFO 1 --- [bank-shared] [           main] o.hibernate.jpa.internal.util.LogHelper  : HHH000204: Processing PersistenceUnitInfo [name: default]
auth-statistics-service  | 2025-10-03T16:12:18.675Z  INFO 1 --- [bank-shared] [           main] r.katacademy.auth.AuthStatisticsService  : Starting AuthStatisticsService v0.0.1-SNAPSHOT using Java 21.0.8 with PID 1 (/app/app.jar started by root in /app)
auth-statistics-service  | 2025-10-03T16:12:19.306Z  INFO 1 --- [bank-shared] [           main] r.katacademy.auth.AuthStatisticsService  : No active profile set, falling back to 1 default profile: "default"
notification-service     | 2025-10-03T16:12:19.762Z  INFO 1 --- [bank-shared] [           main] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring embedded WebApplicationContext
notification-service     | 2025-10-03T16:12:19.817Z  INFO 1 --- [bank-shared] [           main] w.s.c.ServletWebServerApplicationContext : Root WebApplicationContext: initialization completed in 44598 ms
security-service         | 
security-service         |   .   ____          _            __ _ _
security-service         |  /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \
security-service         | ( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \
security-service         |  \\/  ___)| |_)| | | | | || (_| |  ) ) ) )
security-service         |   '  |____| .__|_| |_|_| |_\__, | / / / /
security-service         |  =========|_|==============|___/=/_/_/_/
security-service         | 
security-service         |  :: Spring Boot ::                (v3.5.0)
security-service         | 
settings-service         | 2025-10-03T16:12:20.367Z  INFO 1 --- [bank-shared] [           main] org.hibernate.Version                    : HHH000412: Hibernate ORM core version 6.6.15.Final
settings-service         | 2025-10-03T16:12:20.828Z  INFO 1 --- [bank-shared] [           main] o.h.c.internal.RegionFactoryInitiator    : HHH000026: Second-level cache disabled
account-service          | 2025-10-03T16:12:21.573Z  INFO 1 --- [bank-shared] [           main] r.k.b.a.AccountServiceApplication        : Starting AccountServiceApplication v0.0.1-SNAPSHOT using Java 21.0.8 with PID 1 (/app/app.jar started by root in /app)
account-service          | 2025-10-03T16:12:22.030Z  INFO 1 --- [bank-shared] [           main] r.k.b.a.AccountServiceApplication        : No active profile set, falling back to 1 default profile: "default"
otel-collector           | 2025-10-03T16:12:22.373Z	info	Logs	{"resource": {"service.instance.id": "4aa48a6d-7678-4f39-b57a-6fa72002086e", "service.name": "otelcol", "service.version": "0.132.0"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "logs", "resource logs": 1, "log records": 1}
otel-collector           | 2025-10-03T16:12:22.407Z	info	ResourceLog #0
otel-collector           | Resource SchemaURL: https://opentelemetry.io/schemas/1.24.0
otel-collector           | Resource attributes:
otel-collector           |      -> container.id: Str(b7462027190fc5ca17c8fad62a6a7c6d248c5b38516fe3b1dfd9b3b6cf8f715b)
otel-collector           |      -> host.arch: Str(aarch64)
otel-collector           |      -> host.name: Str(b7462027190f)
otel-collector           |      -> os.description: Str(Linux 6.10.14-linuxkit)
otel-collector           |      -> os.type: Str(linux)
otel-collector           |      -> process.command_args: Slice(["/opt/java/openjdk/bin/java","-javaagent:/app/opentelemetry-javaagent.jar","-jar","app.jar"])
otel-collector           |      -> process.executable.path: Str(/opt/java/openjdk/bin/java)
otel-collector           |      -> process.pid: Int(1)
otel-collector           |      -> process.runtime.description: Str(Eclipse Adoptium OpenJDK 64-Bit Server VM 21.0.8+9-LTS)
otel-collector           |      -> process.runtime.name: Str(OpenJDK Runtime Environment)
otel-collector           |      -> process.runtime.version: Str(21.0.8+9-LTS)
otel-collector           |      -> service.instance.id: Str(88ceffbe-6ccf-45bf-b476-a5c5db2fc9f5)
otel-collector           |      -> service.name: Str(kyc-service)
otel-collector           |      -> service.version: Str(0.0.1-SNAPSHOT)
otel-collector           |      -> telemetry.distro.name: Str(opentelemetry-java-instrumentation)
otel-collector           |      -> telemetry.distro.version: Str(2.15.0)
otel-collector           |      -> telemetry.sdk.language: Str(java)
otel-collector           |      -> telemetry.sdk.name: Str(opentelemetry)
otel-collector           |      -> telemetry.sdk.version: Str(1.49.0)
otel-collector           | ScopeLogs #0
otel-collector           | ScopeLogs SchemaURL: 
otel-collector           | InstrumentationScope ru.katacademy.kycservice.KycServiceApplication 
otel-collector           | LogRecord #0
otel-collector           | ObservedTimestamp: 2025-10-03 16:12:15.716282376 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:15.104324709 +0000 UTC
otel-collector           | SeverityText: INFO
otel-collector           | SeverityNumber: Info(9)
otel-collector           | Body: Str(Starting KycServiceApplication v0.0.1-SNAPSHOT using Java 21.0.8 with PID 1 (/app/app.jar started by root in /app))
otel-collector           | Trace ID: 
otel-collector           | Span ID: 
otel-collector           | Flags: 0
otel-collector           | 	{"resource": {"service.instance.id": "4aa48a6d-7678-4f39-b57a-6fa72002086e", "service.name": "otelcol", "service.version": "0.132.0"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "logs"}
api-gateway-1            | 2025-10-03T16:12:22.961Z DEBUG 1 --- [api-gateway] [           main] o.s.c.gateway.config.GatewayProperties   : Routes supplied from Gateway Properties: [RouteDefinition{id='account-service', predicates=[PredicateDefinition{name='Path', args={_genkey_0=/api/accounts/**}}], filters=[], uri=http://account-service:8080, order=0, metadata={}, enabled=true}, RouteDefinition{id='security-service', predicates=[PredicateDefinition{name='Path', args={_genkey_0=/api/security/**}}], filters=[], uri=http://security-service:8080, order=0, metadata={}, enabled=true}]
fraud-detection          | 2025-10-03T16:12:23.232Z  INFO 1 --- [fraud-detection] [           main] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Starting...
security-service         | 2025-10-03T16:12:23.784Z  INFO 1 --- [bank-shared] [           main] r.k.s.SecurityServiceApplication         : Starting SecurityServiceApplication v0.0.1-SNAPSHOT using Java 21.0.8 with PID 1 (/app/app.jar started by root in /app)
security-service         | 2025-10-03T16:12:24.669Z  INFO 1 --- [bank-shared] [           main] r.k.s.SecurityServiceApplication         : No active profile set, falling back to 1 default profile: "default"
settings-service         | 2025-10-03T16:12:25.152Z  INFO 1 --- [bank-shared] [           main] o.s.o.j.p.SpringPersistenceUnitInfo      : No LoadTimeWeaver setup: ignoring JPA class transformer
fraud-detection          | 2025-10-03T16:12:25.229Z  INFO 1 --- [fraud-detection] [           main] com.zaxxer.hikari.pool.HikariPool        : HikariPool-1 - Added connection org.postgresql.jdbc.PgConnection@1a2773a8
fraud-detection          | 2025-10-03T16:12:25.286Z  INFO 1 --- [fraud-detection] [           main] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Start completed.
settings-service         | 2025-10-03T16:12:26.305Z  INFO 1 --- [bank-shared] [           main] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Starting...
notification-service     | 2025-10-03T16:12:27.286Z  INFO 1 --- [bank-shared] [           main] o.hibernate.jpa.internal.util.LogHelper  : HHH000204: Processing PersistenceUnitInfo [name: default]
otel-collector           | 2025-10-03T16:12:27.417Z	info	Logs	{"resource": {"service.instance.id": "4aa48a6d-7678-4f39-b57a-6fa72002086e", "service.name": "otelcol", "service.version": "0.132.0"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "logs", "resource logs": 5, "log records": 7}
otel-collector           | 2025-10-03T16:12:27.424Z	info	ResourceLog #0
otel-collector           | Resource SchemaURL: https://opentelemetry.io/schemas/1.24.0
otel-collector           | Resource attributes:
otel-collector           |      -> container.id: Str(39f4ff18951127ac8c0450512e9a37033fa15478db84c119a8e4f633002d31ea)
otel-collector           |      -> host.arch: Str(aarch64)
otel-collector           |      -> host.name: Str(39f4ff189511)
otel-collector           |      -> os.description: Str(Linux 6.10.14-linuxkit)
otel-collector           |      -> os.type: Str(linux)
otel-collector           |      -> process.command_args: Slice(["/opt/java/openjdk/bin/java","-javaagent:/app/opentelemetry-javaagent.jar","-jar","app.jar"])
otel-collector           |      -> process.executable.path: Str(/opt/java/openjdk/bin/java)
otel-collector           |      -> process.pid: Int(1)
otel-collector           |      -> process.runtime.description: Str(Eclipse Adoptium OpenJDK 64-Bit Server VM 21.0.8+9-LTS)
otel-collector           |      -> process.runtime.name: Str(OpenJDK Runtime Environment)
otel-collector           |      -> process.runtime.version: Str(21.0.8+9-LTS)
otel-collector           |      -> service.instance.id: Str(319f836a-b6f8-4ce0-a5f5-6f27a85ee280)
otel-collector           |      -> service.name: Str(bankapp)
otel-collector           |      -> service.version: Str(0.0.1-SNAPSHOT)
otel-collector           |      -> telemetry.distro.name: Str(opentelemetry-java-instrumentation)
otel-collector           |      -> telemetry.distro.version: Str(2.15.0)
otel-collector           |      -> telemetry.sdk.language: Str(java)
otel-collector           |      -> telemetry.sdk.name: Str(opentelemetry)
otel-collector           |      -> telemetry.sdk.version: Str(1.49.0)
otel-collector           | ScopeLogs #0
otel-collector           | ScopeLogs SchemaURL: 
otel-collector           | InstrumentationScope ru.katacademy.bank_app.BankAppApplication 
otel-collector           | LogRecord #0
otel-collector           | ObservedTimestamp: 2025-10-03 16:12:17.233986376 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:17.124620501 +0000 UTC
otel-collector           | SeverityText: INFO
otel-collector           | SeverityNumber: Info(9)
otel-collector           | Body: Str(Starting BankAppApplication v0.0.1-SNAPSHOT using Java 21.0.8 with PID 1 (/app/app.jar started by root in /app))
otel-collector           | Trace ID: 
otel-collector           | Span ID: 
otel-collector           | Flags: 0
otel-collector           | ResourceLog #1
otel-collector           | Resource SchemaURL: https://opentelemetry.io/schemas/1.24.0
otel-collector           | Resource attributes:
otel-collector           |      -> container.id: Str(b7462027190fc5ca17c8fad62a6a7c6d248c5b38516fe3b1dfd9b3b6cf8f715b)
otel-collector           |      -> host.arch: Str(aarch64)
otel-collector           |      -> host.name: Str(b7462027190f)
otel-collector           |      -> os.description: Str(Linux 6.10.14-linuxkit)
otel-collector           |      -> os.type: Str(linux)
otel-collector           |      -> process.command_args: Slice(["/opt/java/openjdk/bin/java","-javaagent:/app/opentelemetry-javaagent.jar","-jar","app.jar"])
otel-collector           |      -> process.executable.path: Str(/opt/java/openjdk/bin/java)
otel-collector           |      -> process.pid: Int(1)
otel-collector           |      -> process.runtime.description: Str(Eclipse Adoptium OpenJDK 64-Bit Server VM 21.0.8+9-LTS)
otel-collector           |      -> process.runtime.name: Str(OpenJDK Runtime Environment)
otel-collector           |      -> process.runtime.version: Str(21.0.8+9-LTS)
otel-collector           |      -> service.instance.id: Str(88ceffbe-6ccf-45bf-b476-a5c5db2fc9f5)
otel-collector           |      -> service.name: Str(kyc-service)
otel-collector           |      -> service.version: Str(0.0.1-SNAPSHOT)
otel-collector           |      -> telemetry.distro.name: Str(opentelemetry-java-instrumentation)
otel-collector           |      -> telemetry.distro.version: Str(2.15.0)
otel-collector           |      -> telemetry.sdk.language: Str(java)
otel-collector           |      -> telemetry.sdk.name: Str(opentelemetry)
otel-collector           |      -> telemetry.sdk.version: Str(1.49.0)
otel-collector           | ScopeLogs #0
otel-collector           | ScopeLogs SchemaURL: 
otel-collector           | InstrumentationScope ru.katacademy.kycservice.KycServiceApplication 
otel-collector           | LogRecord #0
otel-collector           | ObservedTimestamp: 2025-10-03 16:12:16.421800084 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:16.417018168 +0000 UTC
otel-collector           | SeverityText: INFO
otel-collector           | SeverityNumber: Info(9)
otel-collector           | Body: Str(No active profile set, falling back to 1 default profile: "default")
otel-collector           | Trace ID: 
otel-collector           | Span ID: 
otel-collector           | Flags: 0
otel-collector           | ResourceLog #2
otel-collector           | Resource SchemaURL: https://opentelemetry.io/schemas/1.24.0
otel-collector           | Resource attributes:
otel-collector           |      -> container.id: Str(39f4ff18951127ac8c0450512e9a37033fa15478db84c119a8e4f633002d31ea)
otel-collector           |      -> host.arch: Str(aarch64)
otel-collector           |      -> host.name: Str(39f4ff189511)
otel-collector           |      -> os.description: Str(Linux 6.10.14-linuxkit)
otel-collector           |      -> os.type: Str(linux)
otel-collector           |      -> process.command_args: Slice(["/opt/java/openjdk/bin/java","-javaagent:/app/opentelemetry-javaagent.jar","-jar","app.jar"])
otel-collector           |      -> process.executable.path: Str(/opt/java/openjdk/bin/java)
otel-collector           |      -> process.pid: Int(1)
otel-collector           |      -> process.runtime.description: Str(Eclipse Adoptium OpenJDK 64-Bit Server VM 21.0.8+9-LTS)
otel-collector           |      -> process.runtime.name: Str(OpenJDK Runtime Environment)
otel-collector           |      -> process.runtime.version: Str(21.0.8+9-LTS)
otel-collector           |      -> service.instance.id: Str(319f836a-b6f8-4ce0-a5f5-6f27a85ee280)
otel-collector           |      -> service.name: Str(bankapp)
otel-collector           |      -> service.version: Str(0.0.1-SNAPSHOT)
otel-collector           |      -> telemetry.distro.name: Str(opentelemetry-java-instrumentation)
otel-collector           |      -> telemetry.distro.version: Str(2.15.0)
otel-collector           |      -> telemetry.sdk.language: Str(java)
otel-collector           |      -> telemetry.sdk.name: Str(opentelemetry)
otel-collector           |      -> telemetry.sdk.version: Str(1.49.0)
otel-collector           | ScopeLogs #0
otel-collector           | ScopeLogs SchemaURL: 
otel-collector           | InstrumentationScope ru.katacademy.bank_app.BankAppApplication 
otel-collector           | LogRecord #0
otel-collector           | ObservedTimestamp: 2025-10-03 16:12:17.82530096 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:17.814378252 +0000 UTC
otel-collector           | SeverityText: INFO
otel-collector           | SeverityNumber: Info(9)
otel-collector           | Body: Str(No active profile set, falling back to 1 default profile: "default")
otel-collector           | Trace ID: 
otel-collector           | Span ID: 
otel-collector           | Flags: 0
otel-collector           | ResourceLog #3
otel-collector           | Resource SchemaURL: https://opentelemetry.io/schemas/1.24.0
otel-collector           | Resource attributes:
otel-collector           |      -> container.id: Str(760f6b53c16009d5e985ba97a71d43520d7cc1bcea8fc6b6984fe64cd8aa49c1)
otel-collector           |      -> host.arch: Str(aarch64)
otel-collector           |      -> host.name: Str(760f6b53c160)
otel-collector           |      -> os.description: Str(Linux 6.10.14-linuxkit)
otel-collector           |      -> os.type: Str(linux)
otel-collector           |      -> process.command_args: Slice(["/opt/java/openjdk/bin/java","-javaagent:/app/opentelemetry-javaagent.jar","-jar","app.jar"])
otel-collector           |      -> process.executable.path: Str(/opt/java/openjdk/bin/java)
otel-collector           |      -> process.pid: Int(1)
otel-collector           |      -> process.runtime.description: Str(Eclipse Adoptium OpenJDK 64-Bit Server VM 21.0.8+9-LTS)
otel-collector           |      -> process.runtime.name: Str(OpenJDK Runtime Environment)
otel-collector           |      -> process.runtime.version: Str(21.0.8+9-LTS)
otel-collector           |      -> service.instance.id: Str(9b417095-e9ef-4f07-abb2-049482ceb128)
otel-collector           |      -> service.name: Str(auth-statistics-service)
otel-collector           |      -> service.version: Str(0.0.1-SNAPSHOT)
otel-collector           |      -> telemetry.distro.name: Str(opentelemetry-java-instrumentation)
otel-collector           |      -> telemetry.distro.version: Str(2.15.0)
otel-collector           |      -> telemetry.sdk.language: Str(java)
otel-collector           |      -> telemetry.sdk.name: Str(opentelemetry)
otel-collector           |      -> telemetry.sdk.version: Str(1.49.0)
otel-collector           | ScopeLogs #0
otel-collector           | ScopeLogs SchemaURL: 
otel-collector           | InstrumentationScope ru.katacademy.auth.AuthStatisticsService 
otel-collector           | LogRecord #0
otel-collector           | ObservedTimestamp: 2025-10-03 16:12:19.11854321 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:18.675446502 +0000 UTC
otel-collector           | SeverityText: INFO
otel-collector           | SeverityNumber: Info(9)
otel-collector           | Body: Str(Starting AuthStatisticsService v0.0.1-SNAPSHOT using Java 21.0.8 with PID 1 (/app/app.jar started by root in /app))
otel-collector           | Trace ID: 
otel-collector           | Span ID: 
otel-collector           | Flags: 0
otel-collector           | LogRecord #1
otel-collector           | ObservedTimestamp: 2025-10-03 16:12:19.306933127 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:19.306813211 +0000 UTC
otel-collector           | SeverityText: INFO
otel-collector           | SeverityNumber: Info(9)
otel-collector           | Body: Str(No active profile set, falling back to 1 default profile: "default")
otel-collector           | Trace ID: 
otel-collector           | Span ID: 
otel-collector           | Flags: 0
otel-collector           | ResourceLog #4
otel-collector           | Resource SchemaURL: https://opentelemetry.io/schemas/1.24.0
otel-collector           | Resource attributes:
otel-collector           |      -> container.id: Str(85a453b0cb0d19978dc616b0d20a22506c238700e8b6c4ace228f9c7bf06f34d)
otel-collector           |      -> host.arch: Str(aarch64)
otel-collector           |      -> host.name: Str(85a453b0cb0d)
otel-collector           |      -> os.description: Str(Linux 6.10.14-linuxkit)
otel-collector           |      -> os.type: Str(linux)
otel-collector           |      -> process.command_args: Slice(["/opt/java/openjdk/bin/java","-javaagent:/app/opentelemetry-javaagent.jar","-jar","app.jar"])
otel-collector           |      -> process.executable.path: Str(/opt/java/openjdk/bin/java)
otel-collector           |      -> process.pid: Int(1)
otel-collector           |      -> process.runtime.description: Str(Eclipse Adoptium OpenJDK 64-Bit Server VM 21.0.8+9-LTS)
otel-collector           |      -> process.runtime.name: Str(OpenJDK Runtime Environment)
otel-collector           |      -> process.runtime.version: Str(21.0.8+9-LTS)
otel-collector           |      -> service.instance.id: Str(dd672c4c-c3b6-49aa-acbe-5f1b73f92d54)
otel-collector           |      -> service.name: Str(user-service)
otel-collector           |      -> service.version: Str(0.0.1-SNAPSHOT)
otel-collector           |      -> telemetry.distro.name: Str(opentelemetry-java-instrumentation)
otel-collector           |      -> telemetry.distro.version: Str(2.15.0)
otel-collector           |      -> telemetry.sdk.language: Str(java)
otel-collector           |      -> telemetry.sdk.name: Str(opentelemetry)
otel-collector           |      -> telemetry.sdk.version: Str(1.49.0)
otel-collector           | ScopeLogs #0
otel-collector           | ScopeLogs SchemaURL: 
otel-collector           | InstrumentationScope ru.katacademy.bank_app.accountservice.AccountServiceApplication 
otel-collector           | LogRecord #0
otel-collector           | ObservedTimestamp: 2025-10-03 16:12:21.86221542 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:21.573066753 +0000 UTC
otel-collector           | SeverityText: INFO
otel-collector           | SeverityNumber: Info(9)
otel-collector           | Body: Str(Starting AccountServiceApplication v0.0.1-SNAPSHOT using Java 21.0.8 with PID 1 (/app/app.jar started by root in /app))
otel-collector           | Trace ID: 
otel-collector           | Span ID: 
otel-collector           | Flags: 0
otel-collector           | LogRecord #1
otel-collector           | ObservedTimestamp: 2025-10-03 16:12:22.030317379 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:22.030095629 +0000 UTC
otel-collector           | SeverityText: INFO
otel-collector           | SeverityNumber: Info(9)
otel-collector           | Body: Str(No active profile set, falling back to 1 default profile: "default")
otel-collector           | Trace ID: 
otel-collector           | Span ID: 
otel-collector           | Flags: 0
otel-collector           | 	{"resource": {"service.instance.id": "4aa48a6d-7678-4f39-b57a-6fa72002086e", "service.name": "otelcol", "service.version": "0.132.0"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "logs"}
fraud-detection          | 2025-10-03T16:12:27.460Z  INFO 1 --- [fraud-detection] [           main] o.hibernate.jpa.internal.util.LogHelper  : HHH000204: Processing PersistenceUnitInfo [name: default]
settings-service         | 2025-10-03T16:12:27.519Z  INFO 1 --- [bank-shared] [           main] com.zaxxer.hikari.pool.HikariPool        : HikariPool-1 - Added connection org.postgresql.jdbc.PgConnection@56ba8e8c
settings-service         | 2025-10-03T16:12:27.534Z  INFO 1 --- [bank-shared] [           main] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Start completed.
settings-service         | 2025-10-03T16:12:27.878Z  WARN 1 --- [bank-shared] [           main] org.hibernate.orm.deprecation            : HHH90000025: PostgreSQLDialect does not need to be specified explicitly using 'hibernate.dialect' (remove the property setting and it will be selected by default)
settings-service         | 2025-10-03T16:12:28.350Z  INFO 1 --- [bank-shared] [           main] org.hibernate.orm.connections.pooling    : HHH10001005: Database info:
settings-service         | 	Database JDBC URL [Connecting through datasource 'HikariDataSource (HikariPool-1)']
settings-service         | 	Database driver: undefined/unknown
settings-service         | 	Database version: 15.14
settings-service         | 	Autocommit mode: undefined/unknown
settings-service         | 	Isolation level: undefined/unknown
settings-service         | 	Minimum pool size: undefined/unknown
settings-service         | 	Maximum pool size: undefined/unknown
notification-service     | 2025-10-03T16:12:29.473Z  INFO 1 --- [bank-shared] [           main] org.hibernate.Version                    : HHH000412: Hibernate ORM core version 6.6.15.Final
fraud-detection          | 2025-10-03T16:12:29.856Z  INFO 1 --- [fraud-detection] [           main] org.hibernate.Version                    : HHH000412: Hibernate ORM core version 6.6.15.Final
api-gateway-1            | 2025-10-03T16:12:30.346Z  INFO 1 --- [api-gateway] [           main] o.s.c.g.r.RouteDefinitionRouteLocator    : Loaded RoutePredicateFactory [After]
api-gateway-1            | 2025-10-03T16:12:30.367Z  INFO 1 --- [api-gateway] [           main] o.s.c.g.r.RouteDefinitionRouteLocator    : Loaded RoutePredicateFactory [Before]
notification-service     | 2025-10-03T16:12:30.366Z  INFO 1 --- [bank-shared] [           main] o.h.c.internal.RegionFactoryInitiator    : HHH000026: Second-level cache disabled
api-gateway-1            | 2025-10-03T16:12:30.370Z  INFO 1 --- [api-gateway] [           main] o.s.c.g.r.RouteDefinitionRouteLocator    : Loaded RoutePredicateFactory [Between]
api-gateway-1            | 2025-10-03T16:12:30.378Z  INFO 1 --- [api-gateway] [           main] o.s.c.g.r.RouteDefinitionRouteLocator    : Loaded RoutePredicateFactory [Cookie]
api-gateway-1            | 2025-10-03T16:12:30.378Z  INFO 1 --- [api-gateway] [           main] o.s.c.g.r.RouteDefinitionRouteLocator    : Loaded RoutePredicateFactory [Header]
api-gateway-1            | 2025-10-03T16:12:30.378Z  INFO 1 --- [api-gateway] [           main] o.s.c.g.r.RouteDefinitionRouteLocator    : Loaded RoutePredicateFactory [Host]
api-gateway-1            | 2025-10-03T16:12:30.378Z  INFO 1 --- [api-gateway] [           main] o.s.c.g.r.RouteDefinitionRouteLocator    : Loaded RoutePredicateFactory [Method]
api-gateway-1            | 2025-10-03T16:12:30.378Z  INFO 1 --- [api-gateway] [           main] o.s.c.g.r.RouteDefinitionRouteLocator    : Loaded RoutePredicateFactory [Path]
api-gateway-1            | 2025-10-03T16:12:30.379Z  INFO 1 --- [api-gateway] [           main] o.s.c.g.r.RouteDefinitionRouteLocator    : Loaded RoutePredicateFactory [Query]
api-gateway-1            | 2025-10-03T16:12:30.379Z  INFO 1 --- [api-gateway] [           main] o.s.c.g.r.RouteDefinitionRouteLocator    : Loaded RoutePredicateFactory [ReadBody]
api-gateway-1            | 2025-10-03T16:12:30.379Z  INFO 1 --- [api-gateway] [           main] o.s.c.g.r.RouteDefinitionRouteLocator    : Loaded RoutePredicateFactory [RemoteAddr]
api-gateway-1            | 2025-10-03T16:12:30.379Z  INFO 1 --- [api-gateway] [           main] o.s.c.g.r.RouteDefinitionRouteLocator    : Loaded RoutePredicateFactory [XForwardedRemoteAddr]
api-gateway-1            | 2025-10-03T16:12:30.379Z  INFO 1 --- [api-gateway] [           main] o.s.c.g.r.RouteDefinitionRouteLocator    : Loaded RoutePredicateFactory [Weight]
api-gateway-1            | 2025-10-03T16:12:30.379Z  INFO 1 --- [api-gateway] [           main] o.s.c.g.r.RouteDefinitionRouteLocator    : Loaded RoutePredicateFactory [CloudFoundryRouteService]
fraud-detection          | 2025-10-03T16:12:30.447Z  INFO 1 --- [fraud-detection] [           main] o.h.c.internal.RegionFactoryInitiator    : HHH000026: Second-level cache disabled
otel-collector           | 2025-10-03T16:12:32.355Z	info	Metrics	{"resource": {"service.instance.id": "4aa48a6d-7678-4f39-b57a-6fa72002086e", "service.name": "otelcol", "service.version": "0.132.0"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics", "resource metrics": 5, "metrics": 85, "data points": 206}
otel-collector           | 2025-10-03T16:12:32.407Z	info	ResourceMetrics #0
otel-collector           | Resource SchemaURL: https://opentelemetry.io/schemas/1.24.0
otel-collector           | Resource attributes:
otel-collector           |      -> container.id: Str(b7462027190fc5ca17c8fad62a6a7c6d248c5b38516fe3b1dfd9b3b6cf8f715b)
otel-collector           |      -> host.arch: Str(aarch64)
otel-collector           |      -> host.name: Str(b7462027190f)
otel-collector           |      -> os.description: Str(Linux 6.10.14-linuxkit)
otel-collector           |      -> os.type: Str(linux)
otel-collector           |      -> process.command_args: Slice(["/opt/java/openjdk/bin/java","-javaagent:/app/opentelemetry-javaagent.jar","-jar","app.jar"])
otel-collector           |      -> process.executable.path: Str(/opt/java/openjdk/bin/java)
otel-collector           |      -> process.pid: Int(1)
otel-collector           |      -> process.runtime.description: Str(Eclipse Adoptium OpenJDK 64-Bit Server VM 21.0.8+9-LTS)
otel-collector           |      -> process.runtime.name: Str(OpenJDK Runtime Environment)
otel-collector           |      -> process.runtime.version: Str(21.0.8+9-LTS)
otel-collector           |      -> service.instance.id: Str(88ceffbe-6ccf-45bf-b476-a5c5db2fc9f5)
otel-collector           |      -> service.name: Str(kyc-service)
otel-collector           |      -> service.version: Str(0.0.1-SNAPSHOT)
otel-collector           |      -> telemetry.distro.name: Str(opentelemetry-java-instrumentation)
otel-collector           |      -> telemetry.distro.version: Str(2.15.0)
otel-collector           |      -> telemetry.sdk.language: Str(java)
otel-collector           |      -> telemetry.sdk.name: Str(opentelemetry)
otel-collector           |      -> telemetry.sdk.version: Str(1.49.0)
otel-collector           | ScopeMetrics #0
otel-collector           | ScopeMetrics SchemaURL: 
otel-collector           | InstrumentationScope io.opentelemetry.exporters.otlp-http 
otel-collector           | Metric #0
otel-collector           | Descriptor:
otel-collector           |      -> Name: otlp.exporter.seen
otel-collector           |      -> Description: 
otel-collector           |      -> Unit: 
otel-collector           |      -> DataType: Sum
otel-collector           |      -> IsMonotonic: true
otel-collector           |      -> AggregationTemporality: Cumulative
otel-collector           | NumberDataPoints #0
otel-collector           | Data point attributes:
otel-collector           |      -> type: Str(log)
otel-collector           | StartTimestamp: 2025-10-03 16:11:28.986453257 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.195884215 +0000 UTC
otel-collector           | Value: 2
otel-collector           | Metric #1
otel-collector           | Descriptor:
otel-collector           |      -> Name: otlp.exporter.exported
otel-collector           |      -> Description: 
otel-collector           |      -> Unit: 
otel-collector           |      -> DataType: Sum
otel-collector           |      -> IsMonotonic: true
otel-collector           |      -> AggregationTemporality: Cumulative
otel-collector           | NumberDataPoints #0
otel-collector           | Data point attributes:
otel-collector           |      -> success: Bool(true)
otel-collector           |      -> type: Str(log)
otel-collector           | StartTimestamp: 2025-10-03 16:11:28.986453257 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.195884215 +0000 UTC
otel-collector           | Value: 2
otel-collector           | ScopeMetrics #1
otel-collector           | ScopeMetrics SchemaURL: 
otel-collector           | InstrumentationScope io.opentelemetry.sdk.trace 
otel-collector           | Metric #0
otel-collector           | Descriptor:
otel-collector           |      -> Name: queueSize
otel-collector           |      -> Description: The number of items queued
otel-collector           |      -> Unit: 1
otel-collector           |      -> DataType: Gauge
otel-collector           | NumberDataPoints #0
otel-collector           | Data point attributes:
otel-collector           |      -> processorType: Str(BatchSpanProcessor)
otel-collector           | StartTimestamp: 2025-10-03 16:11:28.986453257 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.195884215 +0000 UTC
otel-collector           | Value: 0
otel-collector           | ScopeMetrics #2
otel-collector           | ScopeMetrics SchemaURL: 
otel-collector           | InstrumentationScope io.opentelemetry.runtime-telemetry-java8 2.15.0-alpha
otel-collector           | Metric #0
otel-collector           | Descriptor:
otel-collector           |      -> Name: jvm.cpu.recent_utilization
otel-collector           |      -> Description: Recent CPU utilization for the process as reported by the JVM.
otel-collector           |      -> Unit: 1
otel-collector           |      -> DataType: Gauge
otel-collector           | NumberDataPoints #0
otel-collector           | StartTimestamp: 2025-10-03 16:11:28.986453257 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.195884215 +0000 UTC
otel-collector           | Value: 0.000000
otel-collector           | Metric #1
otel-collector           | Descriptor:
otel-collector           |      -> Name: jvm.memory.limit
otel-collector           |      -> Description: Measure of max obtainable memory.
otel-collector           |      -> Unit: By
otel-collector           |      -> DataType: Sum
otel-collector           |      -> IsMonotonic: false
otel-collector           |      -> AggregationTemporality: Cumulative
otel-collector           | NumberDataPoints #0
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.memory.pool.name: Str(Compressed Class Space)
otel-collector           |      -> jvm.memory.type: Str(non_heap)
otel-collector           | StartTimestamp: 2025-10-03 16:11:28.986453257 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.195884215 +0000 UTC
otel-collector           | Value: 1073741824
otel-collector           | NumberDataPoints #1
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.memory.pool.name: Str(G1 Old Gen)
otel-collector           |      -> jvm.memory.type: Str(heap)
otel-collector           | StartTimestamp: 2025-10-03 16:11:28.986453257 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.195884215 +0000 UTC
otel-collector           | Value: 1027604480
otel-collector           | NumberDataPoints #2
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.memory.pool.name: Str(CodeHeap 'non-profiled nmethods')
otel-collector           |      -> jvm.memory.type: Str(non_heap)
otel-collector           | StartTimestamp: 2025-10-03 16:11:28.986453257 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.195884215 +0000 UTC
otel-collector           | Value: 122912768
otel-collector           | NumberDataPoints #3
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.memory.pool.name: Str(CodeHeap 'non-nmethods')
otel-collector           |      -> jvm.memory.type: Str(non_heap)
otel-collector           | StartTimestamp: 2025-10-03 16:11:28.986453257 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.195884215 +0000 UTC
otel-collector           | Value: 5836800
otel-collector           | NumberDataPoints #4
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.memory.pool.name: Str(CodeHeap 'profiled nmethods')
otel-collector           |      -> jvm.memory.type: Str(non_heap)
otel-collector           | StartTimestamp: 2025-10-03 16:11:28.986453257 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.195884215 +0000 UTC
otel-collector           | Value: 122908672
otel-collector           | Metric #2
otel-collector           | Descriptor:
otel-collector           |      -> Name: jvm.thread.count
otel-collector           |      -> Description: Number of executing platform threads.
otel-collector           |      -> Unit: {thread}
otel-collector           |      -> DataType: Sum
otel-collector           |      -> IsMonotonic: false
otel-collector           |      -> AggregationTemporality: Cumulative
otel-collector           | NumberDataPoints #0
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.thread.daemon: Bool(true)
otel-collector           |      -> jvm.thread.state: Str(timed_waiting)
otel-collector           | StartTimestamp: 2025-10-03 16:11:28.986453257 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.195884215 +0000 UTC
otel-collector           | Value: 7
otel-collector           | NumberDataPoints #1
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.thread.daemon: Bool(false)
otel-collector           |      -> jvm.thread.state: Str(runnable)
otel-collector           | StartTimestamp: 2025-10-03 16:11:28.986453257 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.195884215 +0000 UTC
otel-collector           | Value: 2
otel-collector           | NumberDataPoints #2
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.thread.daemon: Bool(true)
otel-collector           |      -> jvm.thread.state: Str(runnable)
otel-collector           | StartTimestamp: 2025-10-03 16:11:28.986453257 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.195884215 +0000 UTC
otel-collector           | Value: 4
otel-collector           | NumberDataPoints #3
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.thread.daemon: Bool(true)
otel-collector           |      -> jvm.thread.state: Str(waiting)
otel-collector           | StartTimestamp: 2025-10-03 16:11:28.986453257 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.195884215 +0000 UTC
otel-collector           | Value: 2
otel-collector           | Metric #3
otel-collector           | Descriptor:
otel-collector           |      -> Name: jvm.class.count
otel-collector           |      -> Description: Number of classes currently loaded.
otel-collector           |      -> Unit: {class}
otel-collector           |      -> DataType: Sum
otel-collector           |      -> IsMonotonic: false
otel-collector           |      -> AggregationTemporality: Cumulative
otel-collector           | NumberDataPoints #0
otel-collector           | StartTimestamp: 2025-10-03 16:11:28.986453257 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.195884215 +0000 UTC
otel-collector           | Value: 9417
otel-collector           | Metric #4
otel-collector           | Descriptor:
otel-collector           |      -> Name: jvm.class.unloaded
otel-collector           |      -> Description: Number of classes unloaded since JVM start.
otel-collector           |      -> Unit: {class}
otel-collector           |      -> DataType: Sum
otel-collector           |      -> IsMonotonic: true
otel-collector           |      -> AggregationTemporality: Cumulative
otel-collector           | NumberDataPoints #0
otel-collector           | StartTimestamp: 2025-10-03 16:11:28.986453257 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.195884215 +0000 UTC
otel-collector           | Value: 1
otel-collector           | Metric #5
otel-collector           | Descriptor:
otel-collector           |      -> Name: jvm.memory.committed
otel-collector           |      -> Description: Measure of memory committed.
otel-collector           |      -> Unit: By
otel-collector           |      -> DataType: Sum
otel-collector           |      -> IsMonotonic: false
otel-collector           |      -> AggregationTemporality: Cumulative
otel-collector           | NumberDataPoints #0
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.memory.pool.name: Str(Compressed Class Space)
otel-collector           |      -> jvm.memory.type: Str(non_heap)
otel-collector           | StartTimestamp: 2025-10-03 16:11:28.986453257 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.195884215 +0000 UTC
otel-collector           | Value: 6029312
otel-collector           | NumberDataPoints #1
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.memory.pool.name: Str(G1 Old Gen)
otel-collector           |      -> jvm.memory.type: Str(heap)
otel-collector           | StartTimestamp: 2025-10-03 16:11:28.986453257 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.195884215 +0000 UTC
otel-collector           | Value: 161480704
otel-collector           | NumberDataPoints #2
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.memory.pool.name: Str(G1 Survivor Space)
otel-collector           |      -> jvm.memory.type: Str(heap)
otel-collector           | StartTimestamp: 2025-10-03 16:11:28.986453257 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.195884215 +0000 UTC
otel-collector           | Value: 1048576
otel-collector           | NumberDataPoints #3
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.memory.pool.name: Str(CodeHeap 'non-profiled nmethods')
otel-collector           |      -> jvm.memory.type: Str(non_heap)
otel-collector           | StartTimestamp: 2025-10-03 16:11:28.986453257 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.195884215 +0000 UTC
otel-collector           | Value: 4259840
otel-collector           | NumberDataPoints #4
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.memory.pool.name: Str(G1 Eden Space)
otel-collector           |      -> jvm.memory.type: Str(heap)
otel-collector           | StartTimestamp: 2025-10-03 16:11:28.986453257 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.195884215 +0000 UTC
otel-collector           | Value: 41943040
otel-collector           | NumberDataPoints #5
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.memory.pool.name: Str(CodeHeap 'non-nmethods')
otel-collector           |      -> jvm.memory.type: Str(non_heap)
otel-collector           | StartTimestamp: 2025-10-03 16:11:28.986453257 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.195884215 +0000 UTC
otel-collector           | Value: 2555904
otel-collector           | NumberDataPoints #6
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.memory.pool.name: Str(Metaspace)
otel-collector           |      -> jvm.memory.type: Str(non_heap)
otel-collector           | StartTimestamp: 2025-10-03 16:11:28.986453257 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.195884215 +0000 UTC
otel-collector           | Value: 44433408
otel-collector           | NumberDataPoints #7
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.memory.pool.name: Str(CodeHeap 'profiled nmethods')
otel-collector           |      -> jvm.memory.type: Str(non_heap)
otel-collector           | StartTimestamp: 2025-10-03 16:11:28.986453257 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.195884215 +0000 UTC
otel-collector           | Value: 13172736
otel-collector           | Metric #6
otel-collector           | Descriptor:
otel-collector           |      -> Name: jvm.cpu.time
otel-collector           |      -> Description: CPU time used by the process as reported by the JVM.
otel-collector           |      -> Unit: s
otel-collector           |      -> DataType: Sum
otel-collector           |      -> IsMonotonic: true
otel-collector           |      -> AggregationTemporality: Cumulative
otel-collector           | NumberDataPoints #0
otel-collector           | StartTimestamp: 2025-10-03 16:11:28.986453257 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.195884215 +0000 UTC
otel-collector           | Value: 32.170000
otel-collector           | Metric #7
otel-collector           | Descriptor:
otel-collector           |      -> Name: jvm.memory.used_after_last_gc
otel-collector           |      -> Description: Measure of memory used, as measured after the most recent garbage collection event on this pool.
otel-collector           |      -> Unit: By
otel-collector           |      -> DataType: Sum
otel-collector           |      -> IsMonotonic: false
otel-collector           |      -> AggregationTemporality: Cumulative
otel-collector           | NumberDataPoints #0
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.memory.pool.name: Str(G1 Old Gen)
otel-collector           |      -> jvm.memory.type: Str(heap)
otel-collector           | StartTimestamp: 2025-10-03 16:11:28.986453257 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.195884215 +0000 UTC
otel-collector           | Value: 29880704
otel-collector           | NumberDataPoints #1
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.memory.pool.name: Str(G1 Survivor Space)
otel-collector           |      -> jvm.memory.type: Str(heap)
otel-collector           | StartTimestamp: 2025-10-03 16:11:28.986453257 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.195884215 +0000 UTC
otel-collector           | Value: 673272
otel-collector           | NumberDataPoints #2
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.memory.pool.name: Str(G1 Eden Space)
otel-collector           |      -> jvm.memory.type: Str(heap)
otel-collector           | StartTimestamp: 2025-10-03 16:11:28.986453257 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.195884215 +0000 UTC
otel-collector           | Value: 0
otel-collector           | Metric #8
otel-collector           | Descriptor:
otel-collector           |      -> Name: jvm.memory.used
otel-collector           |      -> Description: Measure of memory used.
otel-collector           |      -> Unit: By
otel-collector           |      -> DataType: Sum
otel-collector           |      -> IsMonotonic: false
otel-collector           |      -> AggregationTemporality: Cumulative
otel-collector           | NumberDataPoints #0
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.memory.pool.name: Str(Compressed Class Space)
otel-collector           |      -> jvm.memory.type: Str(non_heap)
otel-collector           | StartTimestamp: 2025-10-03 16:11:28.986453257 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.195884215 +0000 UTC
otel-collector           | Value: 5728600
otel-collector           | NumberDataPoints #1
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.memory.pool.name: Str(G1 Old Gen)
otel-collector           |      -> jvm.memory.type: Str(heap)
otel-collector           | StartTimestamp: 2025-10-03 16:11:28.986453257 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.195884215 +0000 UTC
otel-collector           | Value: 29880704
otel-collector           | NumberDataPoints #2
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.memory.pool.name: Str(G1 Survivor Space)
otel-collector           |      -> jvm.memory.type: Str(heap)
otel-collector           | StartTimestamp: 2025-10-03 16:11:28.986453257 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.195884215 +0000 UTC
otel-collector           | Value: 673272
otel-collector           | NumberDataPoints #3
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.memory.pool.name: Str(CodeHeap 'non-profiled nmethods')
otel-collector           |      -> jvm.memory.type: Str(non_heap)
otel-collector           | StartTimestamp: 2025-10-03 16:11:28.986453257 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.195884215 +0000 UTC
otel-collector           | Value: 4229248
otel-collector           | NumberDataPoints #4
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.memory.pool.name: Str(G1 Eden Space)
otel-collector           |      -> jvm.memory.type: Str(heap)
otel-collector           | StartTimestamp: 2025-10-03 16:11:28.986453257 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.195884215 +0000 UTC
otel-collector           | Value: 1048576
otel-collector           | NumberDataPoints #5
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.memory.pool.name: Str(CodeHeap 'non-nmethods')
otel-collector           |      -> jvm.memory.type: Str(non_heap)
otel-collector           | StartTimestamp: 2025-10-03 16:11:28.986453257 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.195884215 +0000 UTC
otel-collector           | Value: 1523328
otel-collector           | NumberDataPoints #6
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.memory.pool.name: Str(Metaspace)
otel-collector           |      -> jvm.memory.type: Str(non_heap)
otel-collector           | StartTimestamp: 2025-10-03 16:11:28.986453257 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.195884215 +0000 UTC
otel-collector           | Value: 43772328
otel-collector           | NumberDataPoints #7
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.memory.pool.name: Str(CodeHeap 'profiled nmethods')
otel-collector           |      -> jvm.memory.type: Str(non_heap)
otel-collector           | StartTimestamp: 2025-10-03 16:11:28.986453257 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.195884215 +0000 UTC
otel-collector           | Value: 11579008
otel-collector           | Metric #9
otel-collector           | Descriptor:
otel-collector           |      -> Name: jvm.cpu.count
otel-collector           |      -> Description: Number of processors available to the Java virtual machine.
otel-collector           |      -> Unit: {cpu}
otel-collector           |      -> DataType: Sum
otel-collector           |      -> IsMonotonic: false
otel-collector           |      -> AggregationTemporality: Cumulative
otel-collector           | NumberDataPoints #0
otel-collector           | StartTimestamp: 2025-10-03 16:11:28.986453257 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.195884215 +0000 UTC
otel-collector           | Value: 5
otel-collector           | Metric #10
otel-collector           | Descriptor:
otel-collector           |      -> Name: jvm.class.loaded
otel-collector           |      -> Description: Number of classes loaded since JVM start.
otel-collector           |      -> Unit: {class}
otel-collector           |      -> DataType: Sum
otel-collector           |      -> IsMonotonic: true
otel-collector           |      -> AggregationTemporality: Cumulative
otel-collector           | NumberDataPoints #0
otel-collector           | StartTimestamp: 2025-10-03 16:11:28.986453257 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.195884215 +0000 UTC
otel-collector           | Value: 9418
otel-collector           | Metric #11
otel-collector           | Descriptor:
otel-collector           |      -> Name: jvm.gc.duration
otel-collector           |      -> Description: Duration of JVM garbage collection actions.
otel-collector           |      -> Unit: s
otel-collector           |      -> DataType: Histogram
otel-collector           |      -> AggregationTemporality: Cumulative
otel-collector           | HistogramDataPoints #0
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.gc.action: Str(end of concurrent GC pause)
otel-collector           |      -> jvm.gc.name: Str(G1 Concurrent GC)
otel-collector           | StartTimestamp: 2025-10-03 16:11:28.986453257 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.195884215 +0000 UTC
otel-collector           | Count: 2
otel-collector           | Sum: 0.489000
otel-collector           | Min: 0.001000
otel-collector           | Max: 0.488000
otel-collector           | ExplicitBounds #0: 0.010000
otel-collector           | ExplicitBounds #1: 0.100000
otel-collector           | ExplicitBounds #2: 1.000000
otel-collector           | ExplicitBounds #3: 10.000000
otel-collector           | Buckets #0, Count: 1
otel-collector           | Buckets #1, Count: 0
otel-collector           | Buckets #2, Count: 1
otel-collector           | Buckets #3, Count: 0
otel-collector           | Buckets #4, Count: 0
otel-collector           | HistogramDataPoints #1
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.gc.action: Str(end of minor GC)
otel-collector           |      -> jvm.gc.name: Str(G1 Young Generation)
otel-collector           | StartTimestamp: 2025-10-03 16:11:28.986453257 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.195884215 +0000 UTC
otel-collector           | Count: 16
otel-collector           | Sum: 2.386000
otel-collector           | Min: 0.033000
otel-collector           | Max: 0.760000
otel-collector           | ExplicitBounds #0: 0.010000
otel-collector           | ExplicitBounds #1: 0.100000
otel-collector           | ExplicitBounds #2: 1.000000
otel-collector           | ExplicitBounds #3: 10.000000
otel-collector           | Buckets #0, Count: 0
otel-collector           | Buckets #1, Count: 6
otel-collector           | Buckets #2, Count: 10
otel-collector           | Buckets #3, Count: 0
otel-collector           | Buckets #4, Count: 0
otel-collector           | ScopeMetrics #3
otel-collector           | ScopeMetrics SchemaURL: 
otel-collector           | InstrumentationScope io.opentelemetry.sdk.logs 
otel-collector           | Metric #0
otel-collector           | Descriptor:
otel-collector           |      -> Name: processedLogs
otel-collector           |      -> Description: The number of logs processed by the BatchLogRecordProcessor. [dropped=true if they were dropped due to high throughput]
otel-collector           |      -> Unit: 1
otel-collector           |      -> DataType: Sum
otel-collector           |      -> IsMonotonic: true
otel-collector           |      -> AggregationTemporality: Cumulative
otel-collector           | NumberDataPoints #0
otel-collector           | Data point attributes:
otel-collector           |      -> dropped: Bool(false)
otel-collector           |      -> processorType: Str(BatchLogRecordProcessor)
otel-collector           | StartTimestamp: 2025-10-03 16:11:28.986453257 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.195884215 +0000 UTC
otel-collector           | Value: 2
otel-collector           | Metric #1
otel-collector           | Descriptor:
otel-collector           |      -> Name: queueSize
otel-collector           |      -> Description: The number of items queued
otel-collector           |      -> Unit: 1
otel-collector           |      -> DataType: Gauge
otel-collector           | NumberDataPoints #0
otel-collector           | Data point attributes:
otel-collector           |      -> processorType: Str(BatchLogRecordProcessor)
otel-collector           | StartTimestamp: 2025-10-03 16:11:28.986453257 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.195884215 +0000 UTC
otel-collector           | Value: 0
otel-collector           | ResourceMetrics #1
otel-collector           | Resource SchemaURL: https://opentelemetry.io/schemas/1.24.0
otel-collector           | Resource attributes:
otel-collector           |      -> container.id: Str(39f4ff18951127ac8c0450512e9a37033fa15478db84c119a8e4f633002d31ea)
otel-collector           |      -> host.arch: Str(aarch64)
otel-collector           |      -> host.name: Str(39f4ff189511)
otel-collector           |      -> os.description: Str(Linux 6.10.14-linuxkit)
otel-collector           |      -> os.type: Str(linux)
otel-collector           |      -> process.command_args: Slice(["/opt/java/openjdk/bin/java","-javaagent:/app/opentelemetry-javaagent.jar","-jar","app.jar"])
otel-collector           |      -> process.executable.path: Str(/opt/java/openjdk/bin/java)
otel-collector           |      -> process.pid: Int(1)
otel-collector           |      -> process.runtime.description: Str(Eclipse Adoptium OpenJDK 64-Bit Server VM 21.0.8+9-LTS)
otel-collector           |      -> process.runtime.name: Str(OpenJDK Runtime Environment)
otel-collector           |      -> process.runtime.version: Str(21.0.8+9-LTS)
otel-collector           |      -> service.instance.id: Str(319f836a-b6f8-4ce0-a5f5-6f27a85ee280)
otel-collector           |      -> service.name: Str(bankapp)
otel-collector           |      -> service.version: Str(0.0.1-SNAPSHOT)
otel-collector           |      -> telemetry.distro.name: Str(opentelemetry-java-instrumentation)
otel-collector           |      -> telemetry.distro.version: Str(2.15.0)
otel-collector           |      -> telemetry.sdk.language: Str(java)
otel-collector           |      -> telemetry.sdk.name: Str(opentelemetry)
otel-collector           |      -> telemetry.sdk.version: Str(1.49.0)
otel-collector           | ScopeMetrics #0
otel-collector           | ScopeMetrics SchemaURL: 
otel-collector           | InstrumentationScope io.opentelemetry.runtime-telemetry-java8 2.15.0-alpha
otel-collector           | Metric #0
otel-collector           | Descriptor:
otel-collector           |      -> Name: jvm.memory.used
otel-collector           |      -> Description: Measure of memory used.
otel-collector           |      -> Unit: By
otel-collector           |      -> DataType: Sum
otel-collector           |      -> IsMonotonic: false
otel-collector           |      -> AggregationTemporality: Cumulative
otel-collector           | NumberDataPoints #0
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.memory.pool.name: Str(Compressed Class Space)
otel-collector           |      -> jvm.memory.type: Str(non_heap)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.186809215 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.33587134 +0000 UTC
otel-collector           | Value: 5487176
otel-collector           | NumberDataPoints #1
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.memory.pool.name: Str(G1 Old Gen)
otel-collector           |      -> jvm.memory.type: Str(heap)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.186809215 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.33587134 +0000 UTC
otel-collector           | Value: 25408840
otel-collector           | NumberDataPoints #2
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.memory.pool.name: Str(G1 Survivor Space)
otel-collector           |      -> jvm.memory.type: Str(heap)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.186809215 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.33587134 +0000 UTC
otel-collector           | Value: 652240
otel-collector           | NumberDataPoints #3
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.memory.pool.name: Str(CodeHeap 'non-profiled nmethods')
otel-collector           |      -> jvm.memory.type: Str(non_heap)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.186809215 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.33587134 +0000 UTC
otel-collector           | Value: 4164224
otel-collector           | NumberDataPoints #4
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.memory.pool.name: Str(G1 Eden Space)
otel-collector           |      -> jvm.memory.type: Str(heap)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.186809215 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.33587134 +0000 UTC
otel-collector           | Value: 45088768
otel-collector           | NumberDataPoints #5
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.memory.pool.name: Str(CodeHeap 'non-nmethods')
otel-collector           |      -> jvm.memory.type: Str(non_heap)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.186809215 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.33587134 +0000 UTC
otel-collector           | Value: 1519360
otel-collector           | NumberDataPoints #6
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.memory.pool.name: Str(Metaspace)
otel-collector           |      -> jvm.memory.type: Str(non_heap)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.186809215 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.33587134 +0000 UTC
otel-collector           | Value: 42607656
otel-collector           | NumberDataPoints #7
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.memory.pool.name: Str(CodeHeap 'profiled nmethods')
otel-collector           |      -> jvm.memory.type: Str(non_heap)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.186809215 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.33587134 +0000 UTC
otel-collector           | Value: 11201664
otel-collector           | Metric #1
otel-collector           | Descriptor:
otel-collector           |      -> Name: jvm.cpu.recent_utilization
otel-collector           |      -> Description: Recent CPU utilization for the process as reported by the JVM.
otel-collector           |      -> Unit: 1
otel-collector           |      -> DataType: Gauge
otel-collector           | NumberDataPoints #0
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.186809215 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.33587134 +0000 UTC
otel-collector           | Value: 0.000000
otel-collector           | Metric #2
otel-collector           | Descriptor:
otel-collector           |      -> Name: jvm.cpu.time
otel-collector           |      -> Description: CPU time used by the process as reported by the JVM.
otel-collector           |      -> Unit: s
otel-collector           |      -> DataType: Sum
otel-collector           |      -> IsMonotonic: true
otel-collector           |      -> AggregationTemporality: Cumulative
otel-collector           | NumberDataPoints #0
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.186809215 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.33587134 +0000 UTC
otel-collector           | Value: 31.950000
otel-collector           | Metric #3
otel-collector           | Descriptor:
otel-collector           |      -> Name: jvm.memory.used_after_last_gc
otel-collector           |      -> Description: Measure of memory used, as measured after the most recent garbage collection event on this pool.
otel-collector           |      -> Unit: By
otel-collector           |      -> DataType: Sum
otel-collector           |      -> IsMonotonic: false
otel-collector           |      -> AggregationTemporality: Cumulative
otel-collector           | NumberDataPoints #0
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.memory.pool.name: Str(G1 Old Gen)
otel-collector           |      -> jvm.memory.type: Str(heap)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.186809215 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.33587134 +0000 UTC
otel-collector           | Value: 25408840
otel-collector           | NumberDataPoints #1
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.memory.pool.name: Str(G1 Survivor Space)
otel-collector           |      -> jvm.memory.type: Str(heap)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.186809215 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.33587134 +0000 UTC
otel-collector           | Value: 652240
otel-collector           | NumberDataPoints #2
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.memory.pool.name: Str(G1 Eden Space)
otel-collector           |      -> jvm.memory.type: Str(heap)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.186809215 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.33587134 +0000 UTC
otel-collector           | Value: 0
otel-collector           | Metric #4
otel-collector           | Descriptor:
otel-collector           |      -> Name: jvm.class.loaded
otel-collector           |      -> Description: Number of classes loaded since JVM start.
otel-collector           |      -> Unit: {class}
otel-collector           |      -> DataType: Sum
otel-collector           |      -> IsMonotonic: true
otel-collector           |      -> AggregationTemporality: Cumulative
otel-collector           | NumberDataPoints #0
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.186809215 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.33587134 +0000 UTC
otel-collector           | Value: 9042
otel-collector           | Metric #5
otel-collector           | Descriptor:
otel-collector           |      -> Name: jvm.memory.committed
otel-collector           |      -> Description: Measure of memory committed.
otel-collector           |      -> Unit: By
otel-collector           |      -> DataType: Sum
otel-collector           |      -> IsMonotonic: false
otel-collector           |      -> AggregationTemporality: Cumulative
otel-collector           | NumberDataPoints #0
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.memory.pool.name: Str(Compressed Class Space)
otel-collector           |      -> jvm.memory.type: Str(non_heap)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.186809215 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.33587134 +0000 UTC
otel-collector           | Value: 5767168
otel-collector           | NumberDataPoints #1
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.memory.pool.name: Str(G1 Old Gen)
otel-collector           |      -> jvm.memory.type: Str(heap)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.186809215 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.33587134 +0000 UTC
otel-collector           | Value: 30408704
otel-collector           | NumberDataPoints #2
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.memory.pool.name: Str(G1 Survivor Space)
otel-collector           |      -> jvm.memory.type: Str(heap)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.186809215 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.33587134 +0000 UTC
otel-collector           | Value: 1048576
otel-collector           | NumberDataPoints #3
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.memory.pool.name: Str(CodeHeap 'non-profiled nmethods')
otel-collector           |      -> jvm.memory.type: Str(non_heap)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.186809215 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.33587134 +0000 UTC
otel-collector           | Value: 4259840
otel-collector           | NumberDataPoints #4
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.memory.pool.name: Str(G1 Eden Space)
otel-collector           |      -> jvm.memory.type: Str(heap)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.186809215 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.33587134 +0000 UTC
otel-collector           | Value: 52428800
otel-collector           | NumberDataPoints #5
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.memory.pool.name: Str(CodeHeap 'non-nmethods')
otel-collector           |      -> jvm.memory.type: Str(non_heap)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.186809215 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.33587134 +0000 UTC
otel-collector           | Value: 2555904
otel-collector           | NumberDataPoints #6
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.memory.pool.name: Str(Metaspace)
otel-collector           |      -> jvm.memory.type: Str(non_heap)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.186809215 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.33587134 +0000 UTC
otel-collector           | Value: 43253760
otel-collector           | NumberDataPoints #7
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.memory.pool.name: Str(CodeHeap 'profiled nmethods')
otel-collector           |      -> jvm.memory.type: Str(non_heap)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.186809215 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.33587134 +0000 UTC
otel-collector           | Value: 12582912
otel-collector           | Metric #6
otel-collector           | Descriptor:
otel-collector           |      -> Name: jvm.thread.count
otel-collector           |      -> Description: Number of executing platform threads.
otel-collector           |      -> Unit: {thread}
otel-collector           |      -> DataType: Sum
otel-collector           |      -> IsMonotonic: false
otel-collector           |      -> AggregationTemporality: Cumulative
otel-collector           | NumberDataPoints #0
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.thread.daemon: Bool(true)
otel-collector           |      -> jvm.thread.state: Str(timed_waiting)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.186809215 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.33587134 +0000 UTC
otel-collector           | Value: 7
otel-collector           | NumberDataPoints #1
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.thread.daemon: Bool(true)
otel-collector           |      -> jvm.thread.state: Str(waiting)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.186809215 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.33587134 +0000 UTC
otel-collector           | Value: 2
otel-collector           | NumberDataPoints #2
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.thread.daemon: Bool(true)
otel-collector           |      -> jvm.thread.state: Str(runnable)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.186809215 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.33587134 +0000 UTC
otel-collector           | Value: 4
otel-collector           | NumberDataPoints #3
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.thread.daemon: Bool(false)
otel-collector           |      -> jvm.thread.state: Str(runnable)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.186809215 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.33587134 +0000 UTC
otel-collector           | Value: 1
otel-collector           | Metric #7
otel-collector           | Descriptor:
otel-collector           |      -> Name: jvm.memory.limit
otel-collector           |      -> Description: Measure of max obtainable memory.
otel-collector           |      -> Unit: By
otel-collector           |      -> DataType: Sum
otel-collector           |      -> IsMonotonic: false
otel-collector           |      -> AggregationTemporality: Cumulative
otel-collector           | NumberDataPoints #0
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.memory.pool.name: Str(Compressed Class Space)
otel-collector           |      -> jvm.memory.type: Str(non_heap)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.186809215 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.33587134 +0000 UTC
otel-collector           | Value: 1073741824
otel-collector           | NumberDataPoints #1
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.memory.pool.name: Str(G1 Old Gen)
otel-collector           |      -> jvm.memory.type: Str(heap)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.186809215 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.33587134 +0000 UTC
otel-collector           | Value: 1027604480
otel-collector           | NumberDataPoints #2
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.memory.pool.name: Str(CodeHeap 'non-profiled nmethods')
otel-collector           |      -> jvm.memory.type: Str(non_heap)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.186809215 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.33587134 +0000 UTC
otel-collector           | Value: 122912768
otel-collector           | NumberDataPoints #3
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.memory.pool.name: Str(CodeHeap 'non-nmethods')
otel-collector           |      -> jvm.memory.type: Str(non_heap)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.186809215 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.33587134 +0000 UTC
otel-collector           | Value: 5836800
otel-collector           | NumberDataPoints #4
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.memory.pool.name: Str(CodeHeap 'profiled nmethods')
otel-collector           |      -> jvm.memory.type: Str(non_heap)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.186809215 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.33587134 +0000 UTC
otel-collector           | Value: 122908672
otel-collector           | Metric #8
otel-collector           | Descriptor:
otel-collector           |      -> Name: jvm.gc.duration
otel-collector           |      -> Description: Duration of JVM garbage collection actions.
otel-collector           |      -> Unit: s
otel-collector           |      -> DataType: Histogram
otel-collector           |      -> AggregationTemporality: Cumulative
otel-collector           | HistogramDataPoints #0
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.gc.action: Str(end of concurrent GC pause)
otel-collector           |      -> jvm.gc.name: Str(G1 Concurrent GC)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.186809215 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.33587134 +0000 UTC
otel-collector           | Count: 2
otel-collector           | Sum: 0.781000
otel-collector           | Min: 0.000000
otel-collector           | Max: 0.781000
otel-collector           | ExplicitBounds #0: 0.010000
otel-collector           | ExplicitBounds #1: 0.100000
otel-collector           | ExplicitBounds #2: 1.000000
otel-collector           | ExplicitBounds #3: 10.000000
otel-collector           | Buckets #0, Count: 1
otel-collector           | Buckets #1, Count: 0
otel-collector           | Buckets #2, Count: 1
otel-collector           | Buckets #3, Count: 0
otel-collector           | Buckets #4, Count: 0
otel-collector           | HistogramDataPoints #1
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.gc.action: Str(end of minor GC)
otel-collector           |      -> jvm.gc.name: Str(G1 Young Generation)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.186809215 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.33587134 +0000 UTC
otel-collector           | Count: 11
otel-collector           | Sum: 1.856000
otel-collector           | Min: 0.053000
otel-collector           | Max: 0.623000
otel-collector           | ExplicitBounds #0: 0.010000
otel-collector           | ExplicitBounds #1: 0.100000
otel-collector           | ExplicitBounds #2: 1.000000
otel-collector           | ExplicitBounds #3: 10.000000
otel-collector           | Buckets #0, Count: 0
otel-collector           | Buckets #1, Count: 3
otel-collector           | Buckets #2, Count: 8
otel-collector           | Buckets #3, Count: 0
otel-collector           | Buckets #4, Count: 0
otel-collector           | Metric #9
otel-collector           | Descriptor:
otel-collector           |      -> Name: jvm.cpu.count
otel-collector           |      -> Description: Number of processors available to the Java virtual machine.
otel-collector           |      -> Unit: {cpu}
otel-collector           |      -> DataType: Sum
otel-collector           |      -> IsMonotonic: false
otel-collector           |      -> AggregationTemporality: Cumulative
otel-collector           | NumberDataPoints #0
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.186809215 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.33587134 +0000 UTC
otel-collector           | Value: 5
otel-collector           | Metric #10
otel-collector           | Descriptor:
otel-collector           |      -> Name: jvm.class.count
otel-collector           |      -> Description: Number of classes currently loaded.
otel-collector           |      -> Unit: {class}
otel-collector           |      -> DataType: Sum
otel-collector           |      -> IsMonotonic: false
otel-collector           |      -> AggregationTemporality: Cumulative
otel-collector           | NumberDataPoints #0
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.186809215 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.33587134 +0000 UTC
otel-collector           | Value: 9041
otel-collector           | Metric #11
otel-collector           | Descriptor:
otel-collector           |      -> Name: jvm.class.unloaded
otel-collector           |      -> Description: Number of classes unloaded since JVM start.
otel-collector           |      -> Unit: {class}
otel-collector           |      -> DataType: Sum
otel-collector           |      -> IsMonotonic: true
otel-collector           |      -> AggregationTemporality: Cumulative
otel-collector           | NumberDataPoints #0
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.186809215 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.33587134 +0000 UTC
otel-collector           | Value: 1
otel-collector           | ScopeMetrics #1
otel-collector           | ScopeMetrics SchemaURL: 
otel-collector           | InstrumentationScope io.opentelemetry.exporters.otlp-http 
otel-collector           | Metric #0
otel-collector           | Descriptor:
otel-collector           |      -> Name: otlp.exporter.seen
otel-collector           |      -> Description: 
otel-collector           |      -> Unit: 
otel-collector           |      -> DataType: Sum
otel-collector           |      -> IsMonotonic: true
otel-collector           |      -> AggregationTemporality: Cumulative
otel-collector           | NumberDataPoints #0
otel-collector           | Data point attributes:
otel-collector           |      -> type: Str(log)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.186809215 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.33587134 +0000 UTC
otel-collector           | Value: 2
otel-collector           | Metric #1
otel-collector           | Descriptor:
otel-collector           |      -> Name: otlp.exporter.exported
otel-collector           |      -> Description: 
otel-collector           |      -> Unit: 
otel-collector           |      -> DataType: Sum
otel-collector           |      -> IsMonotonic: true
otel-collector           |      -> AggregationTemporality: Cumulative
otel-collector           | NumberDataPoints #0
otel-collector           | Data point attributes:
otel-collector           |      -> success: Bool(true)
otel-collector           |      -> type: Str(log)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.186809215 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.33587134 +0000 UTC
otel-collector           | Value: 2
otel-collector           | ScopeMetrics #2
otel-collector           | ScopeMetrics SchemaURL: 
otel-collector           | InstrumentationScope io.opentelemetry.sdk.logs 
otel-collector           | Metric #0
otel-collector           | Descriptor:
otel-collector           |      -> Name: queueSize
otel-collector           |      -> Description: The number of items queued
otel-collector           |      -> Unit: 1
otel-collector           |      -> DataType: Gauge
otel-collector           | NumberDataPoints #0
otel-collector           | Data point attributes:
otel-collector           |      -> processorType: Str(BatchLogRecordProcessor)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.186809215 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.33587134 +0000 UTC
otel-collector           | Value: 0
otel-collector           | Metric #1
otel-collector           | Descriptor:
otel-collector           |      -> Name: processedLogs
otel-collector           |      -> Description: The number of logs processed by the BatchLogRecordProcessor. [dropped=true if they were dropped due to high throughput]
otel-collector           |      -> Unit: 1
otel-collector           |      -> DataType: Sum
otel-collector           |      -> IsMonotonic: true
otel-collector           |      -> AggregationTemporality: Cumulative
otel-collector           | NumberDataPoints #0
otel-collector           | Data point attributes:
otel-collector           |      -> dropped: Bool(false)
otel-collector           |      -> processorType: Str(BatchLogRecordProcessor)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.186809215 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.33587134 +0000 UTC
otel-collector           | Value: 2
otel-collector           | ScopeMetrics #3
otel-collector           | ScopeMetrics SchemaURL: 
otel-collector           | InstrumentationScope io.opentelemetry.sdk.trace 
otel-collector           | Metric #0
otel-collector           | Descriptor:
otel-collector           |      -> Name: queueSize
otel-collector           |      -> Description: The number of items queued
otel-collector           |      -> Unit: 1
otel-collector           |      -> DataType: Gauge
otel-collector           | NumberDataPoints #0
otel-collector           | Data point attributes:
otel-collector           |      -> processorType: Str(BatchSpanProcessor)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.186809215 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.33587134 +0000 UTC
otel-collector           | Value: 0
otel-collector           | ResourceMetrics #2
otel-collector           | Resource SchemaURL: https://opentelemetry.io/schemas/1.24.0
otel-collector           | Resource attributes:
otel-collector           |      -> container.id: Str(85a453b0cb0d19978dc616b0d20a22506c238700e8b6c4ace228f9c7bf06f34d)
otel-collector           |      -> host.arch: Str(aarch64)
otel-collector           |      -> host.name: Str(85a453b0cb0d)
otel-collector           |      -> os.description: Str(Linux 6.10.14-linuxkit)
otel-collector           |      -> os.type: Str(linux)
otel-collector           |      -> process.command_args: Slice(["/opt/java/openjdk/bin/java","-javaagent:/app/opentelemetry-javaagent.jar","-jar","app.jar"])
otel-collector           |      -> process.executable.path: Str(/opt/java/openjdk/bin/java)
otel-collector           |      -> process.pid: Int(1)
otel-collector           |      -> process.runtime.description: Str(Eclipse Adoptium OpenJDK 64-Bit Server VM 21.0.8+9-LTS)
otel-collector           |      -> process.runtime.name: Str(OpenJDK Runtime Environment)
otel-collector           |      -> process.runtime.version: Str(21.0.8+9-LTS)
otel-collector           |      -> service.instance.id: Str(dd672c4c-c3b6-49aa-acbe-5f1b73f92d54)
otel-collector           |      -> service.name: Str(user-service)
otel-collector           |      -> service.version: Str(0.0.1-SNAPSHOT)
otel-collector           |      -> telemetry.distro.name: Str(opentelemetry-java-instrumentation)
otel-collector           |      -> telemetry.distro.version: Str(2.15.0)
otel-collector           |      -> telemetry.sdk.language: Str(java)
otel-collector           |      -> telemetry.sdk.name: Str(opentelemetry)
otel-collector           |      -> telemetry.sdk.version: Str(1.49.0)
otel-collector           | ScopeMetrics #0
otel-collector           | ScopeMetrics SchemaURL: 
otel-collector           | InstrumentationScope io.opentelemetry.exporters.otlp-http 
otel-collector           | Metric #0
otel-collector           | Descriptor:
otel-collector           |      -> Name: otlp.exporter.seen
otel-collector           |      -> Description: 
otel-collector           |      -> Unit: 
otel-collector           |      -> DataType: Sum
otel-collector           |      -> IsMonotonic: true
otel-collector           |      -> AggregationTemporality: Cumulative
otel-collector           | NumberDataPoints #0
otel-collector           | Data point attributes:
otel-collector           |      -> type: Str(log)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.656694757 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.763905132 +0000 UTC
otel-collector           | Value: 2
otel-collector           | Metric #1
otel-collector           | Descriptor:
otel-collector           |      -> Name: otlp.exporter.exported
otel-collector           |      -> Description: 
otel-collector           |      -> Unit: 
otel-collector           |      -> DataType: Sum
otel-collector           |      -> IsMonotonic: true
otel-collector           |      -> AggregationTemporality: Cumulative
otel-collector           | NumberDataPoints #0
otel-collector           | Data point attributes:
otel-collector           |      -> success: Bool(true)
otel-collector           |      -> type: Str(log)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.656694757 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.763905132 +0000 UTC
otel-collector           | Value: 2
otel-collector           | ScopeMetrics #1
otel-collector           | ScopeMetrics SchemaURL: 
otel-collector           | InstrumentationScope io.opentelemetry.sdk.logs 
otel-collector           | Metric #0
otel-collector           | Descriptor:
otel-collector           |      -> Name: queueSize
otel-collector           |      -> Description: The number of items queued
otel-collector           |      -> Unit: 1
otel-collector           |      -> DataType: Gauge
otel-collector           | NumberDataPoints #0
otel-collector           | Data point attributes:
otel-collector           |      -> processorType: Str(BatchLogRecordProcessor)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.656694757 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.763905132 +0000 UTC
otel-collector           | Value: 0
otel-collector           | Metric #1
otel-collector           | Descriptor:
otel-collector           |      -> Name: processedLogs
otel-collector           |      -> Description: The number of logs processed by the BatchLogRecordProcessor. [dropped=true if they were dropped due to high throughput]
otel-collector           |      -> Unit: 1
otel-collector           |      -> DataType: Sum
otel-collector           |      -> IsMonotonic: true
otel-collector           |      -> AggregationTemporality: Cumulative
otel-collector           | NumberDataPoints #0
otel-collector           | Data point attributes:
otel-collector           |      -> dropped: Bool(false)
otel-collector           |      -> processorType: Str(BatchLogRecordProcessor)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.656694757 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.763905132 +0000 UTC
otel-collector           | Value: 2
otel-collector           | ScopeMetrics #2
otel-collector           | ScopeMetrics SchemaURL: 
otel-collector           | InstrumentationScope io.opentelemetry.runtime-telemetry-java8 2.15.0-alpha
otel-collector           | Metric #0
otel-collector           | Descriptor:
otel-collector           |      -> Name: jvm.memory.used
otel-collector           |      -> Description: Measure of memory used.
otel-collector           |      -> Unit: By
otel-collector           |      -> DataType: Sum
otel-collector           |      -> IsMonotonic: false
otel-collector           |      -> AggregationTemporality: Cumulative
otel-collector           | NumberDataPoints #0
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.memory.pool.name: Str(Compressed Class Space)
otel-collector           |      -> jvm.memory.type: Str(non_heap)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.656694757 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.763905132 +0000 UTC
otel-collector           | Value: 5337016
otel-collector           | NumberDataPoints #1
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.memory.pool.name: Str(G1 Old Gen)
otel-collector           |      -> jvm.memory.type: Str(heap)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.656694757 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.763905132 +0000 UTC
otel-collector           | Value: 26933584
otel-collector           | NumberDataPoints #2
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.memory.pool.name: Str(G1 Survivor Space)
otel-collector           |      -> jvm.memory.type: Str(heap)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.656694757 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.763905132 +0000 UTC
otel-collector           | Value: 3499232
otel-collector           | NumberDataPoints #3
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.memory.pool.name: Str(CodeHeap 'non-profiled nmethods')
otel-collector           |      -> jvm.memory.type: Str(non_heap)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.656694757 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.763905132 +0000 UTC
otel-collector           | Value: 4016384
otel-collector           | NumberDataPoints #4
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.memory.pool.name: Str(G1 Eden Space)
otel-collector           |      -> jvm.memory.type: Str(heap)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.656694757 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.763905132 +0000 UTC
otel-collector           | Value: 16777216
otel-collector           | NumberDataPoints #5
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.memory.pool.name: Str(CodeHeap 'non-nmethods')
otel-collector           |      -> jvm.memory.type: Str(non_heap)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.656694757 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.763905132 +0000 UTC
otel-collector           | Value: 1514752
otel-collector           | NumberDataPoints #6
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.memory.pool.name: Str(Metaspace)
otel-collector           |      -> jvm.memory.type: Str(non_heap)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.656694757 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.763905132 +0000 UTC
otel-collector           | Value: 40674216
otel-collector           | NumberDataPoints #7
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.memory.pool.name: Str(CodeHeap 'profiled nmethods')
otel-collector           |      -> jvm.memory.type: Str(non_heap)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.656694757 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.763905132 +0000 UTC
otel-collector           | Value: 11314176
otel-collector           | Metric #1
otel-collector           | Descriptor:
otel-collector           |      -> Name: jvm.cpu.recent_utilization
otel-collector           |      -> Description: Recent CPU utilization for the process as reported by the JVM.
otel-collector           |      -> Unit: 1
otel-collector           |      -> DataType: Gauge
otel-collector           | NumberDataPoints #0
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.656694757 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.763905132 +0000 UTC
otel-collector           | Value: 0.000000
otel-collector           | Metric #2
otel-collector           | Descriptor:
otel-collector           |      -> Name: jvm.cpu.time
otel-collector           |      -> Description: CPU time used by the process as reported by the JVM.
otel-collector           |      -> Unit: s
otel-collector           |      -> DataType: Sum
otel-collector           |      -> IsMonotonic: true
otel-collector           |      -> AggregationTemporality: Cumulative
otel-collector           | NumberDataPoints #0
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.656694757 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.763905132 +0000 UTC
otel-collector           | Value: 31.310000
otel-collector           | Metric #3
otel-collector           | Descriptor:
otel-collector           |      -> Name: jvm.memory.used_after_last_gc
otel-collector           |      -> Description: Measure of memory used, as measured after the most recent garbage collection event on this pool.
otel-collector           |      -> Unit: By
otel-collector           |      -> DataType: Sum
otel-collector           |      -> IsMonotonic: false
otel-collector           |      -> AggregationTemporality: Cumulative
otel-collector           | NumberDataPoints #0
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.memory.pool.name: Str(G1 Old Gen)
otel-collector           |      -> jvm.memory.type: Str(heap)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.656694757 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.763905132 +0000 UTC
otel-collector           | Value: 26933584
otel-collector           | NumberDataPoints #1
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.memory.pool.name: Str(G1 Survivor Space)
otel-collector           |      -> jvm.memory.type: Str(heap)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.656694757 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.763905132 +0000 UTC
otel-collector           | Value: 3499232
otel-collector           | NumberDataPoints #2
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.memory.pool.name: Str(G1 Eden Space)
otel-collector           |      -> jvm.memory.type: Str(heap)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.656694757 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.763905132 +0000 UTC
otel-collector           | Value: 0
otel-collector           | Metric #4
otel-collector           | Descriptor:
otel-collector           |      -> Name: jvm.class.loaded
otel-collector           |      -> Description: Number of classes loaded since JVM start.
otel-collector           |      -> Unit: {class}
otel-collector           |      -> DataType: Sum
otel-collector           |      -> IsMonotonic: true
otel-collector           |      -> AggregationTemporality: Cumulative
otel-collector           | NumberDataPoints #0
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.656694757 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.763905132 +0000 UTC
otel-collector           | Value: 8973
otel-collector           | Metric #5
otel-collector           | Descriptor:
otel-collector           |      -> Name: jvm.memory.committed
otel-collector           |      -> Description: Measure of memory committed.
otel-collector           |      -> Unit: By
otel-collector           |      -> DataType: Sum
otel-collector           |      -> IsMonotonic: false
otel-collector           |      -> AggregationTemporality: Cumulative
otel-collector           | NumberDataPoints #0
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.memory.pool.name: Str(Compressed Class Space)
otel-collector           |      -> jvm.memory.type: Str(non_heap)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.656694757 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.763905132 +0000 UTC
otel-collector           | Value: 5636096
otel-collector           | NumberDataPoints #1
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.memory.pool.name: Str(G1 Old Gen)
otel-collector           |      -> jvm.memory.type: Str(heap)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.656694757 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.763905132 +0000 UTC
otel-collector           | Value: 73400320
otel-collector           | NumberDataPoints #2
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.memory.pool.name: Str(G1 Survivor Space)
otel-collector           |      -> jvm.memory.type: Str(heap)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.656694757 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.763905132 +0000 UTC
otel-collector           | Value: 4194304
otel-collector           | NumberDataPoints #3
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.memory.pool.name: Str(CodeHeap 'non-profiled nmethods')
otel-collector           |      -> jvm.memory.type: Str(non_heap)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.656694757 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.763905132 +0000 UTC
otel-collector           | Value: 4259840
otel-collector           | NumberDataPoints #4
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.memory.pool.name: Str(G1 Eden Space)
otel-collector           |      -> jvm.memory.type: Str(heap)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.656694757 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.763905132 +0000 UTC
otel-collector           | Value: 24117248
otel-collector           | NumberDataPoints #5
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.memory.pool.name: Str(CodeHeap 'non-nmethods')
otel-collector           |      -> jvm.memory.type: Str(non_heap)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.656694757 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.763905132 +0000 UTC
otel-collector           | Value: 2555904
otel-collector           | NumberDataPoints #6
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.memory.pool.name: Str(Metaspace)
otel-collector           |      -> jvm.memory.type: Str(non_heap)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.656694757 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.763905132 +0000 UTC
otel-collector           | Value: 41287680
otel-collector           | NumberDataPoints #7
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.memory.pool.name: Str(CodeHeap 'profiled nmethods')
otel-collector           |      -> jvm.memory.type: Str(non_heap)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.656694757 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.763905132 +0000 UTC
otel-collector           | Value: 12976128
otel-collector           | Metric #6
otel-collector           | Descriptor:
otel-collector           |      -> Name: jvm.thread.count
otel-collector           |      -> Description: Number of executing platform threads.
otel-collector           |      -> Unit: {thread}
otel-collector           |      -> DataType: Sum
otel-collector           |      -> IsMonotonic: false
otel-collector           |      -> AggregationTemporality: Cumulative
otel-collector           | NumberDataPoints #0
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.thread.daemon: Bool(true)
otel-collector           |      -> jvm.thread.state: Str(timed_waiting)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.656694757 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.763905132 +0000 UTC
otel-collector           | Value: 7
otel-collector           | NumberDataPoints #1
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.thread.daemon: Bool(true)
otel-collector           |      -> jvm.thread.state: Str(waiting)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.656694757 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.763905132 +0000 UTC
otel-collector           | Value: 2
otel-collector           | NumberDataPoints #2
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.thread.daemon: Bool(true)
otel-collector           |      -> jvm.thread.state: Str(runnable)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.656694757 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.763905132 +0000 UTC
otel-collector           | Value: 4
otel-collector           | NumberDataPoints #3
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.thread.daemon: Bool(false)
otel-collector           |      -> jvm.thread.state: Str(runnable)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.656694757 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.763905132 +0000 UTC
otel-collector           | Value: 2
otel-collector           | Metric #7
otel-collector           | Descriptor:
otel-collector           |      -> Name: jvm.memory.limit
otel-collector           |      -> Description: Measure of max obtainable memory.
otel-collector           |      -> Unit: By
otel-collector           |      -> DataType: Sum
otel-collector           |      -> IsMonotonic: false
otel-collector           |      -> AggregationTemporality: Cumulative
otel-collector           | NumberDataPoints #0
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.memory.pool.name: Str(Compressed Class Space)
otel-collector           |      -> jvm.memory.type: Str(non_heap)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.656694757 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.763905132 +0000 UTC
otel-collector           | Value: 1073741824
otel-collector           | NumberDataPoints #1
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.memory.pool.name: Str(G1 Old Gen)
otel-collector           |      -> jvm.memory.type: Str(heap)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.656694757 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.763905132 +0000 UTC
otel-collector           | Value: 1027604480
otel-collector           | NumberDataPoints #2
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.memory.pool.name: Str(CodeHeap 'non-profiled nmethods')
otel-collector           |      -> jvm.memory.type: Str(non_heap)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.656694757 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.763905132 +0000 UTC
otel-collector           | Value: 122912768
otel-collector           | NumberDataPoints #3
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.memory.pool.name: Str(CodeHeap 'non-nmethods')
otel-collector           |      -> jvm.memory.type: Str(non_heap)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.656694757 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.763905132 +0000 UTC
otel-collector           | Value: 5836800
otel-collector           | NumberDataPoints #4
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.memory.pool.name: Str(CodeHeap 'profiled nmethods')
otel-collector           |      -> jvm.memory.type: Str(non_heap)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.656694757 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.763905132 +0000 UTC
otel-collector           | Value: 122908672
otel-collector           | Metric #8
otel-collector           | Descriptor:
otel-collector           |      -> Name: jvm.gc.duration
otel-collector           |      -> Description: Duration of JVM garbage collection actions.
otel-collector           |      -> Unit: s
otel-collector           |      -> DataType: Histogram
otel-collector           |      -> AggregationTemporality: Cumulative
otel-collector           | HistogramDataPoints #0
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.gc.action: Str(end of concurrent GC pause)
otel-collector           |      -> jvm.gc.name: Str(G1 Concurrent GC)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.656694757 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.763905132 +0000 UTC
otel-collector           | Count: 2
otel-collector           | Sum: 0.251000
otel-collector           | Min: 0.001000
otel-collector           | Max: 0.250000
otel-collector           | ExplicitBounds #0: 0.010000
otel-collector           | ExplicitBounds #1: 0.100000
otel-collector           | ExplicitBounds #2: 1.000000
otel-collector           | ExplicitBounds #3: 10.000000
otel-collector           | Buckets #0, Count: 1
otel-collector           | Buckets #1, Count: 0
otel-collector           | Buckets #2, Count: 1
otel-collector           | Buckets #3, Count: 0
otel-collector           | Buckets #4, Count: 0
otel-collector           | HistogramDataPoints #1
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.gc.action: Str(end of minor GC)
otel-collector           |      -> jvm.gc.name: Str(G1 Young Generation)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.656694757 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.763905132 +0000 UTC
otel-collector           | Count: 12
otel-collector           | Sum: 1.721000
otel-collector           | Min: 0.058000
otel-collector           | Max: 0.414000
otel-collector           | ExplicitBounds #0: 0.010000
otel-collector           | ExplicitBounds #1: 0.100000
otel-collector           | ExplicitBounds #2: 1.000000
otel-collector           | ExplicitBounds #3: 10.000000
otel-collector           | Buckets #0, Count: 0
otel-collector           | Buckets #1, Count: 3
otel-collector           | Buckets #2, Count: 9
otel-collector           | Buckets #3, Count: 0
otel-collector           | Buckets #4, Count: 0
otel-collector           | Metric #9
otel-collector           | Descriptor:
otel-collector           |      -> Name: jvm.cpu.count
otel-collector           |      -> Description: Number of processors available to the Java virtual machine.
otel-collector           |      -> Unit: {cpu}
otel-collector           |      -> DataType: Sum
otel-collector           |      -> IsMonotonic: false
otel-collector           |      -> AggregationTemporality: Cumulative
otel-collector           | NumberDataPoints #0
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.656694757 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.763905132 +0000 UTC
otel-collector           | Value: 5
otel-collector           | Metric #10
otel-collector           | Descriptor:
otel-collector           |      -> Name: jvm.class.count
otel-collector           |      -> Description: Number of classes currently loaded.
otel-collector           |      -> Unit: {class}
otel-collector           |      -> DataType: Sum
otel-collector           |      -> IsMonotonic: false
otel-collector           |      -> AggregationTemporality: Cumulative
otel-collector           | NumberDataPoints #0
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.656694757 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.763905132 +0000 UTC
otel-collector           | Value: 8972
otel-collector           | Metric #11
otel-collector           | Descriptor:
otel-collector           |      -> Name: jvm.class.unloaded
otel-collector           |      -> Description: Number of classes unloaded since JVM start.
otel-collector           |      -> Unit: {class}
otel-collector           |      -> DataType: Sum
otel-collector           |      -> IsMonotonic: true
otel-collector           |      -> AggregationTemporality: Cumulative
otel-collector           | NumberDataPoints #0
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.656694757 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.763905132 +0000 UTC
otel-collector           | Value: 1
otel-collector           | ScopeMetrics #3
otel-collector           | ScopeMetrics SchemaURL: 
otel-collector           | InstrumentationScope io.opentelemetry.sdk.trace 
otel-collector           | Metric #0
otel-collector           | Descriptor:
otel-collector           |      -> Name: queueSize
otel-collector           |      -> Description: The number of items queued
otel-collector           |      -> Unit: 1
otel-collector           |      -> DataType: Gauge
otel-collector           | NumberDataPoints #0
otel-collector           | Data point attributes:
otel-collector           |      -> processorType: Str(BatchSpanProcessor)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.656694757 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.763905132 +0000 UTC
otel-collector           | Value: 0
otel-collector           | ResourceMetrics #3
otel-collector           | Resource SchemaURL: https://opentelemetry.io/schemas/1.24.0
otel-collector           | Resource attributes:
otel-collector           |      -> container.id: Str(0666752b63c6f038ff3642eed2328cd1eb0fa66e27a671fa04a261189ed4d98f)
otel-collector           |      -> host.arch: Str(aarch64)
otel-collector           |      -> host.name: Str(0666752b63c6)
otel-collector           |      -> os.description: Str(Linux 6.10.14-linuxkit)
otel-collector           |      -> os.type: Str(linux)
otel-collector           |      -> process.command_args: Slice(["/opt/java/openjdk/bin/java","-javaagent:/app/opentelemetry-javaagent.jar","-jar","app.jar"])
otel-collector           |      -> process.executable.path: Str(/opt/java/openjdk/bin/java)
otel-collector           |      -> process.pid: Int(1)
otel-collector           |      -> process.runtime.description: Str(Eclipse Adoptium OpenJDK 64-Bit Server VM 21.0.8+9-LTS)
otel-collector           |      -> process.runtime.name: Str(OpenJDK Runtime Environment)
otel-collector           |      -> process.runtime.version: Str(21.0.8+9-LTS)
otel-collector           |      -> service.instance.id: Str(1ce10a93-a081-4fdc-8739-d45c4e1db2ea)
otel-collector           |      -> service.name: Str(security-service)
otel-collector           |      -> service.version: Str(0.0.1-SNAPSHOT)
otel-collector           |      -> telemetry.distro.name: Str(opentelemetry-java-instrumentation)
otel-collector           |      -> telemetry.distro.version: Str(2.15.0)
otel-collector           |      -> telemetry.sdk.language: Str(java)
otel-collector           |      -> telemetry.sdk.name: Str(opentelemetry)
otel-collector           |      -> telemetry.sdk.version: Str(1.49.0)
otel-collector           | ScopeMetrics #0
otel-collector           | ScopeMetrics SchemaURL: 
otel-collector           | InstrumentationScope io.opentelemetry.sdk.trace 
otel-collector           | Metric #0
otel-collector           | Descriptor:
otel-collector           |      -> Name: queueSize
otel-collector           |      -> Description: The number of items queued
otel-collector           |      -> Unit: 1
otel-collector           |      -> DataType: Gauge
otel-collector           | NumberDataPoints #0
otel-collector           | Data point attributes:
otel-collector           |      -> processorType: Str(BatchSpanProcessor)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.712313007 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.859758591 +0000 UTC
otel-collector           | Value: 0
otel-collector           | ScopeMetrics #1
otel-collector           | ScopeMetrics SchemaURL: 
otel-collector           | InstrumentationScope io.opentelemetry.sdk.logs 
otel-collector           | Metric #0
otel-collector           | Descriptor:
otel-collector           |      -> Name: queueSize
otel-collector           |      -> Description: The number of items queued
otel-collector           |      -> Unit: 1
otel-collector           |      -> DataType: Gauge
otel-collector           | NumberDataPoints #0
otel-collector           | Data point attributes:
otel-collector           |      -> processorType: Str(BatchLogRecordProcessor)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.712313007 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.859758591 +0000 UTC
otel-collector           | Value: 0
otel-collector           | Metric #1
otel-collector           | Descriptor:
otel-collector           |      -> Name: processedLogs
otel-collector           |      -> Description: The number of logs processed by the BatchLogRecordProcessor. [dropped=true if they were dropped due to high throughput]
otel-collector           |      -> Unit: 1
otel-collector           |      -> DataType: Sum
otel-collector           |      -> IsMonotonic: true
otel-collector           |      -> AggregationTemporality: Cumulative
otel-collector           | NumberDataPoints #0
otel-collector           | Data point attributes:
otel-collector           |      -> dropped: Bool(false)
otel-collector           |      -> processorType: Str(BatchLogRecordProcessor)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.712313007 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.859758591 +0000 UTC
otel-collector           | Value: 1
otel-collector           | ScopeMetrics #2
otel-collector           | ScopeMetrics SchemaURL: 
otel-collector           | InstrumentationScope io.opentelemetry.exporters.otlp-http 
otel-collector           | Metric #0
otel-collector           | Descriptor:
otel-collector           |      -> Name: otlp.exporter.seen
otel-collector           |      -> Description: 
otel-collector           |      -> Unit: 
otel-collector           |      -> DataType: Sum
otel-collector           |      -> IsMonotonic: true
otel-collector           |      -> AggregationTemporality: Cumulative
otel-collector           | NumberDataPoints #0
otel-collector           | Data point attributes:
otel-collector           |      -> type: Str(log)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.712313007 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.859758591 +0000 UTC
otel-collector           | Value: 1
otel-collector           | Metric #1
otel-collector           | Descriptor:
otel-collector           |      -> Name: otlp.exporter.exported
otel-collector           |      -> Description: 
otel-collector           |      -> Unit: 
otel-collector           |      -> DataType: Sum
otel-collector           |      -> IsMonotonic: true
otel-collector           |      -> AggregationTemporality: Cumulative
otel-collector           | NumberDataPoints #0
otel-collector           | Data point attributes:
otel-collector           |      -> success: Bool(true)
otel-collector           |      -> type: Str(log)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.712313007 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.859758591 +0000 UTC
otel-collector           | Value: 1
otel-collector           | ScopeMetrics #3
otel-collector           | ScopeMetrics SchemaURL: 
otel-collector           | InstrumentationScope io.opentelemetry.runtime-telemetry-java8 2.15.0-alpha
otel-collector           | Metric #0
otel-collector           | Descriptor:
otel-collector           |      -> Name: jvm.memory.used
otel-collector           |      -> Description: Measure of memory used.
otel-collector           |      -> Unit: By
otel-collector           |      -> DataType: Sum
otel-collector           |      -> IsMonotonic: false
otel-collector           |      -> AggregationTemporality: Cumulative
otel-collector           | NumberDataPoints #0
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.memory.pool.name: Str(Compressed Class Space)
otel-collector           |      -> jvm.memory.type: Str(non_heap)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.712313007 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.859758591 +0000 UTC
otel-collector           | Value: 5243144
otel-collector           | NumberDataPoints #1
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.memory.pool.name: Str(G1 Old Gen)
otel-collector           |      -> jvm.memory.type: Str(heap)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.712313007 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.859758591 +0000 UTC
otel-collector           | Value: 22253736
otel-collector           | NumberDataPoints #2
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.memory.pool.name: Str(G1 Survivor Space)
otel-collector           |      -> jvm.memory.type: Str(heap)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.712313007 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.859758591 +0000 UTC
otel-collector           | Value: 2076064
otel-collector           | NumberDataPoints #3
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.memory.pool.name: Str(CodeHeap 'non-profiled nmethods')
otel-collector           |      -> jvm.memory.type: Str(non_heap)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.712313007 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.859758591 +0000 UTC
otel-collector           | Value: 4017024
otel-collector           | NumberDataPoints #4
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.memory.pool.name: Str(G1 Eden Space)
otel-collector           |      -> jvm.memory.type: Str(heap)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.712313007 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.859758591 +0000 UTC
otel-collector           | Value: 41943040
otel-collector           | NumberDataPoints #5
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.memory.pool.name: Str(CodeHeap 'non-nmethods')
otel-collector           |      -> jvm.memory.type: Str(non_heap)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.712313007 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.859758591 +0000 UTC
otel-collector           | Value: 1516544
otel-collector           | NumberDataPoints #6
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.memory.pool.name: Str(Metaspace)
otel-collector           |      -> jvm.memory.type: Str(non_heap)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.712313007 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.859758591 +0000 UTC
otel-collector           | Value: 40560024
otel-collector           | NumberDataPoints #7
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.memory.pool.name: Str(CodeHeap 'profiled nmethods')
otel-collector           |      -> jvm.memory.type: Str(non_heap)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.712313007 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.859758591 +0000 UTC
otel-collector           | Value: 10634496
otel-collector           | Metric #1
otel-collector           | Descriptor:
otel-collector           |      -> Name: jvm.cpu.recent_utilization
otel-collector           |      -> Description: Recent CPU utilization for the process as reported by the JVM.
otel-collector           |      -> Unit: 1
otel-collector           |      -> DataType: Gauge
otel-collector           | NumberDataPoints #0
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.712313007 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.859758591 +0000 UTC
otel-collector           | Value: 0.000000
otel-collector           | Metric #2
otel-collector           | Descriptor:
otel-collector           |      -> Name: jvm.cpu.time
otel-collector           |      -> Description: CPU time used by the process as reported by the JVM.
otel-collector           |      -> Unit: s
otel-collector           |      -> DataType: Sum
otel-collector           |      -> IsMonotonic: true
otel-collector           |      -> AggregationTemporality: Cumulative
otel-collector           | NumberDataPoints #0
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.712313007 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.859758591 +0000 UTC
otel-collector           | Value: 30.660000
otel-collector           | Metric #3
otel-collector           | Descriptor:
otel-collector           |      -> Name: jvm.memory.used_after_last_gc
otel-collector           |      -> Description: Measure of memory used, as measured after the most recent garbage collection event on this pool.
otel-collector           |      -> Unit: By
otel-collector           |      -> DataType: Sum
otel-collector           |      -> IsMonotonic: false
otel-collector           |      -> AggregationTemporality: Cumulative
otel-collector           | NumberDataPoints #0
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.memory.pool.name: Str(G1 Old Gen)
otel-collector           |      -> jvm.memory.type: Str(heap)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.712313007 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.859758591 +0000 UTC
otel-collector           | Value: 22253736
otel-collector           | NumberDataPoints #1
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.memory.pool.name: Str(G1 Survivor Space)
otel-collector           |      -> jvm.memory.type: Str(heap)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.712313007 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.859758591 +0000 UTC
otel-collector           | Value: 2076064
otel-collector           | NumberDataPoints #2
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.memory.pool.name: Str(G1 Eden Space)
otel-collector           |      -> jvm.memory.type: Str(heap)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.712313007 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.859758591 +0000 UTC
otel-collector           | Value: 0
otel-collector           | Metric #4
otel-collector           | Descriptor:
otel-collector           |      -> Name: jvm.class.loaded
otel-collector           |      -> Description: Number of classes loaded since JVM start.
otel-collector           |      -> Unit: {class}
otel-collector           |      -> DataType: Sum
otel-collector           |      -> IsMonotonic: true
otel-collector           |      -> AggregationTemporality: Cumulative
otel-collector           | NumberDataPoints #0
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.712313007 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.859758591 +0000 UTC
otel-collector           | Value: 8679
otel-collector           | Metric #5
otel-collector           | Descriptor:
otel-collector           |      -> Name: jvm.memory.committed
otel-collector           |      -> Description: Measure of memory committed.
otel-collector           |      -> Unit: By
otel-collector           |      -> DataType: Sum
otel-collector           |      -> IsMonotonic: false
otel-collector           |      -> AggregationTemporality: Cumulative
otel-collector           | NumberDataPoints #0
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.memory.pool.name: Str(Compressed Class Space)
otel-collector           |      -> jvm.memory.type: Str(non_heap)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.712313007 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.859758591 +0000 UTC
otel-collector           | Value: 5570560
otel-collector           | NumberDataPoints #1
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.memory.pool.name: Str(G1 Old Gen)
otel-collector           |      -> jvm.memory.type: Str(heap)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.712313007 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.859758591 +0000 UTC
otel-collector           | Value: 30408704
otel-collector           | NumberDataPoints #2
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.memory.pool.name: Str(G1 Survivor Space)
otel-collector           |      -> jvm.memory.type: Str(heap)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.712313007 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.859758591 +0000 UTC
otel-collector           | Value: 2097152
otel-collector           | NumberDataPoints #3
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.memory.pool.name: Str(CodeHeap 'non-profiled nmethods')
otel-collector           |      -> jvm.memory.type: Str(non_heap)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.712313007 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.859758591 +0000 UTC
otel-collector           | Value: 4128768
otel-collector           | NumberDataPoints #4
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.memory.pool.name: Str(G1 Eden Space)
otel-collector           |      -> jvm.memory.type: Str(heap)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.712313007 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.859758591 +0000 UTC
otel-collector           | Value: 51380224
otel-collector           | NumberDataPoints #5
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.memory.pool.name: Str(CodeHeap 'non-nmethods')
otel-collector           |      -> jvm.memory.type: Str(non_heap)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.712313007 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.859758591 +0000 UTC
otel-collector           | Value: 2555904
otel-collector           | NumberDataPoints #6
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.memory.pool.name: Str(Metaspace)
otel-collector           |      -> jvm.memory.type: Str(non_heap)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.712313007 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.859758591 +0000 UTC
otel-collector           | Value: 41222144
otel-collector           | NumberDataPoints #7
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.memory.pool.name: Str(CodeHeap 'profiled nmethods')
otel-collector           |      -> jvm.memory.type: Str(non_heap)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.712313007 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.859758591 +0000 UTC
otel-collector           | Value: 12255232
otel-collector           | Metric #6
otel-collector           | Descriptor:
otel-collector           |      -> Name: jvm.thread.count
otel-collector           |      -> Description: Number of executing platform threads.
otel-collector           |      -> Unit: {thread}
otel-collector           |      -> DataType: Sum
otel-collector           |      -> IsMonotonic: false
otel-collector           |      -> AggregationTemporality: Cumulative
otel-collector           | NumberDataPoints #0
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.thread.daemon: Bool(true)
otel-collector           |      -> jvm.thread.state: Str(timed_waiting)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.712313007 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.859758591 +0000 UTC
otel-collector           | Value: 7
otel-collector           | NumberDataPoints #1
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.thread.daemon: Bool(true)
otel-collector           |      -> jvm.thread.state: Str(waiting)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.712313007 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.859758591 +0000 UTC
otel-collector           | Value: 2
otel-collector           | NumberDataPoints #2
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.thread.daemon: Bool(true)
otel-collector           |      -> jvm.thread.state: Str(runnable)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.712313007 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.859758591 +0000 UTC
otel-collector           | Value: 4
otel-collector           | NumberDataPoints #3
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.thread.daemon: Bool(false)
otel-collector           |      -> jvm.thread.state: Str(runnable)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.712313007 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.859758591 +0000 UTC
otel-collector           | Value: 1
otel-collector           | NumberDataPoints #4
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.thread.daemon: Bool(false)
otel-collector           |      -> jvm.thread.state: Str(blocked)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.712313007 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.859758591 +0000 UTC
otel-collector           | Value: 1
otel-collector           | Metric #7
otel-collector           | Descriptor:
otel-collector           |      -> Name: jvm.memory.limit
otel-collector           |      -> Description: Measure of max obtainable memory.
otel-collector           |      -> Unit: By
otel-collector           |      -> DataType: Sum
otel-collector           |      -> IsMonotonic: false
otel-collector           |      -> AggregationTemporality: Cumulative
otel-collector           | NumberDataPoints #0
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.memory.pool.name: Str(Compressed Class Space)
otel-collector           |      -> jvm.memory.type: Str(non_heap)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.712313007 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.859758591 +0000 UTC
otel-collector           | Value: 1073741824
otel-collector           | NumberDataPoints #1
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.memory.pool.name: Str(G1 Old Gen)
otel-collector           |      -> jvm.memory.type: Str(heap)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.712313007 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.859758591 +0000 UTC
otel-collector           | Value: 1027604480
otel-collector           | NumberDataPoints #2
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.memory.pool.name: Str(CodeHeap 'non-profiled nmethods')
otel-collector           |      -> jvm.memory.type: Str(non_heap)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.712313007 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.859758591 +0000 UTC
otel-collector           | Value: 122912768
otel-collector           | NumberDataPoints #3
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.memory.pool.name: Str(CodeHeap 'non-nmethods')
otel-collector           |      -> jvm.memory.type: Str(non_heap)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.712313007 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.859758591 +0000 UTC
otel-collector           | Value: 5836800
otel-collector           | NumberDataPoints #4
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.memory.pool.name: Str(CodeHeap 'profiled nmethods')
otel-collector           |      -> jvm.memory.type: Str(non_heap)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.712313007 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.859758591 +0000 UTC
otel-collector           | Value: 122908672
otel-collector           | Metric #8
otel-collector           | Descriptor:
otel-collector           |      -> Name: jvm.gc.duration
otel-collector           |      -> Description: Duration of JVM garbage collection actions.
otel-collector           |      -> Unit: s
otel-collector           |      -> DataType: Histogram
otel-collector           |      -> AggregationTemporality: Cumulative
otel-collector           | HistogramDataPoints #0
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.gc.action: Str(end of concurrent GC pause)
otel-collector           |      -> jvm.gc.name: Str(G1 Concurrent GC)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.712313007 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.859758591 +0000 UTC
otel-collector           | Count: 2
otel-collector           | Sum: 0.965000
otel-collector           | Min: 0.000000
otel-collector           | Max: 0.965000
otel-collector           | ExplicitBounds #0: 0.010000
otel-collector           | ExplicitBounds #1: 0.100000
otel-collector           | ExplicitBounds #2: 1.000000
otel-collector           | ExplicitBounds #3: 10.000000
otel-collector           | Buckets #0, Count: 1
otel-collector           | Buckets #1, Count: 0
otel-collector           | Buckets #2, Count: 1
otel-collector           | Buckets #3, Count: 0
otel-collector           | Buckets #4, Count: 0
otel-collector           | HistogramDataPoints #1
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.gc.action: Str(end of minor GC)
otel-collector           |      -> jvm.gc.name: Str(G1 Young Generation)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.712313007 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.859758591 +0000 UTC
otel-collector           | Count: 7
otel-collector           | Sum: 1.179000
otel-collector           | Min: 0.119000
otel-collector           | Max: 0.237000
otel-collector           | ExplicitBounds #0: 0.010000
otel-collector           | ExplicitBounds #1: 0.100000
otel-collector           | ExplicitBounds #2: 1.000000
otel-collector           | ExplicitBounds #3: 10.000000
otel-collector           | Buckets #0, Count: 0
otel-collector           | Buckets #1, Count: 0
otel-collector           | Buckets #2, Count: 7
otel-collector           | Buckets #3, Count: 0
otel-collector           | Buckets #4, Count: 0
otel-collector           | Metric #9
otel-collector           | Descriptor:
otel-collector           |      -> Name: jvm.cpu.count
otel-collector           |      -> Description: Number of processors available to the Java virtual machine.
otel-collector           |      -> Unit: {cpu}
otel-collector           |      -> DataType: Sum
otel-collector           |      -> IsMonotonic: false
otel-collector           |      -> AggregationTemporality: Cumulative
otel-collector           | NumberDataPoints #0
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.712313007 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.859758591 +0000 UTC
otel-collector           | Value: 5
otel-collector           | Metric #10
otel-collector           | Descriptor:
otel-collector           |      -> Name: jvm.class.count
otel-collector           |      -> Description: Number of classes currently loaded.
otel-collector           |      -> Unit: {class}
otel-collector           |      -> DataType: Sum
otel-collector           |      -> IsMonotonic: false
otel-collector           |      -> AggregationTemporality: Cumulative
otel-collector           | NumberDataPoints #0
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.712313007 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.859758591 +0000 UTC
otel-collector           | Value: 8678
otel-collector           | Metric #11
otel-collector           | Descriptor:
otel-collector           |      -> Name: jvm.class.unloaded
otel-collector           |      -> Description: Number of classes unloaded since JVM start.
otel-collector           |      -> Unit: {class}
otel-collector           |      -> DataType: Sum
otel-collector           |      -> IsMonotonic: true
otel-collector           |      -> AggregationTemporality: Cumulative
otel-collector           | NumberDataPoints #0
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.712313007 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.859758591 +0000 UTC
otel-collector           | Value: 1
otel-collector           | ResourceMetrics #4
otel-collector           | Resource SchemaURL: https://opentelemetry.io/schemas/1.24.0
otel-collector           | Resource attributes:
otel-collector           |      -> container.id: Str(760f6b53c16009d5e985ba97a71d43520d7cc1bcea8fc6b6984fe64cd8aa49c1)
otel-collector           |      -> host.arch: Str(aarch64)
otel-collector           |      -> host.name: Str(760f6b53c160)
otel-collector           |      -> os.description: Str(Linux 6.10.14-linuxkit)
otel-collector           |      -> os.type: Str(linux)
otel-collector           |      -> process.command_args: Slice(["/opt/java/openjdk/bin/java","-javaagent:/app/opentelemetry-javaagent.jar","-jar","app.jar"])
otel-collector           |      -> process.executable.path: Str(/opt/java/openjdk/bin/java)
otel-collector           |      -> process.pid: Int(1)
otel-collector           |      -> process.runtime.description: Str(Eclipse Adoptium OpenJDK 64-Bit Server VM 21.0.8+9-LTS)
otel-collector           |      -> process.runtime.name: Str(OpenJDK Runtime Environment)
otel-collector           |      -> process.runtime.version: Str(21.0.8+9-LTS)
otel-collector           |      -> service.instance.id: Str(9b417095-e9ef-4f07-abb2-049482ceb128)
otel-collector           |      -> service.name: Str(auth-statistics-service)
otel-collector           |      -> service.version: Str(0.0.1-SNAPSHOT)
otel-collector           |      -> telemetry.distro.name: Str(opentelemetry-java-instrumentation)
otel-collector           |      -> telemetry.distro.version: Str(2.15.0)
otel-collector           |      -> telemetry.sdk.language: Str(java)
otel-collector           |      -> telemetry.sdk.name: Str(opentelemetry)
otel-collector           |      -> telemetry.sdk.version: Str(1.49.0)
otel-collector           | ScopeMetrics #0
otel-collector           | ScopeMetrics SchemaURL: 
otel-collector           | InstrumentationScope io.opentelemetry.sdk.logs 
otel-collector           | Metric #0
otel-collector           | Descriptor:
otel-collector           |      -> Name: processedLogs
otel-collector           |      -> Description: The number of logs processed by the BatchLogRecordProcessor. [dropped=true if they were dropped due to high throughput]
otel-collector           |      -> Unit: 1
otel-collector           |      -> DataType: Sum
otel-collector           |      -> IsMonotonic: true
otel-collector           |      -> AggregationTemporality: Cumulative
otel-collector           | NumberDataPoints #0
otel-collector           | Data point attributes:
otel-collector           |      -> dropped: Bool(false)
otel-collector           |      -> processorType: Str(BatchLogRecordProcessor)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.687641716 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.799650341 +0000 UTC
otel-collector           | Value: 2
otel-collector           | Metric #1
otel-collector           | Descriptor:
otel-collector           |      -> Name: queueSize
otel-collector           |      -> Description: The number of items queued
otel-collector           |      -> Unit: 1
otel-collector           |      -> DataType: Gauge
otel-collector           | NumberDataPoints #0
otel-collector           | Data point attributes:
otel-collector           |      -> processorType: Str(BatchLogRecordProcessor)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.687641716 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.799650341 +0000 UTC
otel-collector           | Value: 0
otel-collector           | ScopeMetrics #1
otel-collector           | ScopeMetrics SchemaURL: 
otel-collector           | InstrumentationScope io.opentelemetry.runtime-telemetry-java8 2.15.0-alpha
otel-collector           | Metric #0
otel-collector           | Descriptor:
otel-collector           |      -> Name: jvm.cpu.recent_utilization
otel-collector           |      -> Description: Recent CPU utilization for the process as reported by the JVM.
otel-collector           |      -> Unit: 1
otel-collector           |      -> DataType: Gauge
otel-collector           | NumberDataPoints #0
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.687641716 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.799650341 +0000 UTC
otel-collector           | Value: 0.000000
otel-collector           | Metric #1
otel-collector           | Descriptor:
otel-collector           |      -> Name: jvm.memory.limit
otel-collector           |      -> Description: Measure of max obtainable memory.
otel-collector           |      -> Unit: By
otel-collector           |      -> DataType: Sum
otel-collector           |      -> IsMonotonic: false
otel-collector           |      -> AggregationTemporality: Cumulative
otel-collector           | NumberDataPoints #0
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.memory.pool.name: Str(Compressed Class Space)
otel-collector           |      -> jvm.memory.type: Str(non_heap)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.687641716 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.799650341 +0000 UTC
otel-collector           | Value: 1073741824
otel-collector           | NumberDataPoints #1
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.memory.pool.name: Str(G1 Old Gen)
otel-collector           |      -> jvm.memory.type: Str(heap)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.687641716 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.799650341 +0000 UTC
otel-collector           | Value: 1027604480
otel-collector           | NumberDataPoints #2
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.memory.pool.name: Str(CodeHeap 'non-profiled nmethods')
otel-collector           |      -> jvm.memory.type: Str(non_heap)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.687641716 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.799650341 +0000 UTC
otel-collector           | Value: 122912768
otel-collector           | NumberDataPoints #3
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.memory.pool.name: Str(CodeHeap 'non-nmethods')
otel-collector           |      -> jvm.memory.type: Str(non_heap)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.687641716 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.799650341 +0000 UTC
otel-collector           | Value: 5836800
otel-collector           | NumberDataPoints #4
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.memory.pool.name: Str(CodeHeap 'profiled nmethods')
otel-collector           |      -> jvm.memory.type: Str(non_heap)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.687641716 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.799650341 +0000 UTC
otel-collector           | Value: 122908672
otel-collector           | Metric #2
otel-collector           | Descriptor:
otel-collector           |      -> Name: jvm.thread.count
otel-collector           |      -> Description: Number of executing platform threads.
otel-collector           |      -> Unit: {thread}
otel-collector           |      -> DataType: Sum
otel-collector           |      -> IsMonotonic: false
otel-collector           |      -> AggregationTemporality: Cumulative
otel-collector           | NumberDataPoints #0
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.thread.daemon: Bool(true)
otel-collector           |      -> jvm.thread.state: Str(timed_waiting)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.687641716 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.799650341 +0000 UTC
otel-collector           | Value: 7
otel-collector           | NumberDataPoints #1
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.thread.daemon: Bool(false)
otel-collector           |      -> jvm.thread.state: Str(runnable)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.687641716 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.799650341 +0000 UTC
otel-collector           | Value: 2
otel-collector           | NumberDataPoints #2
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.thread.daemon: Bool(true)
otel-collector           |      -> jvm.thread.state: Str(runnable)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.687641716 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.799650341 +0000 UTC
otel-collector           | Value: 4
otel-collector           | NumberDataPoints #3
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.thread.daemon: Bool(true)
otel-collector           |      -> jvm.thread.state: Str(waiting)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.687641716 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.799650341 +0000 UTC
otel-collector           | Value: 2
otel-collector           | Metric #3
otel-collector           | Descriptor:
otel-collector           |      -> Name: jvm.class.count
otel-collector           |      -> Description: Number of classes currently loaded.
otel-collector           |      -> Unit: {class}
otel-collector           |      -> DataType: Sum
otel-collector           |      -> IsMonotonic: false
otel-collector           |      -> AggregationTemporality: Cumulative
otel-collector           | NumberDataPoints #0
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.687641716 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.799650341 +0000 UTC
otel-collector           | Value: 9187
otel-collector           | Metric #4
otel-collector           | Descriptor:
otel-collector           |      -> Name: jvm.class.unloaded
otel-collector           |      -> Description: Number of classes unloaded since JVM start.
otel-collector           |      -> Unit: {class}
otel-collector           |      -> DataType: Sum
otel-collector           |      -> IsMonotonic: true
otel-collector           |      -> AggregationTemporality: Cumulative
otel-collector           | NumberDataPoints #0
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.687641716 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.799650341 +0000 UTC
otel-collector           | Value: 1
otel-collector           | Metric #5
otel-collector           | Descriptor:
otel-collector           |      -> Name: jvm.memory.committed
otel-collector           |      -> Description: Measure of memory committed.
otel-collector           |      -> Unit: By
otel-collector           |      -> DataType: Sum
otel-collector           |      -> IsMonotonic: false
otel-collector           |      -> AggregationTemporality: Cumulative
otel-collector           | NumberDataPoints #0
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.memory.pool.name: Str(Compressed Class Space)
otel-collector           |      -> jvm.memory.type: Str(non_heap)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.687641716 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.799650341 +0000 UTC
otel-collector           | Value: 5767168
otel-collector           | NumberDataPoints #1
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.memory.pool.name: Str(G1 Old Gen)
otel-collector           |      -> jvm.memory.type: Str(heap)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.687641716 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.799650341 +0000 UTC
otel-collector           | Value: 41943040
otel-collector           | NumberDataPoints #2
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.memory.pool.name: Str(G1 Survivor Space)
otel-collector           |      -> jvm.memory.type: Str(heap)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.687641716 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.799650341 +0000 UTC
otel-collector           | Value: 2097152
otel-collector           | NumberDataPoints #3
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.memory.pool.name: Str(CodeHeap 'non-profiled nmethods')
otel-collector           |      -> jvm.memory.type: Str(non_heap)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.687641716 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.799650341 +0000 UTC
otel-collector           | Value: 4390912
otel-collector           | NumberDataPoints #4
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.memory.pool.name: Str(G1 Eden Space)
otel-collector           |      -> jvm.memory.type: Str(heap)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.687641716 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.799650341 +0000 UTC
otel-collector           | Value: 50331648
otel-collector           | NumberDataPoints #5
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.memory.pool.name: Str(CodeHeap 'non-nmethods')
otel-collector           |      -> jvm.memory.type: Str(non_heap)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.687641716 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.799650341 +0000 UTC
otel-collector           | Value: 2555904
otel-collector           | NumberDataPoints #6
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.memory.pool.name: Str(Metaspace)
otel-collector           |      -> jvm.memory.type: Str(non_heap)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.687641716 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.799650341 +0000 UTC
otel-collector           | Value: 42598400
otel-collector           | NumberDataPoints #7
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.memory.pool.name: Str(CodeHeap 'profiled nmethods')
otel-collector           |      -> jvm.memory.type: Str(non_heap)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.687641716 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.799650341 +0000 UTC
otel-collector           | Value: 13041664
otel-collector           | Metric #6
otel-collector           | Descriptor:
otel-collector           |      -> Name: jvm.cpu.time
otel-collector           |      -> Description: CPU time used by the process as reported by the JVM.
otel-collector           |      -> Unit: s
otel-collector           |      -> DataType: Sum
otel-collector           |      -> IsMonotonic: true
otel-collector           |      -> AggregationTemporality: Cumulative
otel-collector           | NumberDataPoints #0
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.687641716 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.799650341 +0000 UTC
otel-collector           | Value: 32.070000
otel-collector           | Metric #7
otel-collector           | Descriptor:
otel-collector           |      -> Name: jvm.memory.used_after_last_gc
otel-collector           |      -> Description: Measure of memory used, as measured after the most recent garbage collection event on this pool.
otel-collector           |      -> Unit: By
otel-collector           |      -> DataType: Sum
otel-collector           |      -> IsMonotonic: false
otel-collector           |      -> AggregationTemporality: Cumulative
otel-collector           | NumberDataPoints #0
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.memory.pool.name: Str(G1 Old Gen)
otel-collector           |      -> jvm.memory.type: Str(heap)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.687641716 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.799650341 +0000 UTC
otel-collector           | Value: 24889128
otel-collector           | NumberDataPoints #1
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.memory.pool.name: Str(G1 Survivor Space)
otel-collector           |      -> jvm.memory.type: Str(heap)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.687641716 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.799650341 +0000 UTC
otel-collector           | Value: 2097152
otel-collector           | NumberDataPoints #2
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.memory.pool.name: Str(G1 Eden Space)
otel-collector           |      -> jvm.memory.type: Str(heap)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.687641716 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.799650341 +0000 UTC
otel-collector           | Value: 0
otel-collector           | Metric #8
otel-collector           | Descriptor:
otel-collector           |      -> Name: jvm.memory.used
otel-collector           |      -> Description: Measure of memory used.
otel-collector           |      -> Unit: By
otel-collector           |      -> DataType: Sum
otel-collector           |      -> IsMonotonic: false
otel-collector           |      -> AggregationTemporality: Cumulative
otel-collector           | NumberDataPoints #0
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.memory.pool.name: Str(Compressed Class Space)
otel-collector           |      -> jvm.memory.type: Str(non_heap)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.687641716 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.799650341 +0000 UTC
otel-collector           | Value: 5485880
otel-collector           | NumberDataPoints #1
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.memory.pool.name: Str(G1 Old Gen)
otel-collector           |      -> jvm.memory.type: Str(heap)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.687641716 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.799650341 +0000 UTC
otel-collector           | Value: 24889128
otel-collector           | NumberDataPoints #2
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.memory.pool.name: Str(G1 Survivor Space)
otel-collector           |      -> jvm.memory.type: Str(heap)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.687641716 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.799650341 +0000 UTC
otel-collector           | Value: 2097152
otel-collector           | NumberDataPoints #3
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.memory.pool.name: Str(CodeHeap 'non-profiled nmethods')
otel-collector           |      -> jvm.memory.type: Str(non_heap)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.687641716 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.799650341 +0000 UTC
otel-collector           | Value: 4291584
otel-collector           | NumberDataPoints #4
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.memory.pool.name: Str(G1 Eden Space)
otel-collector           |      -> jvm.memory.type: Str(heap)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.687641716 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.799650341 +0000 UTC
otel-collector           | Value: 15728640
otel-collector           | NumberDataPoints #5
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.memory.pool.name: Str(CodeHeap 'non-nmethods')
otel-collector           |      -> jvm.memory.type: Str(non_heap)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.687641716 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.799650341 +0000 UTC
otel-collector           | Value: 1519616
otel-collector           | NumberDataPoints #6
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.memory.pool.name: Str(Metaspace)
otel-collector           |      -> jvm.memory.type: Str(non_heap)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.687641716 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.799650341 +0000 UTC
otel-collector           | Value: 41922072
otel-collector           | NumberDataPoints #7
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.memory.pool.name: Str(CodeHeap 'profiled nmethods')
otel-collector           |      -> jvm.memory.type: Str(non_heap)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.687641716 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.799650341 +0000 UTC
otel-collector           | Value: 11280640
otel-collector           | Metric #9
otel-collector           | Descriptor:
otel-collector           |      -> Name: jvm.cpu.count
otel-collector           |      -> Description: Number of processors available to the Java virtual machine.
otel-collector           |      -> Unit: {cpu}
otel-collector           |      -> DataType: Sum
otel-collector           |      -> IsMonotonic: false
otel-collector           |      -> AggregationTemporality: Cumulative
otel-collector           | NumberDataPoints #0
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.687641716 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.799650341 +0000 UTC
otel-collector           | Value: 5
otel-collector           | Metric #10
otel-collector           | Descriptor:
otel-collector           |      -> Name: jvm.class.loaded
otel-collector           |      -> Description: Number of classes loaded since JVM start.
otel-collector           |      -> Unit: {class}
otel-collector           |      -> DataType: Sum
otel-collector           |      -> IsMonotonic: true
otel-collector           |      -> AggregationTemporality: Cumulative
otel-collector           | NumberDataPoints #0
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.687641716 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.799650341 +0000 UTC
otel-collector           | Value: 9188
otel-collector           | Metric #11
otel-collector           | Descriptor:
otel-collector           |      -> Name: jvm.gc.duration
otel-collector           |      -> Description: Duration of JVM garbage collection actions.
otel-collector           |      -> Unit: s
otel-collector           |      -> DataType: Histogram
otel-collector           |      -> AggregationTemporality: Cumulative
otel-collector           | HistogramDataPoints #0
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.gc.action: Str(end of concurrent GC pause)
otel-collector           |      -> jvm.gc.name: Str(G1 Concurrent GC)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.687641716 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.799650341 +0000 UTC
otel-collector           | Count: 2
otel-collector           | Sum: 0.232000
otel-collector           | Min: 0.005000
otel-collector           | Max: 0.227000
otel-collector           | ExplicitBounds #0: 0.010000
otel-collector           | ExplicitBounds #1: 0.100000
otel-collector           | ExplicitBounds #2: 1.000000
otel-collector           | ExplicitBounds #3: 10.000000
otel-collector           | Buckets #0, Count: 1
otel-collector           | Buckets #1, Count: 0
otel-collector           | Buckets #2, Count: 1
otel-collector           | Buckets #3, Count: 0
otel-collector           | Buckets #4, Count: 0
otel-collector           | HistogramDataPoints #1
otel-collector           | Data point attributes:
otel-collector           |      -> jvm.gc.action: Str(end of minor GC)
otel-collector           |      -> jvm.gc.name: Str(G1 Young Generation)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.687641716 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.799650341 +0000 UTC
otel-collector           | Count: 12
otel-collector           | Sum: 2.017000
otel-collector           | Min: 0.070000
otel-collector           | Max: 0.393000
otel-collector           | ExplicitBounds #0: 0.010000
otel-collector           | ExplicitBounds #1: 0.100000
otel-collector           | ExplicitBounds #2: 1.000000
otel-collector           | ExplicitBounds #3: 10.000000
otel-collector           | Buckets #0, Count: 0
otel-collector           | Buckets #1, Count: 2
otel-collector           | Buckets #2, Count: 10
otel-collector           | Buckets #3, Count: 0
otel-collector           | Buckets #4, Count: 0
otel-collector           | ScopeMetrics #2
otel-collector           | ScopeMetrics SchemaURL: 
otel-collector           | InstrumentationScope io.opentelemetry.sdk.trace 
otel-collector           | Metric #0
otel-collector           | Descriptor:
otel-collector           |      -> Name: queueSize
otel-collector           |      -> Description: The number of items queued
otel-collector           |      -> Unit: 1
otel-collector           |      -> DataType: Gauge
otel-collector           | NumberDataPoints #0
otel-collector           | Data point attributes:
otel-collector           |      -> processorType: Str(BatchSpanProcessor)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.687641716 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.799650341 +0000 UTC
otel-collector           | Value: 0
otel-collector           | ScopeMetrics #3
otel-collector           | ScopeMetrics SchemaURL: 
otel-collector           | InstrumentationScope io.opentelemetry.exporters.otlp-http 
otel-collector           | Metric #0
otel-collector           | Descriptor:
otel-collector           |      -> Name: otlp.exporter.seen
otel-collector           |      -> Description: 
otel-collector           |      -> Unit: 
otel-collector           |      -> DataType: Sum
otel-collector           |      -> IsMonotonic: true
otel-collector           |      -> AggregationTemporality: Cumulative
otel-collector           | NumberDataPoints #0
otel-collector           | Data point attributes:
otel-collector           |      -> type: Str(log)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.687641716 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.799650341 +0000 UTC
otel-collector           | Value: 2
otel-collector           | Metric #1
otel-collector           | Descriptor:
otel-collector           |      -> Name: otlp.exporter.exported
otel-collector           |      -> Description: 
otel-collector           |      -> Unit: 
otel-collector           |      -> DataType: Sum
otel-collector           |      -> IsMonotonic: true
otel-collector           |      -> AggregationTemporality: Cumulative
otel-collector           | NumberDataPoints #0
otel-collector           | Data point attributes:
otel-collector           |      -> success: Bool(true)
otel-collector           |      -> type: Str(log)
otel-collector           | StartTimestamp: 2025-10-03 16:11:29.687641716 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:29.799650341 +0000 UTC
otel-collector           | Value: 2
otel-collector           | 	{"resource": {"service.instance.id": "4aa48a6d-7678-4f39-b57a-6fa72002086e", "service.name": "otelcol", "service.version": "0.132.0"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "metrics"}
otel-collector           | 2025-10-03T16:12:32.434Z	info	Logs	{"resource": {"service.instance.id": "4aa48a6d-7678-4f39-b57a-6fa72002086e", "service.name": "otelcol", "service.version": "0.132.0"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "logs", "resource logs": 2, "log records": 2}
otel-collector           | 2025-10-03T16:12:32.436Z	info	ResourceLog #0
otel-collector           | Resource SchemaURL: https://opentelemetry.io/schemas/1.24.0
otel-collector           | Resource attributes:
otel-collector           |      -> container.id: Str(0666752b63c6f038ff3642eed2328cd1eb0fa66e27a671fa04a261189ed4d98f)
otel-collector           |      -> host.arch: Str(aarch64)
otel-collector           |      -> host.name: Str(0666752b63c6)
otel-collector           |      -> os.description: Str(Linux 6.10.14-linuxkit)
otel-collector           |      -> os.type: Str(linux)
otel-collector           |      -> process.command_args: Slice(["/opt/java/openjdk/bin/java","-javaagent:/app/opentelemetry-javaagent.jar","-jar","app.jar"])
otel-collector           |      -> process.executable.path: Str(/opt/java/openjdk/bin/java)
otel-collector           |      -> process.pid: Int(1)
otel-collector           |      -> process.runtime.description: Str(Eclipse Adoptium OpenJDK 64-Bit Server VM 21.0.8+9-LTS)
otel-collector           |      -> process.runtime.name: Str(OpenJDK Runtime Environment)
otel-collector           |      -> process.runtime.version: Str(21.0.8+9-LTS)
otel-collector           |      -> service.instance.id: Str(1ce10a93-a081-4fdc-8739-d45c4e1db2ea)
otel-collector           |      -> service.name: Str(security-service)
otel-collector           |      -> service.version: Str(0.0.1-SNAPSHOT)
otel-collector           |      -> telemetry.distro.name: Str(opentelemetry-java-instrumentation)
otel-collector           |      -> telemetry.distro.version: Str(2.15.0)
otel-collector           |      -> telemetry.sdk.language: Str(java)
otel-collector           |      -> telemetry.sdk.name: Str(opentelemetry)
otel-collector           |      -> telemetry.sdk.version: Str(1.49.0)
otel-collector           | ScopeLogs #0
otel-collector           | ScopeLogs SchemaURL: 
otel-collector           | InstrumentationScope ru.katacademy.securityservice.SecurityServiceApplication 
otel-collector           | LogRecord #0
otel-collector           | ObservedTimestamp: 2025-10-03 16:12:24.132492921 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:23.784917046 +0000 UTC
otel-collector           | SeverityText: INFO
otel-collector           | SeverityNumber: Info(9)
otel-collector           | Body: Str(Starting SecurityServiceApplication v0.0.1-SNAPSHOT using Java 21.0.8 with PID 1 (/app/app.jar started by root in /app))
otel-collector           | Trace ID: 
otel-collector           | Span ID: 
otel-collector           | Flags: 0
otel-collector           | ResourceLog #1
otel-collector           | Resource SchemaURL: https://opentelemetry.io/schemas/1.24.0
otel-collector           | Resource attributes:
otel-collector           |      -> container.id: Str(0666752b63c6f038ff3642eed2328cd1eb0fa66e27a671fa04a261189ed4d98f)
otel-collector           |      -> host.arch: Str(aarch64)
otel-collector           |      -> host.name: Str(0666752b63c6)
otel-collector           |      -> os.description: Str(Linux 6.10.14-linuxkit)
otel-collector           |      -> os.type: Str(linux)
otel-collector           |      -> process.command_args: Slice(["/opt/java/openjdk/bin/java","-javaagent:/app/opentelemetry-javaagent.jar","-jar","app.jar"])
otel-collector           |      -> process.executable.path: Str(/opt/java/openjdk/bin/java)
otel-collector           |      -> process.pid: Int(1)
otel-collector           |      -> process.runtime.description: Str(Eclipse Adoptium OpenJDK 64-Bit Server VM 21.0.8+9-LTS)
otel-collector           |      -> process.runtime.name: Str(OpenJDK Runtime Environment)
otel-collector           |      -> process.runtime.version: Str(21.0.8+9-LTS)
otel-collector           |      -> service.instance.id: Str(1ce10a93-a081-4fdc-8739-d45c4e1db2ea)
otel-collector           |      -> service.name: Str(security-service)
otel-collector           |      -> service.version: Str(0.0.1-SNAPSHOT)
otel-collector           |      -> telemetry.distro.name: Str(opentelemetry-java-instrumentation)
otel-collector           |      -> telemetry.distro.version: Str(2.15.0)
otel-collector           |      -> telemetry.sdk.language: Str(java)
otel-collector           |      -> telemetry.sdk.name: Str(opentelemetry)
otel-collector           |      -> telemetry.sdk.version: Str(1.49.0)
otel-collector           | ScopeLogs #0
otel-collector           | ScopeLogs SchemaURL: 
otel-collector           | InstrumentationScope ru.katacademy.securityservice.SecurityServiceApplication 
otel-collector           | LogRecord #0
otel-collector           | ObservedTimestamp: 2025-10-03 16:12:24.670017588 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:24.669505338 +0000 UTC
otel-collector           | SeverityText: INFO
otel-collector           | SeverityNumber: Info(9)
otel-collector           | Body: Str(No active profile set, falling back to 1 default profile: "default")
otel-collector           | Trace ID: 
otel-collector           | Span ID: 
otel-collector           | Flags: 0
otel-collector           | 	{"resource": {"service.instance.id": "4aa48a6d-7678-4f39-b57a-6fa72002086e", "service.name": "otelcol", "service.version": "0.132.0"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "logs"}
notification-service     | 2025-10-03T16:12:36.173Z  INFO 1 --- [bank-shared] [           main] o.s.o.j.p.SpringPersistenceUnitInfo      : No LoadTimeWeaver setup: ignoring JPA class transformer
api-gateway-1            | 2025-10-03T16:12:36.346Z  INFO 1 --- [api-gateway] [           main] o.s.b.a.e.web.EndpointLinksResolver      : Exposing 1 endpoint beneath base path '/actuator'
fraud-detection          | 2025-10-03T16:12:36.432Z  INFO 1 --- [fraud-detection] [           main] o.s.o.j.p.SpringPersistenceUnitInfo      : No LoadTimeWeaver setup: ignoring JPA class transformer
notification-service     | 2025-10-03T16:12:37.176Z  INFO 1 --- [bank-shared] [           main] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Starting...
fraud-detection          | 2025-10-03T16:12:37.805Z  INFO 1 --- [fraud-detection] [           main] org.hibernate.orm.connections.pooling    : HHH10001005: Database info:
fraud-detection          | 	Database JDBC URL [Connecting through datasource 'HikariDataSource (HikariPool-1)']
fraud-detection          | 	Database driver: undefined/unknown
fraud-detection          | 	Database version: 15.14
fraud-detection          | 	Autocommit mode: undefined/unknown
fraud-detection          | 	Isolation level: undefined/unknown
fraud-detection          | 	Minimum pool size: undefined/unknown
fraud-detection          | 	Maximum pool size: undefined/unknown
settings-service         | 2025-10-03T16:12:38.146Z  INFO 1 --- [bank-shared] [           main] o.h.e.t.j.p.i.JtaPlatformInitiator       : HHH000489: No JTA platform available (set 'hibernate.transaction.jta.platform' to enable JTA platform integration)
settings-service         | 2025-10-03T16:12:39.574Z  INFO 1 --- [bank-shared] [           main] j.LocalContainerEntityManagerFactoryBean : Initialized JPA EntityManagerFactory for persistence unit 'default'
notification-service     | 2025-10-03T16:12:39.632Z  INFO 1 --- [bank-shared] [           main] com.zaxxer.hikari.pool.HikariPool        : HikariPool-1 - Added connection org.postgresql.jdbc.PgConnection@3ba5c4dd
notification-service     | 2025-10-03T16:12:39.667Z  INFO 1 --- [bank-shared] [           main] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Start completed.
notification-service     | 2025-10-03T16:12:40.326Z  WARN 1 --- [bank-shared] [           main] org.hibernate.orm.deprecation            : HHH90000025: PostgreSQLDialect does not need to be specified explicitly using 'hibernate.dialect' (remove the property setting and it will be selected by default)
notification-service     | 2025-10-03T16:12:40.600Z  INFO 1 --- [bank-shared] [           main] org.hibernate.orm.connections.pooling    : HHH10001005: Database info:
notification-service     | 	Database JDBC URL [Connecting through datasource 'HikariDataSource (HikariPool-1)']
notification-service     | 	Database driver: undefined/unknown
notification-service     | 	Database version: 15.14
notification-service     | 	Autocommit mode: undefined/unknown
notification-service     | 	Isolation level: undefined/unknown
notification-service     | 	Minimum pool size: undefined/unknown
notification-service     | 	Maximum pool size: undefined/unknown
fraud-detection          | 2025-10-03T16:12:42.786Z  INFO 1 --- [fraud-detection] [           main] o.h.e.t.j.p.i.JtaPlatformInitiator       : HHH000489: No JTA platform available (set 'hibernate.transaction.jta.platform' to enable JTA platform integration)
fraud-detection          | 2025-10-03T16:12:42.889Z  INFO 1 --- [fraud-detection] [           main] j.LocalContainerEntityManagerFactoryBean : Initialized JPA EntityManagerFactory for persistence unit 'default'
fraud-detection          | 2025-10-03T16:12:47.949Z  WARN 1 --- [fraud-detection] [           main] JpaBaseConfiguration$JpaWebConfiguration : spring.jpa.open-in-view is enabled by default. Therefore, database queries may be performed during view rendering. Explicitly configure spring.jpa.open-in-view to disable this warning
api-gateway-1            | 2025-10-03T16:12:48.185Z  INFO 1 --- [api-gateway] [           main] o.s.b.web.embedded.netty.NettyWebServer  : Netty started on port 8765 (http)
api-gateway-1            | 2025-10-03T16:12:49.327Z DEBUG 1 --- [api-gateway] [           main] o.s.c.g.r.RouteDefinitionRouteLocator    : RouteDefinition account-service applying {_genkey_0=/api/accounts/**} to Path
api-gateway-1            | 2025-10-03T16:12:49.749Z DEBUG 1 --- [api-gateway] [           main] o.s.c.g.r.RouteDefinitionRouteLocator    : RouteDefinition matched: account-service
api-gateway-1            | 2025-10-03T16:12:49.780Z DEBUG 1 --- [api-gateway] [           main] o.s.c.g.r.RouteDefinitionRouteLocator    : RouteDefinition security-service applying {_genkey_0=/api/security/**} to Path
api-gateway-1            | 2025-10-03T16:12:49.824Z DEBUG 1 --- [api-gateway] [           main] o.s.c.g.r.RouteDefinitionRouteLocator    : RouteDefinition matched: security-service
api-gateway-1            | 2025-10-03T16:12:50.009Z DEBUG 1 --- [api-gateway] [           main] o.s.c.g.filter.GatewayMetricsFilter      : New routes count: 2
api-gateway-1            | 2025-10-03T16:12:50.082Z  INFO 1 --- [api-gateway] [           main] r.k.apigateway.ApiGatewayApplication     : Started ApiGatewayApplication in 80.187 seconds (process running for 93.034)
api-gateway-1            | 2025-10-03T16:12:50.379Z  WARN 1 --- [api-gateway] [           main] ServerWebfluxPropertiesMigrationListener : 
api-gateway-1            | The use of configuration keys that have been renamed was found in the environment:
api-gateway-1            | 
api-gateway-1            | Property source 'Config resource 'class path resource [application.yml]' via location 'optional:classpath:/'':
api-gateway-1            | 	Key: spring.cloud.gateway.routes[0].id
api-gateway-1            | 		Line: 11
api-gateway-1            | 		Replacement: spring.cloud.gateway.server.webflux.routes[0].id
api-gateway-1            | 	Key: spring.cloud.gateway.routes[0].uri
api-gateway-1            | 		Line: 12
api-gateway-1            | 		Replacement: spring.cloud.gateway.server.webflux.routes[0].uri
api-gateway-1            | 	Key: spring.cloud.gateway.routes[0].predicates[0]
api-gateway-1            | 		Line: 14
api-gateway-1            | 		Replacement: spring.cloud.gateway.server.webflux.routes[0].predicates[0]
api-gateway-1            | 	Key: spring.cloud.gateway.routes[1].id
api-gateway-1            | 		Line: 15
api-gateway-1            | 		Replacement: spring.cloud.gateway.server.webflux.routes[1].id
api-gateway-1            | 	Key: spring.cloud.gateway.routes[1].uri
api-gateway-1            | 		Line: 16
api-gateway-1            | 		Replacement: spring.cloud.gateway.server.webflux.routes[1].uri
api-gateway-1            | 	Key: spring.cloud.gateway.routes[1].predicates[0]
api-gateway-1            | 		Line: 18
api-gateway-1            | 		Replacement: spring.cloud.gateway.server.webflux.routes[1].predicates[0]
api-gateway-1            | 
api-gateway-1            | 
api-gateway-1            | Each configuration key has been temporarily mapped to its replacement for your convenience. To silence this warning, please update your configuration to use the new keys.
api-gateway-1            | 
fraud-detection          | 2025-10-03T16:12:50.602Z  INFO 1 --- [fraud-detection] [           main] o.s.v.b.OptionalValidatorFactoryBean     : Failed to set up a Bean Validation provider: jakarta.validation.NoProviderFoundException: Unable to create a Configuration, because no Jakarta Bean Validation provider could be found. Add a provider like Hibernate Validator (RI) to your classpath.
bankapp                  | 2025-10-03T16:12:51.072Z  INFO 1 --- [bank-shared] [           main] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data JPA repositories in DEFAULT mode.
bankapp                  | 2025-10-03T16:12:51.666Z  INFO 1 --- [bank-shared] [           main] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 315 ms. Found 0 JPA repository interfaces.
otel-collector           | 2025-10-03T16:12:52.445Z	info	Logs	{"resource": {"service.instance.id": "4aa48a6d-7678-4f39-b57a-6fa72002086e", "service.name": "otelcol", "service.version": "0.132.0"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "logs", "resource logs": 1, "log records": 2}
otel-collector           | 2025-10-03T16:12:52.465Z	info	ResourceLog #0
otel-collector           | Resource SchemaURL: https://opentelemetry.io/schemas/1.24.0
otel-collector           | Resource attributes:
otel-collector           |      -> container.id: Str(39f4ff18951127ac8c0450512e9a37033fa15478db84c119a8e4f633002d31ea)
otel-collector           |      -> host.arch: Str(aarch64)
otel-collector           |      -> host.name: Str(39f4ff189511)
otel-collector           |      -> os.description: Str(Linux 6.10.14-linuxkit)
otel-collector           |      -> os.type: Str(linux)
otel-collector           |      -> process.command_args: Slice(["/opt/java/openjdk/bin/java","-javaagent:/app/opentelemetry-javaagent.jar","-jar","app.jar"])
otel-collector           |      -> process.executable.path: Str(/opt/java/openjdk/bin/java)
otel-collector           |      -> process.pid: Int(1)
otel-collector           |      -> process.runtime.description: Str(Eclipse Adoptium OpenJDK 64-Bit Server VM 21.0.8+9-LTS)
otel-collector           |      -> process.runtime.name: Str(OpenJDK Runtime Environment)
otel-collector           |      -> process.runtime.version: Str(21.0.8+9-LTS)
otel-collector           |      -> service.instance.id: Str(319f836a-b6f8-4ce0-a5f5-6f27a85ee280)
otel-collector           |      -> service.name: Str(bankapp)
otel-collector           |      -> service.version: Str(0.0.1-SNAPSHOT)
otel-collector           |      -> telemetry.distro.name: Str(opentelemetry-java-instrumentation)
otel-collector           |      -> telemetry.distro.version: Str(2.15.0)
otel-collector           |      -> telemetry.sdk.language: Str(java)
otel-collector           |      -> telemetry.sdk.name: Str(opentelemetry)
otel-collector           |      -> telemetry.sdk.version: Str(1.49.0)
otel-collector           | ScopeLogs #0
otel-collector           | ScopeLogs SchemaURL: 
otel-collector           | InstrumentationScope org.springframework.data.repository.config.RepositoryConfigurationDelegate 
otel-collector           | LogRecord #0
otel-collector           | ObservedTimestamp: 2025-10-03 16:12:51.083614878 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:51.072265253 +0000 UTC
otel-collector           | SeverityText: INFO
otel-collector           | SeverityNumber: Info(9)
otel-collector           | Body: Str(Bootstrapping Spring Data JPA repositories in DEFAULT mode.)
otel-collector           | Trace ID: 
otel-collector           | Span ID: 
otel-collector           | Flags: 0
otel-collector           | LogRecord #1
otel-collector           | ObservedTimestamp: 2025-10-03 16:12:51.674899128 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:51.666344878 +0000 UTC
otel-collector           | SeverityText: INFO
otel-collector           | SeverityNumber: Info(9)
otel-collector           | Body: Str(Finished Spring Data repository scanning in 315 ms. Found 0 JPA repository interfaces.)
otel-collector           | Trace ID: 
otel-collector           | Span ID: 
otel-collector           | Flags: 0
otel-collector           | 	{"resource": {"service.instance.id": "4aa48a6d-7678-4f39-b57a-6fa72002086e", "service.name": "otelcol", "service.version": "0.132.0"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "logs"}
settings-service         | 2025-10-03T16:12:52.585Z  WARN 1 --- [bank-shared] [           main] JpaBaseConfiguration$JpaWebConfiguration : spring.jpa.open-in-view is enabled by default. Therefore, database queries may be performed during view rendering. Explicitly configure spring.jpa.open-in-view to disable this warning
kyc-service              | 2025-10-03T16:12:53.516Z  INFO 1 --- [bank-shared] [           main] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data JPA repositories in DEFAULT mode.
settings-service         | 2025-10-03T16:12:53.741Z  INFO 1 --- [bank-shared] [           main] o.s.v.b.OptionalValidatorFactoryBean     : Failed to set up a Bean Validation provider: jakarta.validation.NoProviderFoundException: Unable to create a Configuration, because no Jakarta Bean Validation provider could be found. Add a provider like Hibernate Validator (RI) to your classpath.
notification-service     | 2025-10-03T16:12:54.775Z  INFO 1 --- [bank-shared] [           main] o.h.e.t.j.p.i.JtaPlatformInitiator       : HHH000489: No JTA platform available (set 'hibernate.transaction.jta.platform' to enable JTA platform integration)
kyc-service              | 2025-10-03T16:12:55.780Z  INFO 1 --- [bank-shared] [           main] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 1953 ms. Found 3 JPA repository interfaces.
notification-service     | 2025-10-03T16:12:56.165Z  INFO 1 --- [bank-shared] [           main] j.LocalContainerEntityManagerFactoryBean : Initialized JPA EntityManagerFactory for persistence unit 'default'
otel-collector           | 2025-10-03T16:12:57.468Z	info	Logs	{"resource": {"service.instance.id": "4aa48a6d-7678-4f39-b57a-6fa72002086e", "service.name": "otelcol", "service.version": "0.132.0"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "logs", "resource logs": 2, "log records": 2}
otel-collector           | 2025-10-03T16:12:57.483Z	info	ResourceLog #0
otel-collector           | Resource SchemaURL: https://opentelemetry.io/schemas/1.24.0
otel-collector           | Resource attributes:
otel-collector           |      -> container.id: Str(b7462027190fc5ca17c8fad62a6a7c6d248c5b38516fe3b1dfd9b3b6cf8f715b)
otel-collector           |      -> host.arch: Str(aarch64)
otel-collector           |      -> host.name: Str(b7462027190f)
otel-collector           |      -> os.description: Str(Linux 6.10.14-linuxkit)
otel-collector           |      -> os.type: Str(linux)
otel-collector           |      -> process.command_args: Slice(["/opt/java/openjdk/bin/java","-javaagent:/app/opentelemetry-javaagent.jar","-jar","app.jar"])
otel-collector           |      -> process.executable.path: Str(/opt/java/openjdk/bin/java)
otel-collector           |      -> process.pid: Int(1)
otel-collector           |      -> process.runtime.description: Str(Eclipse Adoptium OpenJDK 64-Bit Server VM 21.0.8+9-LTS)
otel-collector           |      -> process.runtime.name: Str(OpenJDK Runtime Environment)
otel-collector           |      -> process.runtime.version: Str(21.0.8+9-LTS)
otel-collector           |      -> service.instance.id: Str(88ceffbe-6ccf-45bf-b476-a5c5db2fc9f5)
otel-collector           |      -> service.name: Str(kyc-service)
otel-collector           |      -> service.version: Str(0.0.1-SNAPSHOT)
otel-collector           |      -> telemetry.distro.name: Str(opentelemetry-java-instrumentation)
otel-collector           |      -> telemetry.distro.version: Str(2.15.0)
otel-collector           |      -> telemetry.sdk.language: Str(java)
otel-collector           |      -> telemetry.sdk.name: Str(opentelemetry)
otel-collector           |      -> telemetry.sdk.version: Str(1.49.0)
otel-collector           | ScopeLogs #0
otel-collector           | ScopeLogs SchemaURL: 
otel-collector           | InstrumentationScope org.springframework.data.repository.config.RepositoryConfigurationDelegate 
otel-collector           | LogRecord #0
otel-collector           | ObservedTimestamp: 2025-10-03 16:12:53.522616254 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:53.516536921 +0000 UTC
otel-collector           | SeverityText: INFO
otel-collector           | SeverityNumber: Info(9)
otel-collector           | Body: Str(Bootstrapping Spring Data JPA repositories in DEFAULT mode.)
otel-collector           | Trace ID: 
otel-collector           | Span ID: 
otel-collector           | Flags: 0
otel-collector           | ResourceLog #1
otel-collector           | Resource SchemaURL: https://opentelemetry.io/schemas/1.24.0
otel-collector           | Resource attributes:
otel-collector           |      -> container.id: Str(b7462027190fc5ca17c8fad62a6a7c6d248c5b38516fe3b1dfd9b3b6cf8f715b)
otel-collector           |      -> host.arch: Str(aarch64)
otel-collector           |      -> host.name: Str(b7462027190f)
otel-collector           |      -> os.description: Str(Linux 6.10.14-linuxkit)
otel-collector           |      -> os.type: Str(linux)
otel-collector           |      -> process.command_args: Slice(["/opt/java/openjdk/bin/java","-javaagent:/app/opentelemetry-javaagent.jar","-jar","app.jar"])
otel-collector           |      -> process.executable.path: Str(/opt/java/openjdk/bin/java)
otel-collector           |      -> process.pid: Int(1)
otel-collector           |      -> process.runtime.description: Str(Eclipse Adoptium OpenJDK 64-Bit Server VM 21.0.8+9-LTS)
otel-collector           |      -> process.runtime.name: Str(OpenJDK Runtime Environment)
otel-collector           |      -> process.runtime.version: Str(21.0.8+9-LTS)
otel-collector           |      -> service.instance.id: Str(88ceffbe-6ccf-45bf-b476-a5c5db2fc9f5)
otel-collector           |      -> service.name: Str(kyc-service)
otel-collector           |      -> service.version: Str(0.0.1-SNAPSHOT)
otel-collector           |      -> telemetry.distro.name: Str(opentelemetry-java-instrumentation)
otel-collector           |      -> telemetry.distro.version: Str(2.15.0)
otel-collector           |      -> telemetry.sdk.language: Str(java)
otel-collector           |      -> telemetry.sdk.name: Str(opentelemetry)
otel-collector           |      -> telemetry.sdk.version: Str(1.49.0)
otel-collector           | ScopeLogs #0
otel-collector           | ScopeLogs SchemaURL: 
otel-collector           | InstrumentationScope org.springframework.data.repository.config.RepositoryConfigurationDelegate 
otel-collector           | LogRecord #0
otel-collector           | ObservedTimestamp: 2025-10-03 16:12:55.786497297 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:55.780313089 +0000 UTC
otel-collector           | SeverityText: INFO
otel-collector           | SeverityNumber: Info(9)
otel-collector           | Body: Str(Finished Spring Data repository scanning in 1953 ms. Found 3 JPA repository interfaces.)
otel-collector           | Trace ID: 
otel-collector           | Span ID: 
otel-collector           | Flags: 0
otel-collector           | 	{"resource": {"service.instance.id": "4aa48a6d-7678-4f39-b57a-6fa72002086e", "service.name": "otelcol", "service.version": "0.132.0"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "logs"}
account-service          | 2025-10-03T16:12:57.799Z  INFO 1 --- [bank-shared] [           main] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data JPA repositories in DEFAULT mode.
account-service          | 2025-10-03T16:12:58.307Z  INFO 1 --- [bank-shared] [           main] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 99 ms. Found 0 JPA repository interfaces.
account-service          | 2025-10-03T16:12:58.387Z  INFO 1 --- [bank-shared] [           main] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data JPA repositories in DEFAULT mode.
account-service          | 2025-10-03T16:12:58.736Z  INFO 1 --- [bank-shared] [           main] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 329 ms. Found 2 JPA repository interfaces.
security-service         | 2025-10-03T16:13:01.767Z  INFO 1 --- [bank-shared] [           main] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data JPA repositories in DEFAULT mode.
otel-collector           | 2025-10-03T16:13:02.488Z	info	Logs	{"resource": {"service.instance.id": "4aa48a6d-7678-4f39-b57a-6fa72002086e", "service.name": "otelcol", "service.version": "0.132.0"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "logs", "resource logs": 2, "log records": 4}
otel-collector           | 2025-10-03T16:13:02.530Z	info	ResourceLog #0
otel-collector           | Resource SchemaURL: https://opentelemetry.io/schemas/1.24.0
otel-collector           | Resource attributes:
otel-collector           |      -> container.id: Str(85a453b0cb0d19978dc616b0d20a22506c238700e8b6c4ace228f9c7bf06f34d)
otel-collector           |      -> host.arch: Str(aarch64)
otel-collector           |      -> host.name: Str(85a453b0cb0d)
otel-collector           |      -> os.description: Str(Linux 6.10.14-linuxkit)
otel-collector           |      -> os.type: Str(linux)
otel-collector           |      -> process.command_args: Slice(["/opt/java/openjdk/bin/java","-javaagent:/app/opentelemetry-javaagent.jar","-jar","app.jar"])
otel-collector           |      -> process.executable.path: Str(/opt/java/openjdk/bin/java)
otel-collector           |      -> process.pid: Int(1)
otel-collector           |      -> process.runtime.description: Str(Eclipse Adoptium OpenJDK 64-Bit Server VM 21.0.8+9-LTS)
otel-collector           |      -> process.runtime.name: Str(OpenJDK Runtime Environment)
otel-collector           |      -> process.runtime.version: Str(21.0.8+9-LTS)
otel-collector           |      -> service.instance.id: Str(dd672c4c-c3b6-49aa-acbe-5f1b73f92d54)
otel-collector           |      -> service.name: Str(user-service)
otel-collector           |      -> service.version: Str(0.0.1-SNAPSHOT)
otel-collector           |      -> telemetry.distro.name: Str(opentelemetry-java-instrumentation)
otel-collector           |      -> telemetry.distro.version: Str(2.15.0)
otel-collector           |      -> telemetry.sdk.language: Str(java)
otel-collector           |      -> telemetry.sdk.name: Str(opentelemetry)
otel-collector           |      -> telemetry.sdk.version: Str(1.49.0)
otel-collector           | ScopeLogs #0
otel-collector           | ScopeLogs SchemaURL: 
otel-collector           | InstrumentationScope org.springframework.data.repository.config.RepositoryConfigurationDelegate 
otel-collector           | LogRecord #0
otel-collector           | ObservedTimestamp: 2025-10-03 16:12:57.801007798 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:57.799543923 +0000 UTC
otel-collector           | SeverityText: INFO
otel-collector           | SeverityNumber: Info(9)
otel-collector           | Body: Str(Bootstrapping Spring Data JPA repositories in DEFAULT mode.)
otel-collector           | Trace ID: 
otel-collector           | Span ID: 
otel-collector           | Flags: 0
otel-collector           | ResourceLog #1
otel-collector           | Resource SchemaURL: https://opentelemetry.io/schemas/1.24.0
otel-collector           | Resource attributes:
otel-collector           |      -> container.id: Str(85a453b0cb0d19978dc616b0d20a22506c238700e8b6c4ace228f9c7bf06f34d)
otel-collector           |      -> host.arch: Str(aarch64)
otel-collector           |      -> host.name: Str(85a453b0cb0d)
otel-collector           |      -> os.description: Str(Linux 6.10.14-linuxkit)
otel-collector           |      -> os.type: Str(linux)
otel-collector           |      -> process.command_args: Slice(["/opt/java/openjdk/bin/java","-javaagent:/app/opentelemetry-javaagent.jar","-jar","app.jar"])
otel-collector           |      -> process.executable.path: Str(/opt/java/openjdk/bin/java)
otel-collector           |      -> process.pid: Int(1)
otel-collector           |      -> process.runtime.description: Str(Eclipse Adoptium OpenJDK 64-Bit Server VM 21.0.8+9-LTS)
otel-collector           |      -> process.runtime.name: Str(OpenJDK Runtime Environment)
otel-collector           |      -> process.runtime.version: Str(21.0.8+9-LTS)
otel-collector           |      -> service.instance.id: Str(dd672c4c-c3b6-49aa-acbe-5f1b73f92d54)
otel-collector           |      -> service.name: Str(user-service)
otel-collector           |      -> service.version: Str(0.0.1-SNAPSHOT)
otel-collector           |      -> telemetry.distro.name: Str(opentelemetry-java-instrumentation)
otel-collector           |      -> telemetry.distro.version: Str(2.15.0)
otel-collector           |      -> telemetry.sdk.language: Str(java)
otel-collector           |      -> telemetry.sdk.name: Str(opentelemetry)
otel-collector           |      -> telemetry.sdk.version: Str(1.49.0)
otel-collector           | ScopeLogs #0
otel-collector           | ScopeLogs SchemaURL: 
otel-collector           | InstrumentationScope org.springframework.data.repository.config.RepositoryConfigurationDelegate 
otel-collector           | LogRecord #0
otel-collector           | ObservedTimestamp: 2025-10-03 16:12:58.309166673 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:58.307959382 +0000 UTC
otel-collector           | SeverityText: INFO
otel-collector           | SeverityNumber: Info(9)
otel-collector           | Body: Str(Finished Spring Data repository scanning in 99 ms. Found 0 JPA repository interfaces.)
otel-collector           | Trace ID: 
otel-collector           | Span ID: 
otel-collector           | Flags: 0
otel-collector           | LogRecord #1
otel-collector           | ObservedTimestamp: 2025-10-03 16:12:58.387672007 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:58.387289423 +0000 UTC
otel-collector           | SeverityText: INFO
otel-collector           | SeverityNumber: Info(9)
otel-collector           | Body: Str(Bootstrapping Spring Data JPA repositories in DEFAULT mode.)
otel-collector           | Trace ID: 
otel-collector           | Span ID: 
otel-collector           | Flags: 0
otel-collector           | LogRecord #2
otel-collector           | ObservedTimestamp: 2025-10-03 16:12:58.736440715 +0000 UTC
otel-collector           | Timestamp: 2025-10-03 16:12:58.736226173 +0000 UTC
otel-collector           | SeverityText: INFO
otel-collector           | SeverityNumber: Info(9)
otel-collector           | Body: Str(Finished Spring Data repository scanning in 329 ms. Found 2 JPA repository interfaces.)
otel-collector           | Trace ID: 
otel-collector           | Span ID: 
otel-collector           | Flags: 0
otel-collector           | 	{"resource": {"service.instance.id": "4aa48a6d-7678-4f39-b57a-6fa72002086e", "service.name": "otelcol", "service.version": "0.132.0"}, "otelcol.component.id": "debug", "otelcol.component.kind": "exporter", "otelcol.signal": "logs"}
security-service         | 2025-10-03T16:13:03.066Z  INFO 1 --- [bank-shared] [           main] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 819 ms. Found 0 JPA repository interfaces.
auth-statistics-service  | 2025-10-03T16:13:03.406Z  INFO 1 --- [bank-shared] [           main] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data JPA repositories in DEFAULT mode.
fraud-detection          | 2025-10-03T16:13:04.498Z  WARN 1 --- [fraud-detection] [           main] .s.s.UserDetailsServiceAutoConfiguration : 
fraud-detection          | 
fraud-detection          | Using generated security password: 85512ef8-c3d1-4f86-916e-c4a6ab90c4f2
fraud-detection          | 
fraud-detection          | This generated password is for development use only. Your security configuration must be updated before running your application in production.
fraud-detection          | 
Gracefully Stopping... press Ctrl+C again to force
 Container auth-statistics-service  Stopping
 Container kyc-service  Stopping
 Container bank-app-api-gateway-1  Stopping
 Container fraud-detection  Stopping
 Container notification-service  Stopping
 Container bankapp  Stopping
 Container bank-app-api-gateway-1  Stopped
 Container account-service  Stopping
 Container settings-service  Stopping
 Container security-service  Stopping
[Kapi-gateway-1 exited with code 143
 Container notification-service  Stopped
[Knotification-service exited with code 137
 Container kyc-service  Stopped
 Container minio  Stopping
 Container kyc-service_postgres  Stopping
[Kkyc-service exited with code 137
 Container fraud-detection  Stopped
[Kfraud-detection exited with code 137
 Container auth-statistics-service  Stopped
 Container user-service-postgres  Stopping
[Kauth-statistics-service exited with code 137
 Container bankapp  Stopped
[Kbankapp exited with code 137
 Container kyc-service_postgres  Stopped
[Kkyc-service_postgres exited with code 0
 Container minio  Stopped
 Container user-service-postgres  Stopped
[Kminio exited with code 0
[Kuser-service-postgres exited with code 0
 Container settings-service  Stopped
[Ksettings-service exited with code 143
 Container security-service  Stopped
 Container otel-collector  Stopping
[Ksecurity-service exited with code 137
 Container account-service  Stopped
 Container bankapp-postgres  Stopping
 Container kafka  Stopping
[Kaccount-service exited with code 137
 Container otel-collector  Stopped
[Kotel-collector exited with code 0
 Container bankapp-postgres  Stopped
[Kbankapp-postgres exited with code 0
 Container kafka  Stopped

